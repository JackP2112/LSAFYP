{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling Algorithms Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Topic modelling algorithms are a class of machine learning algorithms which largely grew out of natural language processing.\n",
    "They are used to extract latent features, or topics, from a dataset using a variety of techniques.\n",
    "In information retrieval for example, the topics latent to a query can be extracted by a well-trained model by analysing the terms used.\n",
    "The documents most heavily associated with these topics are returned to the user, hopefully satisfying the user's request.\n",
    "\n",
    "The mathematical techniques used can be generalised to more abstract datasets, with topics that may not be easily conceptualised by humans.\n",
    "The [Amazon SageMaker object2vec](https://docs.aws.amazon.com/sagemaker/latest/dg/object2vec.html) algorithm uses neural embedding to represent objects in a low-dimensional space.\n",
    "The algorithm accepts a diverse range of inputs where pairs can have some notion of similarity.\n",
    "This can be applied to the classic NLP problem of sentence similarity, or to pairs of objects such as users and movies where similarity corresponds to a user's rating.\n",
    "\n",
    "This experiment demonstrates the training and validation of the SageMaker object2vec algorithm, as well as several\n",
    "prediction algorithms from the [Surprise Python scikit](http://surpriselib.com/) for use in recommender systems.\n",
    "The algorithms report their internal validation metrics during training, which are then verified with additional test data.\n",
    "The resulting metrics are compiled and reported using the Amazon SageMaker Experiments framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset used in this experiment is the\n",
    "[MovieLens 100k](https://grouplens.org/datasets/movielens/100k/) dataset.\n",
    "It consists of 100,000 ratings from 943 users on 1682 movies.\n",
    "The dataset provides some extra information about both the users and movies,\n",
    "but for the task at hand all that is needed is user and movie ID pairings, along with their associated rating (1-5).\n",
    "\n",
    "### [License](https://files.grouplens.org/datasets/movielens/ml-100k-README.txt)\n",
    "```\n",
    "The data set may be used for any research purposes under the following conditions:\n",
    "\n",
    "     * The user may not state or imply any endorsement from the\n",
    "       University of Minnesota or the GroupLens Research Group.\n",
    "     * The user must acknowledge the use of the data set in\n",
    "       publications resulting from the use of the data set\n",
    "       (see below for citation information).\n",
    "     * The user may not redistribute the data without separate\n",
    "       permission.\n",
    "     * The user may not use this information for any commercial or\n",
    "       revenue-bearing purposes without first obtaining permission\n",
    "       from a faculty member of the GroupLens Research Project at the\n",
    "       University of Minnesota.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "curl -o ml-100k.zip http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "unzip ml-100k.zip\n",
    "rm ml-100k.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ml-100k dataset comes with premade splits of the data for a variety of use cases.  \n",
    "In this instance the breakdown is as follows:\n",
    "- `ua.base` and `ua.test` are used for training and validation respectively, between them they hold all 100,000 ratings\n",
    "- `ua.test` contains 9430 of the total 100,000 ratings, a 9.43% split with exactly 10 ratings per user\n",
    "- `ub.test` is used for conducting our own testing, it too has 9430 ratings, none of which appear in `ua.test`\n",
    "\n",
    "Shown is some basic exploratory data analysis to provide an idea of the dataset's characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (90570, 4)\n",
      "Validation dataset shape: (9430, 4)\n",
      "Test dataset shape: (9430, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>874965758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>876893171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>878542960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>876893119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>889751712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2          3\n",
       "0  1  1  5  874965758\n",
       "1  1  2  3  876893171\n",
       "2  1  3  4  878542960\n",
       "3  1  4  3  876893119\n",
       "4  1  5  3  889751712"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "prefix = 'ml-100k'\n",
    "dfs = []\n",
    "\n",
    "for f in ['ua.base', 'ua.test', 'ub.test']:\n",
    "    dfs.append(pd.read_csv(os.path.join(prefix, f), sep='\\t', header=None))\n",
    "\n",
    "[df_train, df_valid, df_test] = dfs\n",
    "\n",
    "for (name, df) in zip(['Train', 'Validation', 'Test'], dfs):\n",
    "    print(f\"{name} dataset shape: {df.shape}\")\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the last column (here automatically labelled 3), a Unix timestamp which will be dropped for the purposes of this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>movieID</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  movieID  rating\n",
       "0       1        1       5\n",
       "1       1        2       3\n",
       "2       1        3       4\n",
       "3       1        4       3\n",
       "4       1        5       3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for df in dfs:\n",
    "    df.drop(columns=[3], inplace=True)\n",
    "    df.rename(columns={0:'userID', 1:'movieID', 2:'rating'}, inplace=True)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique users: 943\n",
      "Number of unique movies: 1682\n",
      "Total number of ratings: 100000\n"
     ]
    }
   ],
   "source": [
    "df_total = df_train.append(df_valid)\n",
    "\n",
    "print(f\"Number of unique users: {df_total['userID'].nunique()}\")\n",
    "print(f\"Number of unique movies: {df_total['movieID'].nunique()}\")\n",
    "print(f\"Total number of ratings: {len(df_total)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings per user:\n",
      "\tMin: user 926 with 20 ratings\n",
      "\tMax: user 405 with 737 ratings\n",
      "\tMedian: 65 ratings\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAPyklEQVR4nO3df4xldX3G8fdTFrEKFZCFbmHjgNkaMWkXMkEMjaGltYDG1USbJY1uDHZNC6mkJs1ik2r/IKFN/Zm02FWomChI/VE2Sqt0tTE2ERwQYXGlrLqV6a7sqBVMTUyBT/+4Z+C63t2ZnZk7c+7X9yu5ued8z7n3Pjt39pkz33vvmVQVkqS2/NJaB5AkrTzLXZIaZLlLUoMsd0lqkOUuSQ1at9YBAE477bSamppa6xiSNFHuueee71fV+lHbelHuU1NTzMzMrHUMSZooSf7rSNuclpGkBlnuktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ1yHKXpAYt+AnVJBuBjwC/CjwF7Kyq9yV5J/BHwFy369ur6o7uNtcCVwJPAn9aVZ8bQ3YApnZ89ojb9l//ynE9rCT12mJOP/AE8LaqujfJScA9Se7str2nqv52eOck5wJbgZcAvwb8W5Jfr6onVzK4JOnIFpyWqaqDVXVvt/xjYC9w5lFusgW4tap+WlXfAfYBF6xEWEnS4hzTnHuSKeA84K5u6Ook9ye5Kckp3diZwCNDN5tlxA+DJNuTzCSZmZubO3yzJGkZFl3uSU4EPglcU1WPAzcALwQ2AweBd83vOuLmP/dXuKtqZ1VNV9X0+vUjz1gpSVqiRZV7kuMZFPtHq+pTAFX1aFU9WVVPAR/kmamXWWDj0M3PAg6sXGRJ0kIWLPckAW4E9lbVu4fGNwzt9lpgT7e8C9ia5IQkZwObgLtXLrIkaSGLebfMRcAbgAeS3NeNvR24IslmBlMu+4G3AFTVg0luA77B4J02V/lOGUlaXQuWe1V9mdHz6Hcc5TbXAdctI5ckaRn8hKokNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQQuWe5KNSb6YZG+SB5O8tRs/NcmdSR7urk/pxpPk/Un2Jbk/yfnj/kdIkn7WYo7cnwDeVlUvBi4ErkpyLrAD2F1Vm4Dd3TrAZcCm7rIduGHFU0uSjmrBcq+qg1V1b7f8Y2AvcCawBbi52+1m4DXd8hbgIzXwFeDkJBtWPLkk6YiOac49yRRwHnAXcEZVHYTBDwDg9G63M4FHhm42240dfl/bk8wkmZmbmzv25JKkI1p0uSc5EfgkcE1VPX60XUeM1c8NVO2squmqml6/fv1iY0iSFmFR5Z7keAbF/tGq+lQ3/Oj8dEt3fagbnwU2Dt38LODAysSVJC3GYt4tE+BGYG9VvXto0y5gW7e8Dbh9aPyN3btmLgQem5++kSStjnWL2Oci4A3AA0nu68beDlwP3JbkSuC7wOu7bXcAlwP7gJ8Ab1rRxJKkBS1Y7lX1ZUbPowNcMmL/Aq5aZi5J0jL4CVVJapDlLkkNstwlqUGWuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ1yHKXpAZZ7pLUIMtdkhq0YLknuSnJoSR7hsbemeS/k9zXXS4f2nZtkn1JHkry++MKLkk6ssUcuX8YuHTE+HuqanN3uQMgybnAVuAl3W3+PslxKxVWkrQ4C5Z7VX0J+OEi728LcGtV/bSqvgPsAy5YRj5J0hIsZ8796iT3d9M2p3RjZwKPDO0z241JklbRUsv9BuCFwGbgIPCubjwj9q1Rd5Bke5KZJDNzc3NLjCFJGmVJ5V5Vj1bVk1X1FPBBnpl6mQU2Du16FnDgCPexs6qmq2p6/fr1S4khSTqCJZV7kg1Dq68F5t9JswvYmuSEJGcDm4C7lxdRknSs1i20Q5JbgIuB05LMAu8ALk6ymcGUy37gLQBV9WCS24BvAE8AV1XVk+OJLkk6kgXLvaquGDF841H2vw64bjmhJEnL4ydUJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWrQurUOME5TOz47cnz/9a9c5SSStLo8cpekBlnuktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUGWuyQ1aMFyT3JTkkNJ9gyNnZrkziQPd9endONJ8v4k+5Lcn+T8cYaXJI22mCP3DwOXHja2A9hdVZuA3d06wGXApu6yHbhhZWJKko7FguVeVV8CfnjY8Bbg5m75ZuA1Q+MfqYGvACcn2bBSYSVJi7PUOfczquogQHd9ejd+JvDI0H6z3djPSbI9yUySmbm5uSXGkCSNstIvqGbEWI3asap2VtV0VU2vX79+hWNI0i+2pZb7o/PTLd31oW58Ftg4tN9ZwIGlx5MkLcVSy30XsK1b3gbcPjT+xu5dMxcCj81P30iSVs+C53NPcgtwMXBaklngHcD1wG1JrgS+C7y+2/0O4HJgH/AT4E1jyLxsnuddUusWLPequuIImy4ZsW8BVy03lCRpefyEqiQ1yHKXpAZZ7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalBlrskNchyl6QGWe6S1CDLXZIaZLlLUoMsd0lqkOUuSQ2y3CWpQZa7JDXIcpekBlnuktQgy12SGmS5S1KDLHdJapDlLkkNstwlqUHr1jpAn0zt+OzI8f3Xv3KVk0jS8njkLkkNstwlqUGWuyQ1yHKXpAZZ7pLUIMtdkhpkuUtSg5b1Pvck+4EfA08CT1TVdJJTgY8DU8B+4A+q6n+WF1OSdCxW4sj9t6tqc1VNd+s7gN1VtQnY3a1LklbROKZltgA3d8s3A68Zw2NIko5iueVewOeT3JNkezd2RlUdBOiuTx91wyTbk8wkmZmbm1tmDEnSsOWeW+aiqjqQ5HTgziTfXOwNq2onsBNgenq6lplDkjRkWUfuVXWguz4EfBq4AHg0yQaA7vrQckNKko7Nkss9yXOTnDS/DLwC2APsArZ1u20Dbl9uSEnSsVnOtMwZwKeTzN/Px6rqX5N8FbgtyZXAd4HXLz+mJOlYLLncq+rbwG+OGP8BcMlyQk0Kz/8uqa/8hKokNchyl6QGWe6S1CD/hmoPOHcvaaV55C5JDfLIfQw8Epe01jxyl6QGWe6S1CCnZVbRkaZrJGmlWe6LYClLmjSWe4/5wqykpXLOXZIaZLlLUoMsd0lqkHPuDXGOXtI8j9wlqUGWuyQ1yHKXpAY5566RnL+XJptH7pLUII/cJ9Cxng7haPt7JC61ySN3SWqQ5S5JDXJa5hfcuM946Quz0tqw3HVMLGtpMjgtI0kNstwlqUFOy2hFrNTcvdM+0sqw3LUm/GEgjZflrong37GVjo3lrl8oS/m0rr8daBJZ7tISWfrqs7GVe5JLgfcBxwEfqqrrx/VY0kqY9Kkff9ho2FjKPclxwN8BvwfMAl9NsquqvjGOx5MmgeWr1TSuI/cLgH1V9W2AJLcCWwDLXatiLY/CV+qsneMu/aU8bt9+QI07z0qeUXW1v3apqpW/0+R1wKVV9eZu/Q3AS6vq6qF9tgPbu9UXAQ8d4e5OA76/4iFX3qTkhMnJOik5YXKyTkpOmJysa5nzBVW1ftSGcR25Z8TYz/wUqaqdwM4F7yiZqarplQo2LpOSEyYn66TkhMnJOik5YXKy9jXnuE4/MAtsHFo/CzgwpseSJB1mXOX+VWBTkrOTPAvYCuwa02NJkg4zlmmZqnoiydXA5xi8FfKmqnpwiXe34NRNT0xKTpicrJOSEyYn66TkhMnJ2sucY3lBVZK0tjzlryQ1yHKXpAb1ttyTXJrkoST7kuzoQZ6bkhxKsmdo7NQkdyZ5uLs+pRtPkvd32e9Pcv4q5tyY5ItJ9iZ5MMlbe5z12UnuTvL1LutfdeNnJ7mry/rx7kV5kpzQre/rtk+tVtbu8Y9L8rUkn+l5zv1JHkhyX5KZbqyPz//JST6R5Jvd9+vL+pYzyYu6r+P85fEk1/Qt50hV1bsLgxdhvwWcAzwL+Dpw7hpnejlwPrBnaOxvgB3d8g7gr7vly4F/YfB+/wuBu1Yx5wbg/G75JOA/gXN7mjXAid3y8cBdXYbbgK3d+AeAP+6W/wT4QLe8Ffj4Kn8P/BnwMeAz3Xpfc+4HTjtsrI/P/83Am7vlZwEn9zHnUN7jgO8BL+hzzqfzrtUDL/BFfBnwuaH1a4Fre5Br6rByfwjY0C1vAB7qlv8BuGLUfmuQ+XYG5/jpdVbgOcC9wEsZfNpv3eHfCwzeffWybnldt19WKd9ZwG7gd4DPdP95e5eze8xR5d6r5x/4FeA7h39d+pbzsGyvAP6j7znnL32dljkTeGRofbYb65szquogQHd9ejfei/zddMB5DI6Ie5m1m+q4DzgE3MngN7YfVdUTI/I8nbXb/hjw/FWK+l7gz4GnuvXn9zQnDD4N/vkk92Rwmg/o3/N/DjAH/GM31fWhJM/tYc5hW4FbuuU+5wT6O+e+4OkLem7N8yc5EfgkcE1VPX60XUeMrVrWqnqyqjYzODK+AHjxUfKsSdYkrwIOVdU9w8NHybLWz/9FVXU+cBlwVZKXH2Xftcq6jsE05w1VdR7wvwymN45kTb+m3esprwb+aaFdR4ytSXf1tdwn5fQFjybZANBdH+rG1zR/kuMZFPtHq+pTfc46r6p+BPw7g3nKk5PMf8BuOM/TWbvtzwN+uArxLgJenWQ/cCuDqZn39jAnAFV1oLs+BHyawQ/Nvj3/s8BsVd3VrX+CQdn3Lee8y4B7q+rRbr2vOZ/W13KflNMX7AK2dcvbGMxvz4+/sXvl/ELgsflf4cYtSYAbgb1V9e6eZ12f5ORu+ZeB3wX2Al8EXneErPP/htcBX6huYnOcquraqjqrqqYYfC9+oar+sG85AZI8N8lJ88sM5on30LPnv6q+BzyS5EXd0CUMTgneq5xDruCZKZn5PH3M+Yy1mOhf5IsXlzN4p8e3gL/oQZ5bgIPA/zH46Xwlg3nU3cDD3fWp3b5h8MdKvgU8AEyvYs7fYvBr4P3Afd3l8p5m/Q3ga13WPcBfduPnAHcD+xj8GnxCN/7sbn1ft/2cNfg+uJhn3i3Tu5xdpq93lwfn/+/09PnfDMx0z/8/A6f0NOdzgB8Azxsa613Owy+efkCSGtTXaRlJ0jJY7pLUIMtdkhpkuUtSgyx3SWqQ5S5JDbLcJalB/w/m5ZbkBM63oAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings per movie:\n",
      "\tMin: movie 1653 with 1 ratings\n",
      "\tMax: movie 50 with 583 ratings\n",
      "\tMedian: 27 ratings\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# calculate min, max, median ratings per user and ratings per movie\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for col in ['userID', 'movieID']:\n",
    "    counts = Counter(df_total[col]).most_common()\n",
    "    colMax = counts[0]\n",
    "    colMin = counts[-1]\n",
    "    colMed = counts[int(len(counts)/2)]\n",
    "\n",
    "    name = col[:-2] # column name without \"ID\"\n",
    "    print(f\"Ratings per {name}:\")\n",
    "    print(f\"\\tMin: {name} {colMin[0]} with {colMin[1]} ratings\")\n",
    "    print(f\"\\tMax: {name} {colMax[0]} with {colMax[1]} ratings\")\n",
    "    print(f\"\\tMedian: {colMed[1]} ratings\")\n",
    "    \n",
    "    num_ratings = [n for (_,n) in counts]\n",
    "    plt.hist(num_ratings, bins=50)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we confirm that `ua.base`(training set) and `ua.test`(validation set) are disjoint,\n",
    "as well as `ua.test` and `ub.test`(testing set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking training set and validation set...\n",
      "No duplicates found, datasets are disjoint.\n",
      "\n",
      "Checking validation set and testing set...\n",
      "No duplicates found, datasets are disjoint.\n"
     ]
    }
   ],
   "source": [
    "def checkForDuplicates(df_a, df_b):\n",
    "    df_concat = df_a.append(df_b)\n",
    "    # confirm that no user movie pair occurs more than once\n",
    "    duplicates = df_concat.duplicated(['userID', 'movieID'])\n",
    "    if duplicates.any():\n",
    "        [uID, mID] = df_concat.loc[duplicates][['userID', 'movieID']].values[0]\n",
    "        print(f\"Duplicate found! userID: {uID}, movieID: {mID}.\")\n",
    "    else:\n",
    "        print(\"No duplicates found, datasets are disjoint.\")\n",
    "\n",
    "print(\"Checking training set and validation set...\")\n",
    "checkForDuplicates(df_train, df_valid)\n",
    "print(\"\\nChecking validation set and testing set...\")\n",
    "checkForDuplicates(df_valid, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "The algorithms to be trained have different requirements for the format of the input data.\n",
    "The SageMaker object2vec algorithm requires [JSON Lines](https://docs.aws.amazon.com/sagemaker/latest/dg/object2vec-training-formats.html),\n",
    "while the Surprise scikit algorithms expect [CSV input](https://surprise.readthedocs.io/en/stable/reader.html).  \n",
    "To accomodate this, the dataset will be replicated in both formats and uploaded to S3.\n",
    "While the format of the data is different, the value of the information remains exactly the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import io\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "bucket = \"sagemaker-movielens-experiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload CSV data\n",
    "for (channel, df) in zip(['train', 'validation', 'test'], dfs):\n",
    "    # use tab separator as in ml-100k dataset\n",
    "    data_str = df.to_csv(sep='\\t', header=False, index=False)\n",
    "    # upload_fileobj requires a file-like object\n",
    "    data_bin = io.BytesIO(data_str.encode('utf-8'))\n",
    "    s3_client.upload_fileobj(data_bin, bucket, f'input/csv/{channel}/{channel}.csv')\n",
    "\n",
    "# upload JSON Lines data\n",
    "for (channel, df) in zip(['train', 'validation', 'test'], dfs):\n",
    "    # each line should be formatted as {\"in0\":[userID],\"in1\":[movieID],\"label\":rating}\n",
    "    # rename columns\n",
    "    df_tmp = df.rename(columns={'userID':'in0','movieID':'in1','rating':'label'})\n",
    "    # transform \"in0\" and \"in1\" into columns of singleton lists\n",
    "    df_tmp[['in0','in1']] = df_tmp[['in0', 'in1']].transform(lambda c: [[x] for x in c])\n",
    "    # write to json and upload\n",
    "    data_str = df_tmp.to_json(orient='records', lines=True)\n",
    "    # upload_fileobj requires a file-like object\n",
    "    data_bin = io.BytesIO(data_str.encode('utf-8'))\n",
    "    s3_client.upload_fileobj(data_bin, bucket, f\"input/jsonl/{channel}/{channel}.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each algorithm is now trained on the preprocessed datasets.\n",
    "Information such as hyperparameter values, input data configuration and training metrics are stored by Amazon for each training job.  \n",
    "We can query our training jobs based on these values, as well as the user-defined tags which are used to track the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Couldn't call 'get_role' to get Role ARN from role name AmazonSageMaker-ExecutionRole-20210309T220811 to get Role path.\n",
      "Assuming role was created in SageMaker AWS console, as the name contains `AmazonSageMaker-ExecutionRole`. Defaulting to Role ARN with service-role in path. If this Role ARN is incorrect, please add IAM read permissions to your role or supply the Role Arn directly.\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# create session to manage API calls\n",
    "smclient = boto3.client(service_name='sagemaker')\n",
    "sess = sagemaker.Session(sagemaker_client=smclient)\n",
    "# get sagemaker execution role for training\n",
    "role = get_execution_role()\n",
    "\n",
    "# define experiment tags to track\n",
    "tagKey = \"Experiment\"\n",
    "tagVal = \"FYPDemo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the algorithm image\n",
    "from sagemaker.image_uris import retrieve\n",
    "\n",
    "container = retrieve('object2vec', boto3.Session().region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create input data paths\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "base_path = f\"s3://{bucket}/input/jsonl/\"\n",
    "input_paths = {}\n",
    "for channel in ['train', 'validation']:\n",
    "    input_paths[channel] = TrainingInput(base_path + f\"{channel}/{channel}.jsonl\",\n",
    "                                         distribution=\"ShardedByS3Key\",\n",
    "                                         content_type=\"application/jsonlines\")\n",
    "\n",
    "# create ouput path for generated model artifacts\n",
    "output_path = f\"s3://{bucket}/output/object2vec/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "hyperparameters = {\n",
    "    \"_kvstore\": \"device\",\n",
    "    \"_num_gpus\": \"auto\",\n",
    "    \"_num_kv_servers\": \"auto\",\n",
    "    \"bucket_width\": 0,\n",
    "    \"early_stopping_patience\": 3,\n",
    "    \"early_stopping_tolerance\": 0.01,\n",
    "    \"enc0_cnn_filter_width\": 3,\n",
    "    \"enc0_layers\": \"auto\",\n",
    "    \"enc0_max_seq_len\": 1,\n",
    "    \"enc0_network\": \"pooled_embedding\",\n",
    "    \"enc0_token_embedding_dim\": 300,\n",
    "    \"enc0_vocab_size\": 944,\n",
    "    \"enc1_layers\": \"auto\",\n",
    "    \"enc1_max_seq_len\": 1,\n",
    "    \"enc1_network\": \"pooled_embedding\",\n",
    "    \"enc1_token_embedding_dim\": 300,\n",
    "    \"enc1_vocab_size\": 1684,\n",
    "    \"enc_dim\": 1024,\n",
    "    \"epochs\": 20,\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"mini_batch_size\": 64,\n",
    "    \"mlp_activation\": \"tanh\",\n",
    "    \"mlp_dim\": 256,\n",
    "    \"mlp_layers\": 1,\n",
    "    \"num_classes\": 2,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"output_layer\": \"mean_squared_error\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-29 05:02:38 Starting - Starting the training job...\n",
      "2021-04-29 05:02:40 Starting - Launching requested ML instancesProfilerReport-1619672558: InProgress\n",
      "......\n",
      "2021-04-29 05:04:06 Starting - Preparing the instances for training............\n",
      "2021-04-29 05:06:06 Downloading - Downloading input data\n",
      "2021-04-29 05:06:06 Training - Downloading the training image.....\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\n",
      "2021-04-29 05:07:06 Training - Training image download completed. Training in progress.\u001b[34m[04/29/2021 05:06:57 INFO 140016395286336] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/default-input.json: {'enc_dim': 4096, 'mlp_dim': 512, 'mlp_activation': 'linear', 'mlp_layers': 2, 'output_layer': 'softmax', 'optimizer': 'adam', 'learning_rate': 0.0004, 'mini_batch_size': 32, 'epochs': 30, 'bucket_width': 0, 'early_stopping_tolerance': 0.01, 'early_stopping_patience': 3, 'dropout': 0, 'weight_decay': 0, 'negative_sampling_rate': 0, 'comparator_list': 'hadamard, concat, abs_diff', 'tied_token_embedding_weight': 'false', 'token_embedding_storage_type': 'dense', 'enc0_network': 'hcnn', 'enc1_network': 'enc0', 'enc0_token_embedding_dim': 300, 'enc0_layers': 'auto', 'enc0_cnn_filter_width': 3, 'enc1_token_embedding_dim': 300, 'enc1_layers': 'auto', 'enc1_cnn_filter_width': 3, 'enc0_pretrained_embedding_file': '', 'enc0_freeze_pretrained_embedding': 'true', 'enc1_pretrained_embedding_file': '', 'enc1_freeze_pretrained_embedding': 'true', 'enc0_vocab_file': '', 'enc1_vocab_file': '', 'num_classes': 2, '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', '_kvstore': 'auto_gpu'}\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:06:57 INFO 140016395286336] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'enc0_network': 'pooled_embedding', 'num_classes': '2', 'enc0_layers': 'auto', 'enc_dim': '1024', 'enc1_network': 'pooled_embedding', 'enc0_token_embedding_dim': '300', 'enc1_layers': 'auto', 'mlp_activation': 'tanh', 'mlp_dim': '256', 'optimizer': 'adam', 'enc1_vocab_size': '1684', '_num_kv_servers': 'auto', 'mlp_layers': '1', '_kvstore': 'device', 'enc0_vocab_size': '944', 'enc0_max_seq_len': '1', 'enc1_token_embedding_dim': '300', 'early_stopping_patience': '3', 'enc1_max_seq_len': '1', 'output_layer': 'mean_squared_error', '_num_gpus': 'auto', 'enc0_cnn_filter_width': '3', 'early_stopping_tolerance': '0.01', 'bucket_width': '0', 'epochs': '20', 'learning_rate': '0.001', 'mini_batch_size': '64'}\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:06:57 INFO 140016395286336] Final configuration: {'enc_dim': '1024', 'mlp_dim': '256', 'mlp_activation': 'tanh', 'mlp_layers': '1', 'output_layer': 'mean_squared_error', 'optimizer': 'adam', 'learning_rate': '0.001', 'mini_batch_size': '64', 'epochs': '20', 'bucket_width': '0', 'early_stopping_tolerance': '0.01', 'early_stopping_patience': '3', 'dropout': 0, 'weight_decay': 0, 'negative_sampling_rate': 0, 'comparator_list': 'hadamard, concat, abs_diff', 'tied_token_embedding_weight': 'false', 'token_embedding_storage_type': 'dense', 'enc0_network': 'pooled_embedding', 'enc1_network': 'pooled_embedding', 'enc0_token_embedding_dim': '300', 'enc0_layers': 'auto', 'enc0_cnn_filter_width': '3', 'enc1_token_embedding_dim': '300', 'enc1_layers': 'auto', 'enc1_cnn_filter_width': 3, 'enc0_pretrained_embedding_file': '', 'enc0_freeze_pretrained_embedding': 'true', 'enc1_pretrained_embedding_file': '', 'enc1_freeze_pretrained_embedding': 'true', 'enc0_vocab_file': '', 'enc1_vocab_file': '', 'num_classes': '2', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', '_kvstore': 'device', 'enc1_vocab_size': '1684', 'enc0_vocab_size': '944', 'enc0_max_seq_len': '1', 'enc1_max_seq_len': '1'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:06:57 INFO 140016395286336] Using default worker.\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:06:57 INFO 140016395286336] Loaded iterator creator application/jsonlines for content type ('application/jsonlines', '1.0')\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:06:57 INFO 140016395286336] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:06:57 INFO 140016395286336] create_iter params {'enc_dim': '1024', 'mlp_dim': '256', 'mlp_activation': 'tanh', 'mlp_layers': '1', 'output_layer': 'mean_squared_error', 'optimizer': 'adam', 'learning_rate': '0.001', 'mini_batch_size': '64', 'epochs': '20', 'bucket_width': '0', 'early_stopping_tolerance': '0.01', 'early_stopping_patience': '3', 'dropout': 0, 'weight_decay': 0, 'negative_sampling_rate': 0, 'comparator_list': 'hadamard, concat, abs_diff', 'tied_token_embedding_weight': 'false', 'token_embedding_storage_type': 'dense', 'enc0_network': 'pooled_embedding', 'enc1_network': 'pooled_embedding', 'enc0_token_embedding_dim': '300', 'enc0_layers': 'auto', 'enc0_cnn_filter_width': '3', 'enc1_token_embedding_dim': '300', 'enc1_layers': 'auto', 'enc1_cnn_filter_width': 3, 'enc0_pretrained_embedding_file': '', 'enc0_freeze_pretrained_embedding': 'true', 'enc1_pretrained_embedding_file': '', 'enc1_freeze_pretrained_embedding': 'true', 'enc0_vocab_file': '', 'enc1_vocab_file': '', 'num_classes': '2', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', '_kvstore': 'device', 'enc1_vocab_size': '1684', 'enc0_vocab_size': '944', 'enc0_max_seq_len': '1', 'enc1_max_seq_len': '1'}\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:06:57 INFO 140016395286336] create_iter content_params {}\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:06:57 INFO 140016395286336] Parameters of encoders: [{'network': 'pooled_embedding', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': '3', 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'vocab_size': '944', 'max_seq_len': '1'}, {'network': 'pooled_embedding', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': 3, 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'vocab_size': '1684', 'max_seq_len': '1'}]\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:06:57 INFO 140016395286336] output_layer is set to mean_squared_error. Ignoring the hyperparameter 'num_classes'.\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:06:57 INFO 140016395286336] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:06:57 INFO 140016395286336] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:06:57 INFO 140016395286336] Encoder configs: [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 1024, 'vocab_size': 944, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 1024, 'vocab_size': 1684, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:06:57 INFO 140016395286336] Config: {'enc_dim': 1024, 'max_seq_lens': [1, 1], 'dropout': 0.0, 'weight_decay': 0.0, 'mlp_activation': 'tanh', 'mlp_dim': 256, 'mlp_layers': 1, 'output_layer': 'mean_squared_error', 'learning_rate': 0.001, 'optimizer': 'adam', 'num_classes': None, 'epochs': 20, 'mini_batch_size': 64, 'bucket_width': 0, 'comparator_list': ['hadamard', 'concat', 'abs_diff'], 'tied_token_embedding_weight': False, 'negative_sampling_rate': 0, 'token_embedding_storage_type': 'dense', 'early_stopping_patience': 3, 'early_stopping_tolerance': 0.01, 'enc_configs': [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 1024, 'vocab_size': 944, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 1024, 'vocab_size': 1684, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]}\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:06:57 INFO 140016395286336] use bucketing: False\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:06:57 INFO 140016395286336] Creating data iterator for /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] Source words: 90570\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] Target words: 90570\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] Total: 90570 samples in 1 buckets\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] Bucket of (1, 1) : 90570 samples in 1416 batches of 64, approx 64.0 words/batch\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] 0 sentence pairs discarded\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] fill up mode: replicate\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] Negative sampling not used\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] Replicating 54 random sentences from bucket (1, 1) to size it to multiple of 64\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] Bucket batch sizes: [BucketBatchSize(batch_size=64, average_words_per_batch=64.0)]\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] create_iter params {'enc_dim': '1024', 'mlp_dim': '256', 'mlp_activation': 'tanh', 'mlp_layers': '1', 'output_layer': 'mean_squared_error', 'optimizer': 'adam', 'learning_rate': '0.001', 'mini_batch_size': '64', 'epochs': '20', 'bucket_width': '0', 'early_stopping_tolerance': '0.01', 'early_stopping_patience': '3', 'dropout': 0, 'weight_decay': 0, 'negative_sampling_rate': 0, 'comparator_list': 'hadamard, concat, abs_diff', 'tied_token_embedding_weight': 'false', 'token_embedding_storage_type': 'dense', 'enc0_network': 'pooled_embedding', 'enc1_network': 'pooled_embedding', 'enc0_token_embedding_dim': '300', 'enc0_layers': 'auto', 'enc0_cnn_filter_width': '3', 'enc1_token_embedding_dim': '300', 'enc1_layers': 'auto', 'enc1_cnn_filter_width': 3, 'enc0_pretrained_embedding_file': '', 'enc0_freeze_pretrained_embedding': 'true', 'enc1_pretrained_embedding_file': '', 'enc1_freeze_pretrained_embedding': 'true', 'enc0_vocab_file': '', 'enc1_vocab_file': '', 'num_classes': '2', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', '_kvstore': 'device', 'enc1_vocab_size': '1684', 'enc0_vocab_size': '944', 'enc0_max_seq_len': '1', 'enc1_max_seq_len': '1'}\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] create_iter content_params {}\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] Parameters of encoders: [{'network': 'pooled_embedding', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': '3', 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'vocab_size': '944', 'max_seq_len': '1'}, {'network': 'pooled_embedding', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': 3, 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'vocab_size': '1684', 'max_seq_len': '1'}]\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] output_layer is set to mean_squared_error. Ignoring the hyperparameter 'num_classes'.\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] Encoder configs: [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 1024, 'vocab_size': 944, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 1024, 'vocab_size': 1684, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] Config: {'enc_dim': 1024, 'max_seq_lens': [1, 1], 'dropout': 0.0, 'weight_decay': 0.0, 'mlp_activation': 'tanh', 'mlp_dim': 256, 'mlp_layers': 1, 'output_layer': 'mean_squared_error', 'learning_rate': 0.001, 'optimizer': 'adam', 'num_classes': None, 'epochs': 20, 'mini_batch_size': 64, 'bucket_width': 0, 'comparator_list': ['hadamard', 'concat', 'abs_diff'], 'tied_token_embedding_weight': False, 'negative_sampling_rate': 0, 'token_embedding_storage_type': 'dense', 'early_stopping_patience': 3, 'early_stopping_tolerance': 0.01, 'enc_configs': [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 1024, 'vocab_size': 944, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 1024, 'vocab_size': 1684, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]}\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] use bucketing: False\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] Creating data iterator for /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] Source words: 9430\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] Target words: 9430\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] Total: 9430 samples in 1 buckets\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] Bucket of (1, 1) : 9430 samples in 148 batches of 64, approx 64.0 words/batch\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] 0 sentence pairs discarded\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] fill up mode: replicate\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] Negative sampling not used\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] Replicating 42 random sentences from bucket (1, 1) to size it to multiple of 64\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] Parameters of encoders: [{'network': 'pooled_embedding', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': '3', 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'vocab_size': '944', 'max_seq_len': '1'}, {'network': 'pooled_embedding', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': 3, 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'vocab_size': '1684', 'max_seq_len': '1'}]\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] output_layer is set to mean_squared_error. Ignoring the hyperparameter 'num_classes'.\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] Encoder configs: [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 1024, 'vocab_size': 944, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 1024, 'vocab_size': 1684, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] Config: {'enc_dim': 1024, 'max_seq_lens': [1, 1], 'dropout': 0.0, 'weight_decay': 0.0, 'mlp_activation': 'tanh', 'mlp_dim': 256, 'mlp_layers': 1, 'output_layer': 'mean_squared_error', 'learning_rate': 0.001, 'optimizer': 'adam', 'num_classes': None, 'epochs': 20, 'mini_batch_size': 64, 'bucket_width': 0, 'comparator_list': ['hadamard', 'concat', 'abs_diff'], 'tied_token_embedding_weight': False, 'negative_sampling_rate': 0, 'token_embedding_storage_type': 'dense', 'early_stopping_patience': 3, 'early_stopping_tolerance': 0.01, 'enc_configs': [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 1024, 'vocab_size': 944, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 1024, 'vocab_size': 1684, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]}\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] Creating new state\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] params {'enc_dim': '1024', 'mlp_dim': '256', 'mlp_activation': 'tanh', 'mlp_layers': '1', 'output_layer': 'mean_squared_error', 'optimizer': 'adam', 'learning_rate': '0.001', 'mini_batch_size': '64', 'epochs': '20', 'bucket_width': '0', 'early_stopping_tolerance': '0.01', 'early_stopping_patience': '3', 'dropout': 0, 'weight_decay': 0, 'negative_sampling_rate': 0, 'comparator_list': 'hadamard, concat, abs_diff', 'tied_token_embedding_weight': 'false', 'token_embedding_storage_type': 'dense', 'enc0_network': 'pooled_embedding', 'enc1_network': 'pooled_embedding', 'enc0_token_embedding_dim': '300', 'enc0_layers': 'auto', 'enc0_cnn_filter_width': '3', 'enc1_token_embedding_dim': '300', 'enc1_layers': 'auto', 'enc1_cnn_filter_width': 3, 'enc0_pretrained_embedding_file': '', 'enc0_freeze_pretrained_embedding': 'true', 'enc1_pretrained_embedding_file': '', 'enc1_freeze_pretrained_embedding': 'true', 'enc0_vocab_file': '', 'enc1_vocab_file': '', 'num_classes': '2', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', '_kvstore': 'device', 'enc1_vocab_size': '1684', 'enc0_vocab_size': '944', 'enc0_max_seq_len': '1', 'enc1_max_seq_len': '1', 'default_bucket_key': (1, 1)}\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] default_bucket_key (1, 1)\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] nvidia-smi: took 0.032 seconds to run.\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] nvidia-smi identified 1 GPUs.\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] context [gpu(0)]\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] Create Store: device\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 WARNING 140016395286336] dense token embedding is used in a multi-gpu setting...consider changing 'token_embedding_storage_type' to 'row_sparse'\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] data_names: ['source', 'target']\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] label_names: ['out_layer_label']\u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mLayer (type)                                        Output Shape            Param #     Previous Layer                  \u001b[0m\n",
      "\u001b[34m========================================================================================================================\u001b[0m\n",
      "\u001b[34msource(null)                                        1                       0                                           \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34membed_0(Embedding)                                  1x1024                  0           source                          \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_not_equal_scalar0(_not_equal_scalar)               1                       0           source                          \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mreshape0(Reshape)                                   1x1                     0           _not_equal_scalar0              \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbroadcast_mul0(broadcast_mul)                       1x1024                  0           embed_0                         \n",
      "                                                                                        reshape0                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34msum0(sum)                                           1024                    0           broadcast_mul0                  \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34msum1(sum)                                           1                       0           reshape0                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mzeros_like0(zeros_like)                             1                       0           sum1                            \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_equal0(_equal)                                     1                       0           sum1                            \n",
      "                                                                                        zeros_like0                     \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_plus0(elemwise_add)                                1                       0           sum1                            \n",
      "                                                                                        _equal0                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbroadcast_div0(broadcast_div)                       1024                    0           sum0                            \n",
      "                                                                                        _plus0                          \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout0(Dropout)                                   1024                    0           broadcast_div0                  \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34membed_1(Embedding)                                  1x1024                  0                                           \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_not_equal_scalar1(_not_equal_scalar)               1                       0                                           \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mreshape1(Reshape)                                   1x1                     0           _not_equal_scalar1              \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbroadcast_mul1(broadcast_mul)                       1x1024                  0           embed_1                         \n",
      "                                                                                        reshape1                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34msum2(sum)                                           1024                    0           broadcast_mul1                  \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34msum3(sum)                                           1                       0           reshape1                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mzeros_like1(zeros_like)                             1                       0           sum3                            \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_equal1(_equal)                                     1                       0           sum3                            \n",
      "                                                                                        zeros_like1                     \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_plus1(elemwise_add)                                1                       0           sum3                            \n",
      "                                                                                        _equal1                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbroadcast_div1(broadcast_div)                       1024                    0           sum2                            \n",
      "                                                                                        _plus1                          \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout1(Dropout)                                   1024                    0           broadcast_div1                  \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_mul0(elemwise_mul)                                 1024                    0           dropout0                        \n",
      "                                                                                        dropout1                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_minus0(elemwise_sub)                               1024                    0           dropout0                        \n",
      "                                                                                        dropout1                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mabs0(abs)                                           1024                    0           _minus0                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconcat0(Concat)                                     4096                    0           _mul0                           \n",
      "                                                                                        dropout0                        \n",
      "                                                                                        dropout1                        \n",
      "                                                                                        abs0                            \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mmlp_fc0(FullyConnected)                             256                     1048832     concat0                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation0(Activation)                             256                     0           mlp_fc0                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout2(Dropout)                                   256                     0           activation0                     \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34moutput_layer(FullyConnected)                        1                       257         dropout2                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mout_layer(LinearRegressionOutput)                   1                       0           output_layer                    \u001b[0m\n",
      "\u001b[34m========================================================================================================================\u001b[0m\n",
      "\u001b[34mTotal params: 1049089\u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] data_shapes [DataDesc[source,(64, 1),<class 'numpy.float32'>,NTC], DataDesc[target,(64, 1),<class 'numpy.float32'>,NTC]]\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] label_shapes [DataDesc[out_layer_label,(64,),<class 'numpy.float32'>,NTC]]\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] fixed_param_names: []\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:00 INFO 140016395286336] Initialized BucketingPlus Module\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:07 INFO 140016395286336] arg_params keys for module initialization: dict_keys([])\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:07 INFO 140016395286336] all params:dict_keys(['embed_0_weight', 'embed_1_weight', 'mlp_fc0_weight', 'mlp_fc0_bias', 'output_layer_weight', 'output_layer_bias'])\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619672817.6272132, \"EndTime\": 1619672827.7867956, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 6987.687110900879, \"count\": 1, \"min\": 6987.687110900879, \"max\": 6987.687110900879}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619672827.7870188, \"EndTime\": 1619672827.7870753, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:08 INFO 140016395286336] Epoch: 0, batches: 100, num_examples: 6400, 14745.1 samples/sec, epoch time so far: 0:00:00.434042\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:08 INFO 140016395286336] #011Training metrics: mean_squared_error: 1.687 mean_absolute_error: 1.017 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:08 INFO 140016395286336] Epoch: 0, batches: 200, num_examples: 12800, 14778.1 samples/sec, epoch time so far: 0:00:00.866148\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:08 INFO 140016395286336] #011Training metrics: mean_squared_error: 1.393 mean_absolute_error: 0.926 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:09 INFO 140016395286336] Epoch: 0, batches: 300, num_examples: 19200, 15224.3 samples/sec, epoch time so far: 0:00:01.261145\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:09 INFO 140016395286336] #011Training metrics: mean_squared_error: 1.284 mean_absolute_error: 0.892 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:09 INFO 140016395286336] Epoch: 0, batches: 400, num_examples: 25600, 15507.4 samples/sec, epoch time so far: 0:00:01.650826\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:09 INFO 140016395286336] #011Training metrics: mean_squared_error: 1.218 mean_absolute_error: 0.870 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:09 INFO 140016395286336] Epoch: 0, batches: 500, num_examples: 32000, 15669.7 samples/sec, epoch time so far: 0:00:02.042160\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:09 INFO 140016395286336] #011Training metrics: mean_squared_error: 1.178 mean_absolute_error: 0.856 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:10 INFO 140016395286336] Epoch: 0, batches: 600, num_examples: 38400, 15748.6 samples/sec, epoch time so far: 0:00:02.438316\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:10 INFO 140016395286336] #011Training metrics: mean_squared_error: 1.142 mean_absolute_error: 0.843 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:10 INFO 140016395286336] Epoch: 0, batches: 700, num_examples: 44800, 15836.7 samples/sec, epoch time so far: 0:00:02.828864\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:10 INFO 140016395286336] #011Training metrics: mean_squared_error: 1.116 mean_absolute_error: 0.833 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:11 INFO 140016395286336] Epoch: 0, batches: 800, num_examples: 51200, 15719.8 samples/sec, epoch time so far: 0:00:03.257048\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:11 INFO 140016395286336] #011Training metrics: mean_squared_error: 1.096 mean_absolute_error: 0.825 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:11 INFO 140016395286336] Epoch: 0, batches: 900, num_examples: 57600, 15797.0 samples/sec, epoch time so far: 0:00:03.646256\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:11 INFO 140016395286336] #011Training metrics: mean_squared_error: 1.080 mean_absolute_error: 0.820 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:11 INFO 140016395286336] Epoch: 0, batches: 1000, num_examples: 64000, 15856.5 samples/sec, epoch time so far: 0:00:04.036193\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:11 INFO 140016395286336] #011Training metrics: mean_squared_error: 1.066 mean_absolute_error: 0.815 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:12 INFO 140016395286336] Epoch: 0, batches: 1100, num_examples: 70400, 15900.3 samples/sec, epoch time so far: 0:00:04.427591\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:12 INFO 140016395286336] #011Training metrics: mean_squared_error: 1.056 mean_absolute_error: 0.812 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:12 INFO 140016395286336] Epoch: 0, batches: 1200, num_examples: 76800, 15939.0 samples/sec, epoch time so far: 0:00:04.818382\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:12 INFO 140016395286336] #011Training metrics: mean_squared_error: 1.045 mean_absolute_error: 0.808 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:13 INFO 140016395286336] Epoch: 0, batches: 1300, num_examples: 83200, 15980.5 samples/sec, epoch time so far: 0:00:05.206355\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:13 INFO 140016395286336] #011Training metrics: mean_squared_error: 1.036 mean_absolute_error: 0.804 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:13 INFO 140016395286336] Epoch: 0, batches: 1400, num_examples: 89600, 15998.7 samples/sec, epoch time so far: 0:00:05.600444\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:13 INFO 140016395286336] #011Training metrics: mean_squared_error: 1.026 mean_absolute_error: 0.800 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:13 INFO 140016395286336] **************\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:13 INFO 140016395286336] Completed Epoch: 0, time taken: 0:00:05.663380\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:13 INFO 140016395286336] Epoch 0 Training metrics:   mean_squared_error: 1.025 mean_absolute_error: 0.800 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:13 INFO 140016395286336] #quality_metric: host=algo-1, epoch=0, train mean_squared_error <loss>=1.025062304347922\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:13 INFO 140016395286336] Epoch 0 Validation metrics: mean_squared_error: 0.951 mean_absolute_error: 0.773 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:13 INFO 140016395286336] #quality_metric: host=algo-1, epoch=0, validation mean_squared_error <loss>=0.9511892545867611\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:13 INFO 140016395286336] **************\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619672827.7869127, \"EndTime\": 1619672833.762773, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 20.0, \"count\": 1, \"min\": 20, \"max\": 20}, \"early_stop.time\": {\"sum\": 0.8397102355957031, \"count\": 1, \"min\": 0.8397102355957031, \"max\": 0.8397102355957031}, \"update.time\": {\"sum\": 5908.940553665161, \"count\": 1, \"min\": 5908.940553665161, \"max\": 5908.940553665161}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:13 INFO 140016395286336] #progress_metric: host=algo-1, completed 5.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619672827.8538039, \"EndTime\": 1619672833.7631133, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Total Batches Seen\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:13 INFO 140016395286336] #throughput_metric: host=algo-1, train throughput=15335.274447695749 records/second\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:14 INFO 140016395286336] Epoch: 1, batches: 100, num_examples: 6400, 16005.4 samples/sec, epoch time so far: 0:00:00.399864\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:14 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.705 mean_absolute_error: 0.661 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:14 INFO 140016395286336] Epoch: 1, batches: 200, num_examples: 12800, 14737.6 samples/sec, epoch time so far: 0:00:00.868527\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:14 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.700 mean_absolute_error: 0.659 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:15 INFO 140016395286336] Epoch: 1, batches: 300, num_examples: 19200, 14335.7 samples/sec, epoch time so far: 0:00:01.339311\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:15 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.705 mean_absolute_error: 0.662 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:15 INFO 140016395286336] Epoch: 1, batches: 400, num_examples: 25600, 13790.3 samples/sec, epoch time so far: 0:00:01.856379\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:15 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.704 mean_absolute_error: 0.660 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:16 INFO 140016395286336] Epoch: 1, batches: 500, num_examples: 32000, 14130.2 samples/sec, epoch time so far: 0:00:02.264660\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:16 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.697 mean_absolute_error: 0.657 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:16 INFO 140016395286336] Epoch: 1, batches: 600, num_examples: 38400, 14342.4 samples/sec, epoch time so far: 0:00:02.677383\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:16 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.690 mean_absolute_error: 0.654 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:16 INFO 140016395286336] Epoch: 1, batches: 700, num_examples: 44800, 14600.2 samples/sec, epoch time so far: 0:00:03.068448\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:16 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.679 mean_absolute_error: 0.649 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:17 INFO 140016395286336] Epoch: 1, batches: 800, num_examples: 51200, 14768.9 samples/sec, epoch time so far: 0:00:03.466735\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:17 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.674 mean_absolute_error: 0.646 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:17 INFO 140016395286336] Epoch: 1, batches: 900, num_examples: 57600, 14928.5 samples/sec, epoch time so far: 0:00:03.858396\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:17 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.670 mean_absolute_error: 0.644 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:18 INFO 140016395286336] Epoch: 1, batches: 1000, num_examples: 64000, 15064.0 samples/sec, epoch time so far: 0:00:04.248527\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:18 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.666 mean_absolute_error: 0.642 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:18 INFO 140016395286336] Epoch: 1, batches: 1100, num_examples: 70400, 15151.4 samples/sec, epoch time so far: 0:00:04.646441\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:18 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.663 mean_absolute_error: 0.640 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:18 INFO 140016395286336] Epoch: 1, batches: 1200, num_examples: 76800, 15224.4 samples/sec, epoch time so far: 0:00:05.044535\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:18 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.660 mean_absolute_error: 0.639 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:19 INFO 140016395286336] Epoch: 1, batches: 1300, num_examples: 83200, 15223.9 samples/sec, epoch time so far: 0:00:05.465098\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:19 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.659 mean_absolute_error: 0.638 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:19 INFO 140016395286336] Epoch: 1, batches: 1400, num_examples: 89600, 15301.6 samples/sec, epoch time so far: 0:00:05.855588\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:19 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.657 mean_absolute_error: 0.637 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:19 INFO 140016395286336] **************\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:19 INFO 140016395286336] Completed Epoch: 1, time taken: 0:00:05.918118\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:19 INFO 140016395286336] Epoch 1 Training metrics:   mean_squared_error: 0.657 mean_absolute_error: 0.637 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:19 INFO 140016395286336] #quality_metric: host=algo-1, epoch=1, train mean_squared_error <loss>=0.6570161882219678\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:19 INFO 140016395286336] Epoch 1 Validation metrics: mean_squared_error: 0.982 mean_absolute_error: 0.788 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:19 INFO 140016395286336] #quality_metric: host=algo-1, epoch=1, validation mean_squared_error <loss>=0.9820304678098576\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:19 INFO 140016395286336] **************\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619672833.7628992, \"EndTime\": 1619672839.9384189, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 0.0286102294921875, \"count\": 1, \"min\": 0.0286102294921875, \"max\": 0.0286102294921875}, \"update.time\": {\"sum\": 6121.577262878418, \"count\": 1, \"min\": 6121.577262878418, \"max\": 6121.577262878418}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:19 INFO 140016395286336] #progress_metric: host=algo-1, completed 10.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619672833.8168175, \"EndTime\": 1619672839.9386945, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 181248.0, \"count\": 1, \"min\": 181248, \"max\": 181248}, \"Total Batches Seen\": {\"sum\": 2832.0, \"count\": 1, \"min\": 2832, \"max\": 2832}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:19 INFO 140016395286336] #throughput_metric: host=algo-1, train throughput=14802.9329662697 records/second\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:20 INFO 140016395286336] Epoch: 2, batches: 100, num_examples: 6400, 16246.6 samples/sec, epoch time so far: 0:00:00.393929\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:20 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.277 mean_absolute_error: 0.404 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:20 INFO 140016395286336] Epoch: 2, batches: 200, num_examples: 12800, 16154.6 samples/sec, epoch time so far: 0:00:00.792345\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:20 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.266 mean_absolute_error: 0.395 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:21 INFO 140016395286336] Epoch: 2, batches: 300, num_examples: 19200, 16198.4 samples/sec, epoch time so far: 0:00:01.185304\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:21 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.267 mean_absolute_error: 0.395 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:21 INFO 140016395286336] Epoch: 2, batches: 400, num_examples: 25600, 16220.9 samples/sec, epoch time so far: 0:00:01.578211\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:21 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.265 mean_absolute_error: 0.393 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:21 INFO 140016395286336] Epoch: 2, batches: 500, num_examples: 32000, 16248.6 samples/sec, epoch time so far: 0:00:01.969398\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:21 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.266 mean_absolute_error: 0.394 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:22 INFO 140016395286336] Epoch: 2, batches: 600, num_examples: 38400, 16252.9 samples/sec, epoch time so far: 0:00:02.362660\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:22 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.266 mean_absolute_error: 0.394 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:22 INFO 140016395286336] Epoch: 2, batches: 700, num_examples: 44800, 16286.7 samples/sec, epoch time so far: 0:00:02.750708\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:22 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.266 mean_absolute_error: 0.395 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:23 INFO 140016395286336] Epoch: 2, batches: 800, num_examples: 51200, 16303.2 samples/sec, epoch time so far: 0:00:03.140493\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:23 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.267 mean_absolute_error: 0.396 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:23 INFO 140016395286336] Epoch: 2, batches: 900, num_examples: 57600, 16297.1 samples/sec, epoch time so far: 0:00:03.534370\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:23 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.268 mean_absolute_error: 0.396 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:23 INFO 140016395286336] Epoch: 2, batches: 1000, num_examples: 64000, 16314.7 samples/sec, epoch time so far: 0:00:03.922851\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:23 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.269 mean_absolute_error: 0.398 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:24 INFO 140016395286336] Epoch: 2, batches: 1100, num_examples: 70400, 16109.8 samples/sec, epoch time so far: 0:00:04.370018\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:24 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.270 mean_absolute_error: 0.399 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:24 INFO 140016395286336] Epoch: 2, batches: 1200, num_examples: 76800, 16135.4 samples/sec, epoch time so far: 0:00:04.759723\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:24 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.272 mean_absolute_error: 0.400 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:25 INFO 140016395286336] Epoch: 2, batches: 1300, num_examples: 83200, 16139.6 samples/sec, epoch time so far: 0:00:05.155022\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:25 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.274 mean_absolute_error: 0.402 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:25 INFO 140016395286336] Epoch: 2, batches: 1400, num_examples: 89600, 16151.1 samples/sec, epoch time so far: 0:00:05.547618\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:25 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.276 mean_absolute_error: 0.403 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:25 INFO 140016395286336] **************\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:25 INFO 140016395286336] Completed Epoch: 2, time taken: 0:00:05.609850\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:25 INFO 140016395286336] Epoch 2 Training metrics:   mean_squared_error: 0.276 mean_absolute_error: 0.403 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:25 INFO 140016395286336] #quality_metric: host=algo-1, epoch=2, train mean_squared_error <loss>=0.2762060411968979\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:25 INFO 140016395286336] Epoch 2 Validation metrics: mean_squared_error: 0.959 mean_absolute_error: 0.779 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:25 INFO 140016395286336] #quality_metric: host=algo-1, epoch=2, validation mean_squared_error <loss>=0.9585297796371821\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:25 INFO 140016395286336] **************\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619672839.9385056, \"EndTime\": 1619672845.7705603, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 0.029087066650390625, \"count\": 1, \"min\": 0.029087066650390625, \"max\": 0.029087066650390625}, \"update.time\": {\"sum\": 5825.82950592041, \"count\": 1, \"min\": 5825.82950592041, \"max\": 5825.82950592041}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:25 INFO 140016395286336] #progress_metric: host=algo-1, completed 15.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619672839.9447098, \"EndTime\": 1619672845.7708774, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 271872.0, \"count\": 1, \"min\": 271872, \"max\": 271872}, \"Total Batches Seen\": {\"sum\": 4248.0, \"count\": 1, \"min\": 4248, \"max\": 4248}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:25 INFO 140016395286336] #throughput_metric: host=algo-1, train throughput=15554.286326184287 records/second\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:26 INFO 140016395286336] Epoch: 3, batches: 100, num_examples: 6400, 16341.4 samples/sec, epoch time so far: 0:00:00.391644\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:26 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.180 mean_absolute_error: 0.306 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:26 INFO 140016395286336] Epoch: 3, batches: 200, num_examples: 12800, 16281.5 samples/sec, epoch time so far: 0:00:00.786166\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:26 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.176 mean_absolute_error: 0.304 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:26 INFO 140016395286336] Epoch: 3, batches: 300, num_examples: 19200, 16308.5 samples/sec, epoch time so far: 0:00:01.177302\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:26 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.169 mean_absolute_error: 0.301 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:27 INFO 140016395286336] Epoch: 3, batches: 400, num_examples: 25600, 16257.7 samples/sec, epoch time so far: 0:00:01.574638\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:27 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.167 mean_absolute_error: 0.300 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:27 INFO 140016395286336] Epoch: 3, batches: 500, num_examples: 32000, 16287.5 samples/sec, epoch time so far: 0:00:01.964694\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:27 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.167 mean_absolute_error: 0.300 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:28 INFO 140016395286336] Epoch: 3, batches: 600, num_examples: 38400, 16313.1 samples/sec, epoch time so far: 0:00:02.353940\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:28 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.166 mean_absolute_error: 0.299 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:28 INFO 140016395286336] Epoch: 3, batches: 700, num_examples: 44800, 16313.4 samples/sec, epoch time so far: 0:00:02.746205\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:28 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.166 mean_absolute_error: 0.300 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:28 INFO 140016395286336] Epoch: 3, batches: 800, num_examples: 51200, 16319.3 samples/sec, epoch time so far: 0:00:03.137390\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:28 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.166 mean_absolute_error: 0.300 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:29 INFO 140016395286336] Epoch: 3, batches: 900, num_examples: 57600, 16196.6 samples/sec, epoch time so far: 0:00:03.556307\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:29 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.165 mean_absolute_error: 0.299 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:29 INFO 140016395286336] Epoch: 3, batches: 1000, num_examples: 64000, 16191.7 samples/sec, epoch time so far: 0:00:03.952652\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:29 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.164 mean_absolute_error: 0.300 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:30 INFO 140016395286336] Epoch: 3, batches: 1100, num_examples: 70400, 16198.0 samples/sec, epoch time so far: 0:00:04.346210\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:30 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.165 mean_absolute_error: 0.301 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:30 INFO 140016395286336] Epoch: 3, batches: 1200, num_examples: 76800, 16199.4 samples/sec, epoch time so far: 0:00:04.740910\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:30 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.166 mean_absolute_error: 0.302 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:30 INFO 140016395286336] Epoch: 3, batches: 1300, num_examples: 83200, 16140.7 samples/sec, epoch time so far: 0:00:05.154670\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:30 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.166 mean_absolute_error: 0.302 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:31 INFO 140016395286336] Epoch: 3, batches: 1400, num_examples: 89600, 16142.8 samples/sec, epoch time so far: 0:00:05.550469\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:31 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.167 mean_absolute_error: 0.303 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:31 INFO 140016395286336] **************\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:31 INFO 140016395286336] Completed Epoch: 3, time taken: 0:00:05.613362\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:31 INFO 140016395286336] Epoch 3 Training metrics:   mean_squared_error: 0.167 mean_absolute_error: 0.303 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:31 INFO 140016395286336] #quality_metric: host=algo-1, epoch=3, train mean_squared_error <loss>=0.16678180450857696\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:31 INFO 140016395286336] Epoch 3 Validation metrics: mean_squared_error: 0.952 mean_absolute_error: 0.763 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:31 INFO 140016395286336] #quality_metric: host=algo-1, epoch=3, validation mean_squared_error <loss>=0.9517564693012753\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:31 INFO 140016395286336] **************\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:31 INFO 140016395286336] patience losses: [0.9511892545867611, 0.9820304678098576, 0.9585297796371821]\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:31 INFO 140016395286336] min patience losses: 0.9511892545867611\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:31 INFO 140016395286336] current loss: 0.9517564693012753\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:31 INFO 140016395286336] absolute loss difference: 0.0005672147145142636\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:31 INFO 140016395286336] Bad epoch: loss has not improved (enough). Bad count:1\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619672845.7706912, \"EndTime\": 1619672851.6007028, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 0.4932880401611328, \"count\": 1, \"min\": 0.4932880401611328, \"max\": 0.4932880401611328}, \"update.time\": {\"sum\": 5824.132919311523, \"count\": 1, \"min\": 5824.132919311523, \"max\": 5824.132919311523}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:31 INFO 140016395286336] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619672845.7765536, \"EndTime\": 1619672851.6009536, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 362496.0, \"count\": 1, \"min\": 362496, \"max\": 362496}, \"Total Batches Seen\": {\"sum\": 5664.0, \"count\": 1, \"min\": 5664, \"max\": 5664}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:31 INFO 140016395286336] #throughput_metric: host=algo-1, train throughput=15558.981279182459 records/second\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:31 INFO 140016395286336] Epoch: 4, batches: 100, num_examples: 6400, 16314.6 samples/sec, epoch time so far: 0:00:00.392286\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:31 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.117 mean_absolute_error: 0.254 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:32 INFO 140016395286336] Epoch: 4, batches: 200, num_examples: 12800, 16335.8 samples/sec, epoch time so far: 0:00:00.783554\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:32 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.117 mean_absolute_error: 0.254 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:32 INFO 140016395286336] Epoch: 4, batches: 300, num_examples: 19200, 16300.1 samples/sec, epoch time so far: 0:00:01.177907\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:32 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.113 mean_absolute_error: 0.251 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:33 INFO 140016395286336] Epoch: 4, batches: 400, num_examples: 25600, 16319.4 samples/sec, epoch time so far: 0:00:01.568689\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:33 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.112 mean_absolute_error: 0.251 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:33 INFO 140016395286336] Epoch: 4, batches: 500, num_examples: 32000, 16326.5 samples/sec, epoch time so far: 0:00:01.960006\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:33 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.111 mean_absolute_error: 0.250 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:33 INFO 140016395286336] Epoch: 4, batches: 600, num_examples: 38400, 16326.9 samples/sec, epoch time so far: 0:00:02.351953\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:33 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.110 mean_absolute_error: 0.250 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:34 INFO 140016395286336] Epoch: 4, batches: 700, num_examples: 44800, 16157.2 samples/sec, epoch time so far: 0:00:02.772754\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:34 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.110 mean_absolute_error: 0.249 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:34 INFO 140016395286336] Epoch: 4, batches: 800, num_examples: 51200, 16141.7 samples/sec, epoch time so far: 0:00:03.171900\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:34 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.110 mean_absolute_error: 0.249 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:35 INFO 140016395286336] Epoch: 4, batches: 900, num_examples: 57600, 16141.4 samples/sec, epoch time so far: 0:00:03.568470\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:35 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.110 mean_absolute_error: 0.249 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:35 INFO 140016395286336] Epoch: 4, batches: 1000, num_examples: 64000, 16151.7 samples/sec, epoch time so far: 0:00:03.962433\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:35 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.110 mean_absolute_error: 0.249 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:35 INFO 140016395286336] Epoch: 4, batches: 1100, num_examples: 70400, 16135.7 samples/sec, epoch time so far: 0:00:04.362984\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:35 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.109 mean_absolute_error: 0.248 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:36 INFO 140016395286336] Epoch: 4, batches: 1200, num_examples: 76800, 16157.2 samples/sec, epoch time so far: 0:00:04.753298\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:36 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.110 mean_absolute_error: 0.249 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:36 INFO 140016395286336] Epoch: 4, batches: 1300, num_examples: 83200, 16156.0 samples/sec, epoch time so far: 0:00:05.149799\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:36 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.110 mean_absolute_error: 0.250 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:37 INFO 140016395286336] Epoch: 4, batches: 1400, num_examples: 89600, 16177.4 samples/sec, epoch time so far: 0:00:05.538587\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:37 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.110 mean_absolute_error: 0.250 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:37 INFO 140016395286336] **************\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:37 INFO 140016395286336] Completed Epoch: 4, time taken: 0:00:05.600776\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:37 INFO 140016395286336] Epoch 4 Training metrics:   mean_squared_error: 0.110 mean_absolute_error: 0.250 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:37 INFO 140016395286336] #quality_metric: host=algo-1, epoch=4, train mean_squared_error <loss>=0.11000582077251063\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:37 INFO 140016395286336] Epoch 4 Validation metrics: mean_squared_error: 0.954 mean_absolute_error: 0.761 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:37 INFO 140016395286336] #quality_metric: host=algo-1, epoch=4, validation mean_squared_error <loss>=0.953693272696959\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:37 INFO 140016395286336] **************\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:37 INFO 140016395286336] patience losses: [0.9820304678098576, 0.9585297796371821, 0.9517564693012753]\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:37 INFO 140016395286336] min patience losses: 0.9517564693012753\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:37 INFO 140016395286336] current loss: 0.953693272696959\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:37 INFO 140016395286336] absolute loss difference: 0.001936803395683695\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:37 INFO 140016395286336] Bad epoch: loss has not improved (enough). Bad count:2\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619672851.600782, \"EndTime\": 1619672857.4096177, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 0.5354881286621094, \"count\": 1, \"min\": 0.5354881286621094, \"max\": 0.5354881286621094}, \"update.time\": {\"sum\": 5803.015947341919, \"count\": 1, \"min\": 5803.015947341919, \"max\": 5803.015947341919}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:37 INFO 140016395286336] #progress_metric: host=algo-1, completed 25.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619672851.6065786, \"EndTime\": 1619672857.4098368, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 453120.0, \"count\": 1, \"min\": 453120, \"max\": 453120}, \"Total Batches Seen\": {\"sum\": 7080.0, \"count\": 1, \"min\": 7080, \"max\": 7080}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:37 INFO 140016395286336] #throughput_metric: host=algo-1, train throughput=15615.789582065156 records/second\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:37 INFO 140016395286336] Epoch: 5, batches: 100, num_examples: 6400, 16306.7 samples/sec, epoch time so far: 0:00:00.392476\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:37 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.094 mean_absolute_error: 0.234 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:38 INFO 140016395286336] Epoch: 5, batches: 200, num_examples: 12800, 16357.0 samples/sec, epoch time so far: 0:00:00.782542\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:38 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.090 mean_absolute_error: 0.230 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:38 INFO 140016395286336] Epoch: 5, batches: 300, num_examples: 19200, 16302.5 samples/sec, epoch time so far: 0:00:01.177734\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:38 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.089 mean_absolute_error: 0.230 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:38 INFO 140016395286336] Epoch: 5, batches: 400, num_examples: 25600, 16292.4 samples/sec, epoch time so far: 0:00:01.571285\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:38 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.088 mean_absolute_error: 0.229 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:39 INFO 140016395286336] Epoch: 5, batches: 500, num_examples: 32000, 16116.8 samples/sec, epoch time so far: 0:00:01.985507\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:39 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.088 mean_absolute_error: 0.228 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:39 INFO 140016395286336] Epoch: 5, batches: 600, num_examples: 38400, 16052.7 samples/sec, epoch time so far: 0:00:02.392119\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:39 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.087 mean_absolute_error: 0.227 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:40 INFO 140016395286336] Epoch: 5, batches: 700, num_examples: 44800, 16069.3 samples/sec, epoch time so far: 0:00:02.787916\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:40 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.087 mean_absolute_error: 0.227 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:40 INFO 140016395286336] Epoch: 5, batches: 800, num_examples: 51200, 16062.6 samples/sec, epoch time so far: 0:00:03.187529\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:40 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.087 mean_absolute_error: 0.227 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:40 INFO 140016395286336] Epoch: 5, batches: 900, num_examples: 57600, 16070.2 samples/sec, epoch time so far: 0:00:03.584284\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:41 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.087 mean_absolute_error: 0.227 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:41 INFO 140016395286336] Epoch: 5, batches: 1000, num_examples: 64000, 16101.9 samples/sec, epoch time so far: 0:00:03.974691\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:41 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.087 mean_absolute_error: 0.227 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:41 INFO 140016395286336] Epoch: 5, batches: 1100, num_examples: 70400, 16108.4 samples/sec, epoch time so far: 0:00:04.370394\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:41 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.086 mean_absolute_error: 0.227 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:42 INFO 140016395286336] Epoch: 5, batches: 1200, num_examples: 76800, 16134.9 samples/sec, epoch time so far: 0:00:04.759875\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:42 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.087 mean_absolute_error: 0.228 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:42 INFO 140016395286336] Epoch: 5, batches: 1300, num_examples: 83200, 16146.6 samples/sec, epoch time so far: 0:00:05.152778\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:42 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.087 mean_absolute_error: 0.228 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:42 INFO 140016395286336] Epoch: 5, batches: 1400, num_examples: 89600, 16147.3 samples/sec, epoch time so far: 0:00:05.548917\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:42 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.087 mean_absolute_error: 0.228 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:43 INFO 140016395286336] **************\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:43 INFO 140016395286336] Completed Epoch: 5, time taken: 0:00:05.612894\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:43 INFO 140016395286336] Epoch 5 Training metrics:   mean_squared_error: 0.087 mean_absolute_error: 0.228 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:43 INFO 140016395286336] #quality_metric: host=algo-1, epoch=5, train mean_squared_error <loss>=0.08698759638141357\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:43 INFO 140016395286336] Epoch 5 Validation metrics: mean_squared_error: 0.937 mean_absolute_error: 0.766 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:43 INFO 140016395286336] #quality_metric: host=algo-1, epoch=5, validation mean_squared_error <loss>=0.9372927490118388\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:43 INFO 140016395286336] **************\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:43 INFO 140016395286336] patience losses: [0.9585297796371821, 0.9517564693012753, 0.953693272696959]\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:43 INFO 140016395286336] min patience losses: 0.9517564693012753\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:43 INFO 140016395286336] current loss: 0.9372927490118388\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:43 INFO 140016395286336] absolute loss difference: 0.014463720289436544\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619672857.4096987, \"EndTime\": 1619672863.2322567, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 3.7755966186523438, \"count\": 1, \"min\": 3.7755966186523438, \"max\": 3.7755966186523438}, \"update.time\": {\"sum\": 5816.628694534302, \"count\": 1, \"min\": 5816.628694534302, \"max\": 5816.628694534302}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:43 INFO 140016395286336] #progress_metric: host=algo-1, completed 30.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619672857.4156032, \"EndTime\": 1619672863.232573, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 543744.0, \"count\": 1, \"min\": 543744, \"max\": 543744}, \"Total Batches Seen\": {\"sum\": 8496.0, \"count\": 1, \"min\": 8496, \"max\": 8496}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:43 INFO 140016395286336] #throughput_metric: host=algo-1, train throughput=15578.857623139418 records/second\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:43 INFO 140016395286336] Epoch: 6, batches: 100, num_examples: 6400, 16396.9 samples/sec, epoch time so far: 0:00:00.390318\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:43 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.088 mean_absolute_error: 0.228 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:44 INFO 140016395286336] Epoch: 6, batches: 200, num_examples: 12800, 16363.4 samples/sec, epoch time so far: 0:00:00.782236\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:44 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.087 mean_absolute_error: 0.227 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:44 INFO 140016395286336] Epoch: 6, batches: 300, num_examples: 19200, 16374.1 samples/sec, epoch time so far: 0:00:01.172587\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:44 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.085 mean_absolute_error: 0.224 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:44 INFO 140016395286336] Epoch: 6, batches: 400, num_examples: 25600, 16095.7 samples/sec, epoch time so far: 0:00:01.590489\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:44 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.084 mean_absolute_error: 0.224 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:45 INFO 140016395286336] Epoch: 6, batches: 500, num_examples: 32000, 16117.4 samples/sec, epoch time so far: 0:00:01.985436\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:45 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.082 mean_absolute_error: 0.222 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:45 INFO 140016395286336] Epoch: 6, batches: 600, num_examples: 38400, 16111.4 samples/sec, epoch time so far: 0:00:02.383399\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:45 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.081 mean_absolute_error: 0.221 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:46 INFO 140016395286336] Epoch: 6, batches: 700, num_examples: 44800, 16110.3 samples/sec, epoch time so far: 0:00:02.780824\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:46 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.081 mean_absolute_error: 0.220 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:46 INFO 140016395286336] Epoch: 6, batches: 800, num_examples: 51200, 16145.8 samples/sec, epoch time so far: 0:00:03.171101\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:46 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.081 mean_absolute_error: 0.220 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:46 INFO 140016395286336] Epoch: 6, batches: 900, num_examples: 57600, 16159.5 samples/sec, epoch time so far: 0:00:03.564456\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:46 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.081 mean_absolute_error: 0.220 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:47 INFO 140016395286336] Epoch: 6, batches: 1000, num_examples: 64000, 16188.5 samples/sec, epoch time so far: 0:00:03.953431\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:47 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.081 mean_absolute_error: 0.220 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:47 INFO 140016395286336] Epoch: 6, batches: 1100, num_examples: 70400, 16205.8 samples/sec, epoch time so far: 0:00:04.344125\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:47 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.081 mean_absolute_error: 0.220 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:47 INFO 140016395286336] Epoch: 6, batches: 1200, num_examples: 76800, 16205.9 samples/sec, epoch time so far: 0:00:04.739010\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:47 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.081 mean_absolute_error: 0.220 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:48 INFO 140016395286336] Epoch: 6, batches: 1300, num_examples: 83200, 16193.0 samples/sec, epoch time so far: 0:00:05.138021\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:48 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.081 mean_absolute_error: 0.220 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:48 INFO 140016395286336] Epoch: 6, batches: 1400, num_examples: 89600, 16202.5 samples/sec, epoch time so far: 0:00:05.530015\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:48 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.081 mean_absolute_error: 0.220 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:48 INFO 140016395286336] **************\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:48 INFO 140016395286336] Completed Epoch: 6, time taken: 0:00:05.592452\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:48 INFO 140016395286336] Epoch 6 Training metrics:   mean_squared_error: 0.081 mean_absolute_error: 0.220 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:48 INFO 140016395286336] #quality_metric: host=algo-1, epoch=6, train mean_squared_error <loss>=0.08106670974843246\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:49 INFO 140016395286336] Epoch 6 Validation metrics: mean_squared_error: 0.932 mean_absolute_error: 0.764 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:49 INFO 140016395286336] #quality_metric: host=algo-1, epoch=6, validation mean_squared_error <loss>=0.931675103870598\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:49 INFO 140016395286336] **************\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:49 INFO 140016395286336] patience losses: [0.9517564693012753, 0.953693272696959, 0.9372927490118388]\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:49 INFO 140016395286336] min patience losses: 0.9372927490118388\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:49 INFO 140016395286336] current loss: 0.931675103870598\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:49 INFO 140016395286336] absolute loss difference: 0.005617645141240746\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:49 INFO 140016395286336] Bad epoch: loss has not improved (enough). Bad count:1\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619672863.2323658, \"EndTime\": 1619672869.0579398, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 3.009319305419922, \"count\": 1, \"min\": 3.009319305419922, \"max\": 3.009319305419922}, \"update.time\": {\"sum\": 5799.183368682861, \"count\": 1, \"min\": 5799.183368682861, \"max\": 5799.183368682861}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:49 INFO 140016395286336] #progress_metric: host=algo-1, completed 35.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619672863.2587306, \"EndTime\": 1619672869.0582786, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 634368.0, \"count\": 1, \"min\": 634368, \"max\": 634368}, \"Total Batches Seen\": {\"sum\": 9912.0, \"count\": 1, \"min\": 9912, \"max\": 9912}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 7.0, \"count\": 1, \"min\": 7, \"max\": 7}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:49 INFO 140016395286336] #throughput_metric: host=algo-1, train throughput=15625.59720921418 records/second\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:49 INFO 140016395286336] Epoch: 7, batches: 100, num_examples: 6400, 16426.0 samples/sec, epoch time so far: 0:00:00.389626\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:49 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.081 mean_absolute_error: 0.217 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:49 INFO 140016395286336] Epoch: 7, batches: 200, num_examples: 12800, 15751.7 samples/sec, epoch time so far: 0:00:00.812609\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:49 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.080 mean_absolute_error: 0.216 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:50 INFO 140016395286336] Epoch: 7, batches: 300, num_examples: 19200, 15910.7 samples/sec, epoch time so far: 0:00:01.206737\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:50 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.078 mean_absolute_error: 0.215 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:50 INFO 140016395286336] Epoch: 7, batches: 400, num_examples: 25600, 16006.1 samples/sec, epoch time so far: 0:00:01.599385\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:50 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.078 mean_absolute_error: 0.215 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:51 INFO 140016395286336] Epoch: 7, batches: 500, num_examples: 32000, 15980.3 samples/sec, epoch time so far: 0:00:02.002468\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:51 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.077 mean_absolute_error: 0.214 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:51 INFO 140016395286336] Epoch: 7, batches: 600, num_examples: 38400, 16038.7 samples/sec, epoch time so far: 0:00:02.394214\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:51 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.078 mean_absolute_error: 0.214 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:51 INFO 140016395286336] Epoch: 7, batches: 700, num_examples: 44800, 16080.3 samples/sec, epoch time so far: 0:00:02.786010\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:51 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.077 mean_absolute_error: 0.214 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:52 INFO 140016395286336] Epoch: 7, batches: 800, num_examples: 51200, 16126.3 samples/sec, epoch time so far: 0:00:03.174930\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:52 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.077 mean_absolute_error: 0.214 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:52 INFO 140016395286336] Epoch: 7, batches: 900, num_examples: 57600, 16152.6 samples/sec, epoch time so far: 0:00:03.565989\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:52 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.077 mean_absolute_error: 0.214 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:53 INFO 140016395286336] Epoch: 7, batches: 1000, num_examples: 64000, 16175.1 samples/sec, epoch time so far: 0:00:03.956710\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:53 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.077 mean_absolute_error: 0.214 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:53 INFO 140016395286336] Epoch: 7, batches: 1100, num_examples: 70400, 16195.4 samples/sec, epoch time so far: 0:00:04.346921\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:53 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.077 mean_absolute_error: 0.213 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:53 INFO 140016395286336] Epoch: 7, batches: 1200, num_examples: 76800, 16164.4 samples/sec, epoch time so far: 0:00:04.751169\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:53 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.076 mean_absolute_error: 0.213 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:54 INFO 140016395286336] Epoch: 7, batches: 1300, num_examples: 83200, 16172.2 samples/sec, epoch time so far: 0:00:05.144628\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:54 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.076 mean_absolute_error: 0.213 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:54 INFO 140016395286336] Epoch: 7, batches: 1400, num_examples: 89600, 16193.6 samples/sec, epoch time so far: 0:00:05.533063\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:54 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.077 mean_absolute_error: 0.213 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:54 INFO 140016395286336] **************\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:54 INFO 140016395286336] Completed Epoch: 7, time taken: 0:00:05.601933\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:54 INFO 140016395286336] Epoch 7 Training metrics:   mean_squared_error: 0.077 mean_absolute_error: 0.213 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:54 INFO 140016395286336] #quality_metric: host=algo-1, epoch=7, train mean_squared_error <loss>=0.07670174245748901\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:54 INFO 140016395286336] Epoch 7 Validation metrics: mean_squared_error: 0.938 mean_absolute_error: 0.759 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:54 INFO 140016395286336] #quality_metric: host=algo-1, epoch=7, validation mean_squared_error <loss>=0.9381044563409444\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:54 INFO 140016395286336] **************\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:54 INFO 140016395286336] patience losses: [0.953693272696959, 0.9372927490118388, 0.931675103870598]\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:54 INFO 140016395286336] min patience losses: 0.931675103870598\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:54 INFO 140016395286336] current loss: 0.9381044563409444\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:54 INFO 140016395286336] absolute loss difference: 0.006429352470346372\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:54 INFO 140016395286336] Bad epoch: loss has not improved (enough). Bad count:2\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619672869.0580485, \"EndTime\": 1619672874.9136267, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 0.5044937133789062, \"count\": 1, \"min\": 0.5044937133789062, \"max\": 0.5044937133789062}, \"update.time\": {\"sum\": 5826.847076416016, \"count\": 1, \"min\": 5826.847076416016, \"max\": 5826.847076416016}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:54 INFO 140016395286336] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619672869.0867512, \"EndTime\": 1619672874.913907, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 724992.0, \"count\": 1, \"min\": 724992, \"max\": 724992}, \"Total Batches Seen\": {\"sum\": 11328.0, \"count\": 1, \"min\": 11328, \"max\": 11328}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 8.0, \"count\": 1, \"min\": 8, \"max\": 8}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:54 INFO 140016395286336] #throughput_metric: host=algo-1, train throughput=15551.628128377073 records/second\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:55 INFO 140016395286336] Epoch: 8, batches: 100, num_examples: 6400, 16480.6 samples/sec, epoch time so far: 0:00:00.388335\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:55 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.069 mean_absolute_error: 0.202 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:55 INFO 140016395286336] Epoch: 8, batches: 200, num_examples: 12800, 16429.2 samples/sec, epoch time so far: 0:00:00.779100\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:55 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.070 mean_absolute_error: 0.201 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:56 INFO 140016395286336] Epoch: 8, batches: 300, num_examples: 19200, 16282.5 samples/sec, epoch time so far: 0:00:01.179178\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:56 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.068 mean_absolute_error: 0.199 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:56 INFO 140016395286336] Epoch: 8, batches: 400, num_examples: 25600, 16330.0 samples/sec, epoch time so far: 0:00:01.567668\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:56 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.069 mean_absolute_error: 0.200 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:56 INFO 140016395286336] Epoch: 8, batches: 500, num_examples: 32000, 16327.7 samples/sec, epoch time so far: 0:00:01.959857\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:56 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.068 mean_absolute_error: 0.199 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:57 INFO 140016395286336] Epoch: 8, batches: 600, num_examples: 38400, 16331.9 samples/sec, epoch time so far: 0:00:02.351231\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:57 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.067 mean_absolute_error: 0.198 \u001b[0m\n",
      "\n",
      "2021-04-29 05:08:10 Uploading - Uploading generated training model\u001b[34m[04/29/2021 05:07:57 INFO 140016395286336] Epoch: 8, batches: 700, num_examples: 44800, 16345.5 samples/sec, epoch time so far: 0:00:02.740815\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:57 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.067 mean_absolute_error: 0.198 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:58 INFO 140016395286336] Epoch: 8, batches: 800, num_examples: 51200, 16321.8 samples/sec, epoch time so far: 0:00:03.136909\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:58 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.067 mean_absolute_error: 0.198 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:58 INFO 140016395286336] Epoch: 8, batches: 900, num_examples: 57600, 16327.4 samples/sec, epoch time so far: 0:00:03.527807\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:58 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.067 mean_absolute_error: 0.198 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:58 INFO 140016395286336] Epoch: 8, batches: 1000, num_examples: 64000, 16334.9 samples/sec, epoch time so far: 0:00:03.917984\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:58 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.067 mean_absolute_error: 0.198 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:59 INFO 140016395286336] Epoch: 8, batches: 1100, num_examples: 70400, 16314.7 samples/sec, epoch time so far: 0:00:04.315137\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:59 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.067 mean_absolute_error: 0.198 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:59 INFO 140016395286336] Epoch: 8, batches: 1200, num_examples: 76800, 16297.7 samples/sec, epoch time so far: 0:00:04.712324\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:07:59 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.066 mean_absolute_error: 0.197 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:00 INFO 140016395286336] Epoch: 8, batches: 1300, num_examples: 83200, 16212.4 samples/sec, epoch time so far: 0:00:05.131879\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:00 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.067 mean_absolute_error: 0.197 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:00 INFO 140016395286336] Epoch: 8, batches: 1400, num_examples: 89600, 16209.0 samples/sec, epoch time so far: 0:00:05.527783\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:00 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.067 mean_absolute_error: 0.198 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:00 INFO 140016395286336] **************\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:00 INFO 140016395286336] Completed Epoch: 8, time taken: 0:00:05.592086\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:00 INFO 140016395286336] Epoch 8 Training metrics:   mean_squared_error: 0.067 mean_absolute_error: 0.198 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:00 INFO 140016395286336] #quality_metric: host=algo-1, epoch=8, train mean_squared_error <loss>=0.06667102151155724\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:00 INFO 140016395286336] Epoch 8 Validation metrics: mean_squared_error: 0.936 mean_absolute_error: 0.768 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:00 INFO 140016395286336] #quality_metric: host=algo-1, epoch=8, validation mean_squared_error <loss>=0.9357642885800954\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:00 INFO 140016395286336] **************\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:00 INFO 140016395286336] patience losses: [0.9372927490118388, 0.931675103870598, 0.9381044563409444]\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:00 INFO 140016395286336] min patience losses: 0.931675103870598\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:00 INFO 140016395286336] current loss: 0.9357642885800954\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:00 INFO 140016395286336] absolute loss difference: 0.004089184709497373\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:00 INFO 140016395286336] Bad epoch: loss has not improved (enough). Bad count:3\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619672874.9137232, \"EndTime\": 1619672880.7150111, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 0.553131103515625, \"count\": 1, \"min\": 0.553131103515625, \"max\": 0.553131103515625}, \"update.time\": {\"sum\": 5795.504570007324, \"count\": 1, \"min\": 5795.504570007324, \"max\": 5795.504570007324}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:00 INFO 140016395286336] #progress_metric: host=algo-1, completed 45.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619672874.9194875, \"EndTime\": 1619672880.7152987, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 815616.0, \"count\": 1, \"min\": 815616, \"max\": 815616}, \"Total Batches Seen\": {\"sum\": 12744.0, \"count\": 1, \"min\": 12744, \"max\": 12744}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:00 INFO 140016395286336] #throughput_metric: host=algo-1, train throughput=15635.765118359375 records/second\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:01 INFO 140016395286336] Epoch: 9, batches: 100, num_examples: 6400, 16252.3 samples/sec, epoch time so far: 0:00:00.393791\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:01 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.062 mean_absolute_error: 0.189 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:01 INFO 140016395286336] Epoch: 9, batches: 200, num_examples: 12800, 12270.5 samples/sec, epoch time so far: 0:00:01.043149\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:01 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.060 mean_absolute_error: 0.186 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:02 INFO 140016395286336] Epoch: 9, batches: 300, num_examples: 19200, 12548.8 samples/sec, epoch time so far: 0:00:01.530026\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:02 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.060 mean_absolute_error: 0.186 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:02 INFO 140016395286336] Epoch: 9, batches: 400, num_examples: 25600, 13182.6 samples/sec, epoch time so far: 0:00:01.941948\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:02 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.059 mean_absolute_error: 0.185 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:03 INFO 140016395286336] Epoch: 9, batches: 500, num_examples: 32000, 13197.7 samples/sec, epoch time so far: 0:00:02.424659\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:03 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.059 mean_absolute_error: 0.185 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:03 INFO 140016395286336] Epoch: 9, batches: 600, num_examples: 38400, 13325.6 samples/sec, epoch time so far: 0:00:02.881678\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:03 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.059 mean_absolute_error: 0.184 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:04 INFO 140016395286336] Epoch: 9, batches: 700, num_examples: 44800, 13525.2 samples/sec, epoch time so far: 0:00:03.312329\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:04 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.058 mean_absolute_error: 0.184 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:04 INFO 140016395286336] Epoch: 9, batches: 800, num_examples: 51200, 13717.2 samples/sec, epoch time so far: 0:00:03.732544\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:04 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.059 mean_absolute_error: 0.184 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:04 INFO 140016395286336] Epoch: 9, batches: 900, num_examples: 57600, 13593.5 samples/sec, epoch time so far: 0:00:04.237319\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:04 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.059 mean_absolute_error: 0.184 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:05 INFO 140016395286336] Epoch: 9, batches: 1000, num_examples: 64000, 13733.8 samples/sec, epoch time so far: 0:00:04.660028\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:05 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.058 mean_absolute_error: 0.184 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:05 INFO 140016395286336] Epoch: 9, batches: 1100, num_examples: 70400, 13780.3 samples/sec, epoch time so far: 0:00:05.108727\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:05 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.058 mean_absolute_error: 0.183 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:06 INFO 140016395286336] Epoch: 9, batches: 1200, num_examples: 76800, 13861.2 samples/sec, epoch time so far: 0:00:05.540647\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:06 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.058 mean_absolute_error: 0.183 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:06 INFO 140016395286336] Epoch: 9, batches: 1300, num_examples: 83200, 14013.7 samples/sec, epoch time so far: 0:00:05.937036\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:06 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.058 mean_absolute_error: 0.183 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:07 INFO 140016395286336] Epoch: 9, batches: 1400, num_examples: 89600, 14145.1 samples/sec, epoch time so far: 0:00:06.334370\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:07 INFO 140016395286336] #011Training metrics: mean_squared_error: 0.058 mean_absolute_error: 0.183 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:07 INFO 140016395286336] **************\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:07 INFO 140016395286336] Completed Epoch: 9, time taken: 0:00:06.400239\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:07 INFO 140016395286336] Epoch 9 Training metrics:   mean_squared_error: 0.058 mean_absolute_error: 0.183 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:07 INFO 140016395286336] #quality_metric: host=algo-1, epoch=9, train mean_squared_error <loss>=0.05774785155867158\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:07 INFO 140016395286336] Epoch 9 Validation metrics: mean_squared_error: 0.925 mean_absolute_error: 0.752 \u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:07 INFO 140016395286336] #quality_metric: host=algo-1, epoch=9, validation mean_squared_error <loss>=0.9253534151090158\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:07 INFO 140016395286336] **************\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:07 INFO 140016395286336] patience losses: [0.931675103870598, 0.9381044563409444, 0.9357642885800954]\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:07 INFO 140016395286336] min patience losses: 0.931675103870598\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:07 INFO 140016395286336] current loss: 0.9253534151090158\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:07 INFO 140016395286336] absolute loss difference: 0.006321688761582234\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:07 INFO 140016395286336] Bad epoch: loss has not improved (enough). Bad count:4\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:07 INFO 140016395286336] Bad epochs exceeded patience. Stopping training early!\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:07 INFO 140016395286336] Early stopping criterion met! Stopping training at epoch: 9\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619672880.7151136, \"EndTime\": 1619672887.3284068, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 4.156351089477539, \"count\": 1, \"min\": 4.156351089477539, \"max\": 4.156351089477539}, \"update.time\": {\"sum\": 6607.446193695068, \"count\": 1, \"min\": 6607.446193695068, \"max\": 6607.446193695068}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:07 INFO 140016395286336] Early stop condition met. Stopping training.\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:07 INFO 140016395286336] #progress_metric: host=algo-1, completed 100 % epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619672880.7209363, \"EndTime\": 1619672887.3288493, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 906240.0, \"count\": 1, \"min\": 906240, \"max\": 906240}, \"Total Batches Seen\": {\"sum\": 14160.0, \"count\": 1, \"min\": 14160, \"max\": 14160}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:07 INFO 140016395286336] #throughput_metric: host=algo-1, train throughput=13714.155495929028 records/second\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:07 WARNING 140016395286336] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:07 INFO 140016395286336] Best model based on epoch 9. Best loss: 0.925\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619672887.3285136, \"EndTime\": 1619672887.3311257, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 1.8613338470458984, \"count\": 1, \"min\": 1.8613338470458984, \"max\": 1.8613338470458984}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:07 INFO 140016395286336] Serializing model to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:07 INFO 140016395286336] Saved checkpoint to \"/tmp/tmplv_j9p90/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[04/29/2021 05:08:07 INFO 140016395286336] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619672887.3312154, \"EndTime\": 1619672887.4166746, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.serialize.time\": {\"sum\": 83.15205574035645, \"count\": 1, \"min\": 83.15205574035645, \"max\": 83.15205574035645}, \"setuptime\": {\"sum\": 10.378599166870117, \"count\": 1, \"min\": 10.378599166870117, \"max\": 10.378599166870117}, \"totaltime\": {\"sum\": 69817.15846061707, \"count\": 1, \"min\": 69817.15846061707, \"max\": 69817.15846061707}}}\n",
      "\u001b[0m\n",
      "\n",
      "2021-04-29 05:08:26 Completed - Training job completed\n",
      "ProfilerReport-1619672558: NoIssuesFound\n",
      "Training seconds: 159\n",
      "Billable seconds: 159\n"
     ]
    }
   ],
   "source": [
    "# begin training\n",
    "regressor = sagemaker.estimator.Estimator(container,\n",
    "                                         role,\n",
    "                                         instance_count=1,\n",
    "                                         instance_type='ml.p2.xlarge',\n",
    "                                         output_path=output_path + \"output-1\",\n",
    "                                         tags=[{\"Key\": tagKey,\"Value\": tagVal}],\n",
    "                                         sagemaker_session=sess)\n",
    "\n",
    "regressor.set_hyperparameters(**hyperparameters)\n",
    "\n",
    "regressor.fit(input_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 17:23:58 Starting - Starting the training job...\n",
      "2021-04-28 17:24:22 Starting - Launching requested ML instancesProfilerReport-1619630638: InProgress\n",
      "......\n",
      "2021-04-28 17:25:22 Starting - Preparing the instances for training.........\n",
      "2021-04-28 17:26:43 Downloading - Downloading input data\n",
      "2021-04-28 17:26:43 Training - Downloading the training image......\n",
      "2021-04-28 17:27:45 Training - Training image download completed. Training in progress.\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:49 INFO 140508977309504] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/default-input.json: {'enc_dim': 4096, 'mlp_dim': 512, 'mlp_activation': 'linear', 'mlp_layers': 2, 'output_layer': 'softmax', 'optimizer': 'adam', 'learning_rate': 0.0004, 'mini_batch_size': 32, 'epochs': 30, 'bucket_width': 0, 'early_stopping_tolerance': 0.01, 'early_stopping_patience': 3, 'dropout': 0, 'weight_decay': 0, 'negative_sampling_rate': 0, 'comparator_list': 'hadamard, concat, abs_diff', 'tied_token_embedding_weight': 'false', 'token_embedding_storage_type': 'dense', 'enc0_network': 'hcnn', 'enc1_network': 'enc0', 'enc0_token_embedding_dim': 300, 'enc0_layers': 'auto', 'enc0_cnn_filter_width': 3, 'enc1_token_embedding_dim': 300, 'enc1_layers': 'auto', 'enc1_cnn_filter_width': 3, 'enc0_pretrained_embedding_file': '', 'enc0_freeze_pretrained_embedding': 'true', 'enc1_pretrained_embedding_file': '', 'enc1_freeze_pretrained_embedding': 'true', 'enc0_vocab_file': '', 'enc1_vocab_file': '', 'num_classes': 2, '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', '_kvstore': 'auto_gpu'}\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:49 INFO 140508977309504] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'enc0_network': 'bilstm', 'num_classes': '2', 'enc0_layers': 'auto', 'enc_dim': '1024', 'enc1_network': 'pooled_embedding', 'enc0_token_embedding_dim': '300', 'enc1_layers': 'auto', 'mlp_activation': 'tanh', 'mlp_dim': '256', 'optimizer': 'adam', 'enc1_vocab_size': '1684', '_num_kv_servers': 'auto', 'mlp_layers': '1', '_kvstore': 'device', 'enc0_vocab_size': '944', 'enc0_max_seq_len': '1', 'enc1_token_embedding_dim': '300', 'early_stopping_patience': '3', 'enc1_max_seq_len': '1', 'output_layer': 'mean_squared_error', '_num_gpus': 'auto', 'enc0_cnn_filter_width': '3', 'early_stopping_tolerance': '0.01', 'bucket_width': '0', 'epochs': '20', 'learning_rate': '0.001', 'mini_batch_size': '64'}\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:49 INFO 140508977309504] Final configuration: {'enc_dim': '1024', 'mlp_dim': '256', 'mlp_activation': 'tanh', 'mlp_layers': '1', 'output_layer': 'mean_squared_error', 'optimizer': 'adam', 'learning_rate': '0.001', 'mini_batch_size': '64', 'epochs': '20', 'bucket_width': '0', 'early_stopping_tolerance': '0.01', 'early_stopping_patience': '3', 'dropout': 0, 'weight_decay': 0, 'negative_sampling_rate': 0, 'comparator_list': 'hadamard, concat, abs_diff', 'tied_token_embedding_weight': 'false', 'token_embedding_storage_type': 'dense', 'enc0_network': 'bilstm', 'enc1_network': 'pooled_embedding', 'enc0_token_embedding_dim': '300', 'enc0_layers': 'auto', 'enc0_cnn_filter_width': '3', 'enc1_token_embedding_dim': '300', 'enc1_layers': 'auto', 'enc1_cnn_filter_width': 3, 'enc0_pretrained_embedding_file': '', 'enc0_freeze_pretrained_embedding': 'true', 'enc1_pretrained_embedding_file': '', 'enc1_freeze_pretrained_embedding': 'true', 'enc0_vocab_file': '', 'enc1_vocab_file': '', 'num_classes': '2', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', '_kvstore': 'device', 'enc1_vocab_size': '1684', 'enc0_vocab_size': '944', 'enc0_max_seq_len': '1', 'enc1_max_seq_len': '1'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:49 INFO 140508977309504] Using default worker.\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:49 INFO 140508977309504] Loaded iterator creator application/jsonlines for content type ('application/jsonlines', '1.0')\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:49 INFO 140508977309504] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:49 INFO 140508977309504] create_iter params {'enc_dim': '1024', 'mlp_dim': '256', 'mlp_activation': 'tanh', 'mlp_layers': '1', 'output_layer': 'mean_squared_error', 'optimizer': 'adam', 'learning_rate': '0.001', 'mini_batch_size': '64', 'epochs': '20', 'bucket_width': '0', 'early_stopping_tolerance': '0.01', 'early_stopping_patience': '3', 'dropout': 0, 'weight_decay': 0, 'negative_sampling_rate': 0, 'comparator_list': 'hadamard, concat, abs_diff', 'tied_token_embedding_weight': 'false', 'token_embedding_storage_type': 'dense', 'enc0_network': 'bilstm', 'enc1_network': 'pooled_embedding', 'enc0_token_embedding_dim': '300', 'enc0_layers': 'auto', 'enc0_cnn_filter_width': '3', 'enc1_token_embedding_dim': '300', 'enc1_layers': 'auto', 'enc1_cnn_filter_width': 3, 'enc0_pretrained_embedding_file': '', 'enc0_freeze_pretrained_embedding': 'true', 'enc1_pretrained_embedding_file': '', 'enc1_freeze_pretrained_embedding': 'true', 'enc0_vocab_file': '', 'enc1_vocab_file': '', 'num_classes': '2', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', '_kvstore': 'device', 'enc1_vocab_size': '1684', 'enc0_vocab_size': '944', 'enc0_max_seq_len': '1', 'enc1_max_seq_len': '1'}\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:49 INFO 140508977309504] create_iter content_params {}\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:49 INFO 140508977309504] Parameters of encoders: [{'network': 'bilstm', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': '3', 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'vocab_size': '944', 'max_seq_len': '1'}, {'network': 'pooled_embedding', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': 3, 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'vocab_size': '1684', 'max_seq_len': '1'}]\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:49 WARNING 140508977309504] Cannot use network \"bilstm\" with enc0. Modifying network to \"pooled_embedding\"\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:49 INFO 140508977309504] output_layer is set to mean_squared_error. Ignoring the hyperparameter 'num_classes'.\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:49 INFO 140508977309504] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:49 INFO 140508977309504] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:49 INFO 140508977309504] Encoder configs: [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 1024, 'vocab_size': 944, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 1024, 'vocab_size': 1684, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:49 INFO 140508977309504] Config: {'enc_dim': 1024, 'max_seq_lens': [1, 1], 'dropout': 0.0, 'weight_decay': 0.0, 'mlp_activation': 'tanh', 'mlp_dim': 256, 'mlp_layers': 1, 'output_layer': 'mean_squared_error', 'learning_rate': 0.001, 'optimizer': 'adam', 'num_classes': None, 'epochs': 20, 'mini_batch_size': 64, 'bucket_width': 0, 'comparator_list': ['hadamard', 'concat', 'abs_diff'], 'tied_token_embedding_weight': False, 'negative_sampling_rate': 0, 'token_embedding_storage_type': 'dense', 'early_stopping_patience': 3, 'early_stopping_tolerance': 0.01, 'enc_configs': [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 1024, 'vocab_size': 944, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 1024, 'vocab_size': 1684, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]}\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:49 INFO 140508977309504] use bucketing: False\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:49 INFO 140508977309504] Creating data iterator for /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] Source words: 90570\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] Target words: 90570\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] Total: 90570 samples in 1 buckets\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] Bucket of (1, 1) : 90570 samples in 1416 batches of 64, approx 64.0 words/batch\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] 0 sentence pairs discarded\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] fill up mode: replicate\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] Negative sampling not used\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] Replicating 54 random sentences from bucket (1, 1) to size it to multiple of 64\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] Bucket batch sizes: [BucketBatchSize(batch_size=64, average_words_per_batch=64.0)]\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] create_iter params {'enc_dim': '1024', 'mlp_dim': '256', 'mlp_activation': 'tanh', 'mlp_layers': '1', 'output_layer': 'mean_squared_error', 'optimizer': 'adam', 'learning_rate': '0.001', 'mini_batch_size': '64', 'epochs': '20', 'bucket_width': '0', 'early_stopping_tolerance': '0.01', 'early_stopping_patience': '3', 'dropout': 0, 'weight_decay': 0, 'negative_sampling_rate': 0, 'comparator_list': 'hadamard, concat, abs_diff', 'tied_token_embedding_weight': 'false', 'token_embedding_storage_type': 'dense', 'enc0_network': 'bilstm', 'enc1_network': 'pooled_embedding', 'enc0_token_embedding_dim': '300', 'enc0_layers': 'auto', 'enc0_cnn_filter_width': '3', 'enc1_token_embedding_dim': '300', 'enc1_layers': 'auto', 'enc1_cnn_filter_width': 3, 'enc0_pretrained_embedding_file': '', 'enc0_freeze_pretrained_embedding': 'true', 'enc1_pretrained_embedding_file': '', 'enc1_freeze_pretrained_embedding': 'true', 'enc0_vocab_file': '', 'enc1_vocab_file': '', 'num_classes': '2', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', '_kvstore': 'device', 'enc1_vocab_size': '1684', 'enc0_vocab_size': '944', 'enc0_max_seq_len': '1', 'enc1_max_seq_len': '1'}\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] create_iter content_params {}\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] Parameters of encoders: [{'network': 'bilstm', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': '3', 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'vocab_size': '944', 'max_seq_len': '1'}, {'network': 'pooled_embedding', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': 3, 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'vocab_size': '1684', 'max_seq_len': '1'}]\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 WARNING 140508977309504] Cannot use network \"bilstm\" with enc0. Modifying network to \"pooled_embedding\"\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] output_layer is set to mean_squared_error. Ignoring the hyperparameter 'num_classes'.\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] Encoder configs: [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 1024, 'vocab_size': 944, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 1024, 'vocab_size': 1684, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] Config: {'enc_dim': 1024, 'max_seq_lens': [1, 1], 'dropout': 0.0, 'weight_decay': 0.0, 'mlp_activation': 'tanh', 'mlp_dim': 256, 'mlp_layers': 1, 'output_layer': 'mean_squared_error', 'learning_rate': 0.001, 'optimizer': 'adam', 'num_classes': None, 'epochs': 20, 'mini_batch_size': 64, 'bucket_width': 0, 'comparator_list': ['hadamard', 'concat', 'abs_diff'], 'tied_token_embedding_weight': False, 'negative_sampling_rate': 0, 'token_embedding_storage_type': 'dense', 'early_stopping_patience': 3, 'early_stopping_tolerance': 0.01, 'enc_configs': [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 1024, 'vocab_size': 944, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 1024, 'vocab_size': 1684, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]}\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] use bucketing: False\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] Creating data iterator for /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] Source words: 9430\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] Target words: 9430\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] Total: 9430 samples in 1 buckets\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] Bucket of (1, 1) : 9430 samples in 148 batches of 64, approx 64.0 words/batch\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] 0 sentence pairs discarded\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] fill up mode: replicate\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] Negative sampling not used\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] Replicating 42 random sentences from bucket (1, 1) to size it to multiple of 64\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] Parameters of encoders: [{'network': 'bilstm', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': '3', 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'vocab_size': '944', 'max_seq_len': '1'}, {'network': 'pooled_embedding', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': 3, 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'vocab_size': '1684', 'max_seq_len': '1'}]\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 WARNING 140508977309504] Cannot use network \"bilstm\" with enc0. Modifying network to \"pooled_embedding\"\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] output_layer is set to mean_squared_error. Ignoring the hyperparameter 'num_classes'.\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] Encoder configs: [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 1024, 'vocab_size': 944, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 1024, 'vocab_size': 1684, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] Config: {'enc_dim': 1024, 'max_seq_lens': [1, 1], 'dropout': 0.0, 'weight_decay': 0.0, 'mlp_activation': 'tanh', 'mlp_dim': 256, 'mlp_layers': 1, 'output_layer': 'mean_squared_error', 'learning_rate': 0.001, 'optimizer': 'adam', 'num_classes': None, 'epochs': 20, 'mini_batch_size': 64, 'bucket_width': 0, 'comparator_list': ['hadamard', 'concat', 'abs_diff'], 'tied_token_embedding_weight': False, 'negative_sampling_rate': 0, 'token_embedding_storage_type': 'dense', 'early_stopping_patience': 3, 'early_stopping_tolerance': 0.01, 'enc_configs': [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 1024, 'vocab_size': 944, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 1024, 'vocab_size': 1684, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]}\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] Creating new state\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] params {'enc_dim': '1024', 'mlp_dim': '256', 'mlp_activation': 'tanh', 'mlp_layers': '1', 'output_layer': 'mean_squared_error', 'optimizer': 'adam', 'learning_rate': '0.001', 'mini_batch_size': '64', 'epochs': '20', 'bucket_width': '0', 'early_stopping_tolerance': '0.01', 'early_stopping_patience': '3', 'dropout': 0, 'weight_decay': 0, 'negative_sampling_rate': 0, 'comparator_list': 'hadamard, concat, abs_diff', 'tied_token_embedding_weight': 'false', 'token_embedding_storage_type': 'dense', 'enc0_network': 'bilstm', 'enc1_network': 'pooled_embedding', 'enc0_token_embedding_dim': '300', 'enc0_layers': 'auto', 'enc0_cnn_filter_width': '3', 'enc1_token_embedding_dim': '300', 'enc1_layers': 'auto', 'enc1_cnn_filter_width': 3, 'enc0_pretrained_embedding_file': '', 'enc0_freeze_pretrained_embedding': 'true', 'enc1_pretrained_embedding_file': '', 'enc1_freeze_pretrained_embedding': 'true', 'enc0_vocab_file': '', 'enc1_vocab_file': '', 'num_classes': '2', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', '_kvstore': 'device', 'enc1_vocab_size': '1684', 'enc0_vocab_size': '944', 'enc0_max_seq_len': '1', 'enc1_max_seq_len': '1', 'default_bucket_key': (1, 1)}\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:52 INFO 140508977309504] default_bucket_key (1, 1)\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:53 INFO 140508977309504] nvidia-smi: took 0.032 seconds to run.\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:53 INFO 140508977309504] nvidia-smi identified 1 GPUs.\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:53 INFO 140508977309504] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:53 INFO 140508977309504] context [gpu(0)]\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:53 INFO 140508977309504] Create Store: device\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:53 INFO 140508977309504] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:53 WARNING 140508977309504] dense token embedding is used in a multi-gpu setting...consider changing 'token_embedding_storage_type' to 'row_sparse'\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:53 INFO 140508977309504] data_names: ['source', 'target']\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:53 INFO 140508977309504] label_names: ['out_layer_label']\u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mLayer (type)                                        Output Shape            Param #     Previous Layer                  \u001b[0m\n",
      "\u001b[34m========================================================================================================================\u001b[0m\n",
      "\u001b[34msource(null)                                        1                       0                                           \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34membed_0(Embedding)                                  1x1024                  0           source                          \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_not_equal_scalar0(_not_equal_scalar)               1                       0           source                          \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mreshape0(Reshape)                                   1x1                     0           _not_equal_scalar0              \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbroadcast_mul0(broadcast_mul)                       1x1024                  0           embed_0                         \n",
      "                                                                                        reshape0                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34msum0(sum)                                           1024                    0           broadcast_mul0                  \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34msum1(sum)                                           1                       0           reshape0                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mzeros_like0(zeros_like)                             1                       0           sum1                            \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_equal0(_equal)                                     1                       0           sum1                            \n",
      "                                                                                        zeros_like0                     \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_plus0(elemwise_add)                                1                       0           sum1                            \n",
      "                                                                                        _equal0                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbroadcast_div0(broadcast_div)                       1024                    0           sum0                            \n",
      "                                                                                        _plus0                          \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout0(Dropout)                                   1024                    0           broadcast_div0                  \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34membed_1(Embedding)                                  1x1024                  0                                           \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_not_equal_scalar1(_not_equal_scalar)               1                       0                                           \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mreshape1(Reshape)                                   1x1                     0           _not_equal_scalar1              \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbroadcast_mul1(broadcast_mul)                       1x1024                  0           embed_1                         \n",
      "                                                                                        reshape1                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34msum2(sum)                                           1024                    0           broadcast_mul1                  \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34msum3(sum)                                           1                       0           reshape1                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mzeros_like1(zeros_like)                             1                       0           sum3                            \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_equal1(_equal)                                     1                       0           sum3                            \n",
      "                                                                                        zeros_like1                     \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_plus1(elemwise_add)                                1                       0           sum3                            \n",
      "                                                                                        _equal1                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbroadcast_div1(broadcast_div)                       1024                    0           sum2                            \n",
      "                                                                                        _plus1                          \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout1(Dropout)                                   1024                    0           broadcast_div1                  \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_mul0(elemwise_mul)                                 1024                    0           dropout0                        \n",
      "                                                                                        dropout1                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_minus0(elemwise_sub)                               1024                    0           dropout0                        \n",
      "                                                                                        dropout1                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mabs0(abs)                                           1024                    0           _minus0                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconcat0(Concat)                                     4096                    0           _mul0                           \n",
      "                                                                                        dropout0                        \n",
      "                                                                                        dropout1                        \n",
      "                                                                                        abs0                            \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mmlp_fc0(FullyConnected)                             256                     1048832     concat0                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation0(Activation)                             256                     0           mlp_fc0                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout2(Dropout)                                   256                     0           activation0                     \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34moutput_layer(FullyConnected)                        1                       257         dropout2                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mout_layer(LinearRegressionOutput)                   1                       0           output_layer                    \u001b[0m\n",
      "\u001b[34m========================================================================================================================\u001b[0m\n",
      "\u001b[34mTotal params: 1049089\u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:53 INFO 140508977309504] data_shapes [DataDesc[source,(64, 1),<class 'numpy.float32'>,NTC], DataDesc[target,(64, 1),<class 'numpy.float32'>,NTC]]\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:53 INFO 140508977309504] label_shapes [DataDesc[out_layer_label,(64,),<class 'numpy.float32'>,NTC]]\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:53 INFO 140508977309504] fixed_param_names: []\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:53 INFO 140508977309504] Initialized BucketingPlus Module\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:57 INFO 140508977309504] arg_params keys for module initialization: dict_keys([])\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:57 INFO 140508977309504] all params:dict_keys(['embed_0_weight', 'embed_1_weight', 'mlp_fc0_weight', 'mlp_fc0_bias', 'output_layer_weight', 'output_layer_bias'])\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619630869.972135, \"EndTime\": 1619630877.4022202, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 4422.200441360474, \"count\": 1, \"min\": 4422.200441360474, \"max\": 4422.200441360474}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619630877.4024081, \"EndTime\": 1619630877.4024627, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:57 INFO 140508977309504] Epoch: 0, batches: 100, num_examples: 6400, 14648.9 samples/sec, epoch time so far: 0:00:00.436892\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:57 INFO 140508977309504] #011Training metrics: mean_squared_error: 1.647 mean_absolute_error: 0.999 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:58 INFO 140508977309504] Epoch: 0, batches: 200, num_examples: 12800, 15410.2 samples/sec, epoch time so far: 0:00:00.830619\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:58 INFO 140508977309504] #011Training metrics: mean_squared_error: 1.364 mean_absolute_error: 0.914 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:58 INFO 140508977309504] Epoch: 0, batches: 300, num_examples: 19200, 15647.3 samples/sec, epoch time so far: 0:00:01.227049\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:58 INFO 140508977309504] #011Training metrics: mean_squared_error: 1.255 mean_absolute_error: 0.880 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:59 INFO 140508977309504] Epoch: 0, batches: 400, num_examples: 25600, 15774.2 samples/sec, epoch time so far: 0:00:01.622902\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:59 INFO 140508977309504] #011Training metrics: mean_squared_error: 1.207 mean_absolute_error: 0.867 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:59 INFO 140508977309504] Epoch: 0, batches: 500, num_examples: 32000, 15854.1 samples/sec, epoch time so far: 0:00:02.018406\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:59 INFO 140508977309504] #011Training metrics: mean_squared_error: 1.171 mean_absolute_error: 0.855 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:59 INFO 140508977309504] Epoch: 0, batches: 600, num_examples: 38400, 15937.7 samples/sec, epoch time so far: 0:00:02.409383\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:27:59 INFO 140508977309504] #011Training metrics: mean_squared_error: 1.141 mean_absolute_error: 0.845 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:00 INFO 140508977309504] Epoch: 0, batches: 700, num_examples: 44800, 15966.1 samples/sec, epoch time so far: 0:00:02.805943\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:00 INFO 140508977309504] #011Training metrics: mean_squared_error: 1.118 mean_absolute_error: 0.836 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:00 INFO 140508977309504] Epoch: 0, batches: 800, num_examples: 51200, 15808.7 samples/sec, epoch time so far: 0:00:03.238733\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:00 INFO 140508977309504] #011Training metrics: mean_squared_error: 1.097 mean_absolute_error: 0.828 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:01 INFO 140508977309504] Epoch: 0, batches: 900, num_examples: 57600, 15858.9 samples/sec, epoch time so far: 0:00:03.632023\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:01 INFO 140508977309504] #011Training metrics: mean_squared_error: 1.081 mean_absolute_error: 0.822 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:01 INFO 140508977309504] Epoch: 0, batches: 1000, num_examples: 64000, 15507.1 samples/sec, epoch time so far: 0:00:04.127131\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:01 INFO 140508977309504] #011Training metrics: mean_squared_error: 1.067 mean_absolute_error: 0.816 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:01 INFO 140508977309504] Epoch: 0, batches: 1100, num_examples: 70400, 15568.0 samples/sec, epoch time so far: 0:00:04.522096\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:01 INFO 140508977309504] #011Training metrics: mean_squared_error: 1.052 mean_absolute_error: 0.811 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:02 INFO 140508977309504] Epoch: 0, batches: 1200, num_examples: 76800, 15504.6 samples/sec, epoch time so far: 0:00:04.953374\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:02 INFO 140508977309504] #011Training metrics: mean_squared_error: 1.039 mean_absolute_error: 0.806 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:02 INFO 140508977309504] Epoch: 0, batches: 1300, num_examples: 83200, 15468.9 samples/sec, epoch time so far: 0:00:05.378522\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:02 INFO 140508977309504] #011Training metrics: mean_squared_error: 1.029 mean_absolute_error: 0.802 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:03 INFO 140508977309504] Epoch: 0, batches: 1400, num_examples: 89600, 15527.6 samples/sec, epoch time so far: 0:00:05.770364\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:03 INFO 140508977309504] #011Training metrics: mean_squared_error: 1.023 mean_absolute_error: 0.799 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:03 INFO 140508977309504] **************\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:03 INFO 140508977309504] Completed Epoch: 0, time taken: 0:00:05.833845\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:03 INFO 140508977309504] Epoch 0 Training metrics:   mean_squared_error: 1.022 mean_absolute_error: 0.799 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:03 INFO 140508977309504] #quality_metric: host=algo-1, epoch=0, train mean_squared_error <loss>=1.021981033017743\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:03 INFO 140508977309504] Epoch 0 Validation metrics: mean_squared_error: 0.954 mean_absolute_error: 0.779 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:03 INFO 140508977309504] #quality_metric: host=algo-1, epoch=0, validation mean_squared_error <loss>=0.9539527365484753\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:03 INFO 140508977309504] **************\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619630877.4023588, \"EndTime\": 1619630883.5412674, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 20.0, \"count\": 1, \"min\": 20, \"max\": 20}, \"early_stop.time\": {\"sum\": 0.4150867462158203, \"count\": 1, \"min\": 0.4150867462158203, \"max\": 0.4150867462158203}, \"update.time\": {\"sum\": 6072.805166244507, \"count\": 1, \"min\": 6072.805166244507, \"max\": 6072.805166244507}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:03 INFO 140508977309504] #progress_metric: host=algo-1, completed 5.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619630877.4684386, \"EndTime\": 1619630883.5414968, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Total Batches Seen\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:03 INFO 140508977309504] #throughput_metric: host=algo-1, train throughput=14922.013137572188 records/second\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:04 INFO 140508977309504] Epoch: 1, batches: 100, num_examples: 6400, 14690.5 samples/sec, epoch time so far: 0:00:00.435654\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:04 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.729 mean_absolute_error: 0.671 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:04 INFO 140508977309504] Epoch: 1, batches: 200, num_examples: 12800, 12894.6 samples/sec, epoch time so far: 0:00:00.992666\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:04 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.720 mean_absolute_error: 0.667 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:05 INFO 140508977309504] Epoch: 1, batches: 300, num_examples: 19200, 12827.2 samples/sec, epoch time so far: 0:00:01.496816\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:05 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.708 mean_absolute_error: 0.662 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:05 INFO 140508977309504] Epoch: 1, batches: 400, num_examples: 25600, 12626.0 samples/sec, epoch time so far: 0:00:02.027564\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:05 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.701 mean_absolute_error: 0.659 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:06 INFO 140508977309504] Epoch: 1, batches: 500, num_examples: 32000, 12812.4 samples/sec, epoch time so far: 0:00:02.497586\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:06 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.697 mean_absolute_error: 0.656 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:06 INFO 140508977309504] Epoch: 1, batches: 600, num_examples: 38400, 12929.1 samples/sec, epoch time so far: 0:00:02.970035\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:06 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.691 mean_absolute_error: 0.654 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:06 INFO 140508977309504] Epoch: 1, batches: 700, num_examples: 44800, 13288.3 samples/sec, epoch time so far: 0:00:03.371395\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:06 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.682 mean_absolute_error: 0.650 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:07 INFO 140508977309504] Epoch: 1, batches: 800, num_examples: 51200, 13604.6 samples/sec, epoch time so far: 0:00:03.763435\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:07 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.677 mean_absolute_error: 0.647 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:07 INFO 140508977309504] Epoch: 1, batches: 900, num_examples: 57600, 13846.3 samples/sec, epoch time so far: 0:00:04.159959\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:07 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.673 mean_absolute_error: 0.644 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:08 INFO 140508977309504] Epoch: 1, batches: 1000, num_examples: 64000, 14061.1 samples/sec, epoch time so far: 0:00:04.551579\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:08 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.667 mean_absolute_error: 0.641 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:08 INFO 140508977309504] Epoch: 1, batches: 1100, num_examples: 70400, 14228.8 samples/sec, epoch time so far: 0:00:04.947703\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:08 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.663 mean_absolute_error: 0.639 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:08 INFO 140508977309504] Epoch: 1, batches: 1200, num_examples: 76800, 14380.4 samples/sec, epoch time so far: 0:00:05.340604\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:08 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.659 mean_absolute_error: 0.637 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:09 INFO 140508977309504] Epoch: 1, batches: 1300, num_examples: 83200, 14503.3 samples/sec, epoch time so far: 0:00:05.736625\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:09 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.656 mean_absolute_error: 0.636 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:09 INFO 140508977309504] Epoch: 1, batches: 1400, num_examples: 89600, 14618.4 samples/sec, epoch time so far: 0:00:06.129263\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:09 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.655 mean_absolute_error: 0.635 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:09 INFO 140508977309504] **************\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:09 INFO 140508977309504] Completed Epoch: 1, time taken: 0:00:06.191458\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:09 INFO 140508977309504] Epoch 1 Training metrics:   mean_squared_error: 0.654 mean_absolute_error: 0.635 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:09 INFO 140508977309504] #quality_metric: host=algo-1, epoch=1, train mean_squared_error <loss>=0.6544799963170189\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:09 INFO 140508977309504] Epoch 1 Validation metrics: mean_squared_error: 0.990 mean_absolute_error: 0.791 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:09 INFO 140508977309504] #quality_metric: host=algo-1, epoch=1, validation mean_squared_error <loss>=0.9898146930578593\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:09 INFO 140508977309504] **************\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619630883.541348, \"EndTime\": 1619630889.9719315, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 0.029325485229492188, \"count\": 1, \"min\": 0.029325485229492188, \"max\": 0.029325485229492188}, \"update.time\": {\"sum\": 6390.347957611084, \"count\": 1, \"min\": 6390.347957611084, \"max\": 6390.347957611084}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:09 INFO 140508977309504] #progress_metric: host=algo-1, completed 10.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619630883.5815535, \"EndTime\": 1619630889.972162, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 181248.0, \"count\": 1, \"min\": 181248, \"max\": 181248}, \"Total Batches Seen\": {\"sum\": 2832.0, \"count\": 1, \"min\": 2832, \"max\": 2832}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:09 INFO 140508977309504] #throughput_metric: host=algo-1, train throughput=14180.423980809765 records/second\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:10 INFO 140508977309504] Epoch: 2, batches: 100, num_examples: 6400, 16333.0 samples/sec, epoch time so far: 0:00:00.391845\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:10 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.276 mean_absolute_error: 0.402 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:10 INFO 140508977309504] Epoch: 2, batches: 200, num_examples: 12800, 16306.0 samples/sec, epoch time so far: 0:00:00.784988\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:10 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.264 mean_absolute_error: 0.393 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:11 INFO 140508977309504] Epoch: 2, batches: 300, num_examples: 19200, 16142.8 samples/sec, epoch time so far: 0:00:01.189387\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:11 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.262 mean_absolute_error: 0.392 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:11 INFO 140508977309504] Epoch: 2, batches: 400, num_examples: 25600, 16042.7 samples/sec, epoch time so far: 0:00:01.595743\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:11 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.262 mean_absolute_error: 0.391 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:11 INFO 140508977309504] Epoch: 2, batches: 500, num_examples: 32000, 15946.3 samples/sec, epoch time so far: 0:00:02.006739\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:11 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.264 mean_absolute_error: 0.392 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:12 INFO 140508977309504] Epoch: 2, batches: 600, num_examples: 38400, 15984.7 samples/sec, epoch time so far: 0:00:02.402295\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:12 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.265 mean_absolute_error: 0.393 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:12 INFO 140508977309504] Epoch: 2, batches: 700, num_examples: 44800, 16040.1 samples/sec, epoch time so far: 0:00:02.792995\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:12 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.267 mean_absolute_error: 0.395 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:13 INFO 140508977309504] Epoch: 2, batches: 800, num_examples: 51200, 16063.7 samples/sec, epoch time so far: 0:00:03.187306\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:13 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.269 mean_absolute_error: 0.397 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:13 INFO 140508977309504] Epoch: 2, batches: 900, num_examples: 57600, 16088.7 samples/sec, epoch time so far: 0:00:03.580149\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:13 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.269 mean_absolute_error: 0.397 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:13 INFO 140508977309504] Epoch: 2, batches: 1000, num_examples: 64000, 16109.8 samples/sec, epoch time so far: 0:00:03.972728\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:13 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.269 mean_absolute_error: 0.398 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:14 INFO 140508977309504] Epoch: 2, batches: 1100, num_examples: 70400, 16117.3 samples/sec, epoch time so far: 0:00:04.367989\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:14 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.270 mean_absolute_error: 0.399 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:14 INFO 140508977309504] Epoch: 2, batches: 1200, num_examples: 76800, 16140.8 samples/sec, epoch time so far: 0:00:04.758141\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:14 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.271 mean_absolute_error: 0.399 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:15 INFO 140508977309504] Epoch: 2, batches: 1300, num_examples: 83200, 16157.4 samples/sec, epoch time so far: 0:00:05.149344\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:15 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.272 mean_absolute_error: 0.400 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:15 INFO 140508977309504] Epoch: 2, batches: 1400, num_examples: 89600, 16168.3 samples/sec, epoch time so far: 0:00:05.541699\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:15 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.273 mean_absolute_error: 0.401 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:15 INFO 140508977309504] **************\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:15 INFO 140508977309504] Completed Epoch: 2, time taken: 0:00:05.604184\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:15 INFO 140508977309504] Epoch 2 Training metrics:   mean_squared_error: 0.274 mean_absolute_error: 0.401 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:15 INFO 140508977309504] #quality_metric: host=algo-1, epoch=2, train mean_squared_error <loss>=0.27375159409991595\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:15 INFO 140508977309504] Epoch 2 Validation metrics: mean_squared_error: 0.933 mean_absolute_error: 0.767 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:15 INFO 140508977309504] #quality_metric: host=algo-1, epoch=2, validation mean_squared_error <loss>=0.9328117990815962\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:15 INFO 140508977309504] **************\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619630889.9720201, \"EndTime\": 1619630895.7879293, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 2.2830963134765625, \"count\": 1, \"min\": 2.2830963134765625, \"max\": 2.2830963134765625}, \"update.time\": {\"sum\": 5810.154914855957, \"count\": 1, \"min\": 5810.154914855957, \"max\": 5810.154914855957}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:15 INFO 140508977309504] #progress_metric: host=algo-1, completed 15.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619630889.9777591, \"EndTime\": 1619630895.788228, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 271872.0, \"count\": 1, \"min\": 271872, \"max\": 271872}, \"Total Batches Seen\": {\"sum\": 4248.0, \"count\": 1, \"min\": 4248, \"max\": 4248}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:15 INFO 140508977309504] #throughput_metric: host=algo-1, train throughput=15596.311687096726 records/second\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:16 INFO 140508977309504] Epoch: 3, batches: 100, num_examples: 6400, 15772.8 samples/sec, epoch time so far: 0:00:00.405762\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:16 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.165 mean_absolute_error: 0.298 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:16 INFO 140508977309504] Epoch: 3, batches: 200, num_examples: 12800, 16002.4 samples/sec, epoch time so far: 0:00:00.799881\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:16 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.160 mean_absolute_error: 0.293 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:17 INFO 140508977309504] Epoch: 3, batches: 300, num_examples: 19200, 15519.6 samples/sec, epoch time so far: 0:00:01.237148\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:17 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.159 mean_absolute_error: 0.292 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:17 INFO 140508977309504] Epoch: 3, batches: 400, num_examples: 25600, 15697.8 samples/sec, epoch time so far: 0:00:01.630804\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:17 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.158 mean_absolute_error: 0.292 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:17 INFO 140508977309504] Epoch: 3, batches: 500, num_examples: 32000, 15825.3 samples/sec, epoch time so far: 0:00:02.022078\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:17 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.159 mean_absolute_error: 0.293 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:18 INFO 140508977309504] Epoch: 3, batches: 600, num_examples: 38400, 15895.6 samples/sec, epoch time so far: 0:00:02.415764\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:18 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.159 mean_absolute_error: 0.293 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:18 INFO 140508977309504] Epoch: 3, batches: 700, num_examples: 44800, 15947.3 samples/sec, epoch time so far: 0:00:02.809245\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:18 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.158 mean_absolute_error: 0.293 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:18 INFO 140508977309504] Epoch: 3, batches: 800, num_examples: 51200, 15996.0 samples/sec, epoch time so far: 0:00:03.200807\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:18 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.159 mean_absolute_error: 0.294 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:19 INFO 140508977309504] Epoch: 3, batches: 900, num_examples: 57600, 16043.9 samples/sec, epoch time so far: 0:00:03.590150\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:19 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.159 mean_absolute_error: 0.295 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:19 INFO 140508977309504] Epoch: 3, batches: 1000, num_examples: 64000, 16033.7 samples/sec, epoch time so far: 0:00:03.991584\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:19 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.159 mean_absolute_error: 0.295 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:20 INFO 140508977309504] Epoch: 3, batches: 1100, num_examples: 70400, 16062.2 samples/sec, epoch time so far: 0:00:04.382971\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:20 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.159 mean_absolute_error: 0.296 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:20 INFO 140508977309504] Epoch: 3, batches: 1200, num_examples: 76800, 16077.9 samples/sec, epoch time so far: 0:00:04.776757\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:20 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.159 mean_absolute_error: 0.296 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:20 INFO 140508977309504] Epoch: 3, batches: 1300, num_examples: 83200, 16101.3 samples/sec, epoch time so far: 0:00:05.167294\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:20 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.159 mean_absolute_error: 0.297 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:21 INFO 140508977309504] Epoch: 3, batches: 1400, num_examples: 89600, 16121.9 samples/sec, epoch time so far: 0:00:05.557660\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:21 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.160 mean_absolute_error: 0.298 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:21 INFO 140508977309504] **************\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:21 INFO 140508977309504] Completed Epoch: 3, time taken: 0:00:05.619770\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:21 INFO 140508977309504] Epoch 3 Training metrics:   mean_squared_error: 0.160 mean_absolute_error: 0.298 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:21 INFO 140508977309504] #quality_metric: host=algo-1, epoch=3, train mean_squared_error <loss>=0.16008305239180723\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:21 INFO 140508977309504] Epoch 3 Validation metrics: mean_squared_error: 0.939 mean_absolute_error: 0.766 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:21 INFO 140508977309504] #quality_metric: host=algo-1, epoch=3, validation mean_squared_error <loss>=0.9389876546086492\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:21 INFO 140508977309504] **************\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:21 INFO 140508977309504] patience losses: [0.9539527365484753, 0.9898146930578593, 0.9328117990815962]\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:21 INFO 140508977309504] min patience losses: 0.9328117990815962\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:21 INFO 140508977309504] current loss: 0.9389876546086492\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:21 INFO 140508977309504] absolute loss difference: 0.00617585552705302\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:21 INFO 140508977309504] Bad epoch: loss has not improved (enough). Bad count:1\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619630895.7880151, \"EndTime\": 1619630901.6330485, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 0.5540847778320312, \"count\": 1, \"min\": 0.5540847778320312, \"max\": 0.5540847778320312}, \"update.time\": {\"sum\": 5834.684371948242, \"count\": 1, \"min\": 5834.684371948242, \"max\": 5834.684371948242}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:21 INFO 140508977309504] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619630895.798341, \"EndTime\": 1619630901.6333292, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 362496.0, \"count\": 1, \"min\": 362496, \"max\": 362496}, \"Total Batches Seen\": {\"sum\": 5664.0, \"count\": 1, \"min\": 5664, \"max\": 5664}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:21 INFO 140508977309504] #throughput_metric: host=algo-1, train throughput=15530.723275773518 records/second\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:22 INFO 140508977309504] Epoch: 4, batches: 100, num_examples: 6400, 14821.4 samples/sec, epoch time so far: 0:00:00.431809\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:22 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.115 mean_absolute_error: 0.256 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:22 INFO 140508977309504] Epoch: 4, batches: 200, num_examples: 12800, 15534.5 samples/sec, epoch time so far: 0:00:00.823975\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:22 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.113 mean_absolute_error: 0.253 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:22 INFO 140508977309504] Epoch: 4, batches: 300, num_examples: 19200, 15770.0 samples/sec, epoch time so far: 0:00:01.217505\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:22 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.112 mean_absolute_error: 0.251 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:23 INFO 140508977309504] Epoch: 4, batches: 400, num_examples: 25600, 15906.4 samples/sec, epoch time so far: 0:00:01.609413\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:23 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.110 mean_absolute_error: 0.249 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:23 INFO 140508977309504] Epoch: 4, batches: 500, num_examples: 32000, 15945.7 samples/sec, epoch time so far: 0:00:02.006814\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:23 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.110 mean_absolute_error: 0.249 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:24 INFO 140508977309504] Epoch: 4, batches: 600, num_examples: 38400, 16009.8 samples/sec, epoch time so far: 0:00:02.398538\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:24 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.108 mean_absolute_error: 0.247 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:24 INFO 140508977309504] Epoch: 4, batches: 700, num_examples: 44800, 16049.0 samples/sec, epoch time so far: 0:00:02.791452\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:24 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.107 mean_absolute_error: 0.247 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:24 INFO 140508977309504] Epoch: 4, batches: 800, num_examples: 51200, 16063.1 samples/sec, epoch time so far: 0:00:03.187436\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:24 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.106 mean_absolute_error: 0.246 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:25 INFO 140508977309504] Epoch: 4, batches: 900, num_examples: 57600, 16106.0 samples/sec, epoch time so far: 0:00:03.576312\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:25 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.105 mean_absolute_error: 0.245 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:25 INFO 140508977309504] Epoch: 4, batches: 1000, num_examples: 64000, 16126.3 samples/sec, epoch time so far: 0:00:03.968672\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:25 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.105 mean_absolute_error: 0.244 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:26 INFO 140508977309504] Epoch: 4, batches: 1100, num_examples: 70400, 16139.9 samples/sec, epoch time so far: 0:00:04.361848\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:26 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.105 mean_absolute_error: 0.245 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:26 INFO 140508977309504] Epoch: 4, batches: 1200, num_examples: 76800, 16141.9 samples/sec, epoch time so far: 0:00:04.757793\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:26 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.105 mean_absolute_error: 0.246 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:26 INFO 140508977309504] Epoch: 4, batches: 1300, num_examples: 83200, 16144.7 samples/sec, epoch time so far: 0:00:05.153383\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:26 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.105 mean_absolute_error: 0.246 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:27 INFO 140508977309504] Epoch: 4, batches: 1400, num_examples: 89600, 16053.3 samples/sec, epoch time so far: 0:00:05.581394\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:27 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.106 mean_absolute_error: 0.246 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:27 INFO 140508977309504] **************\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:27 INFO 140508977309504] Completed Epoch: 4, time taken: 0:00:05.643874\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:27 INFO 140508977309504] Epoch 4 Training metrics:   mean_squared_error: 0.106 mean_absolute_error: 0.247 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:27 INFO 140508977309504] #quality_metric: host=algo-1, epoch=4, train mean_squared_error <loss>=0.10559292712201507\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:27 INFO 140508977309504] Epoch 4 Validation metrics: mean_squared_error: 0.938 mean_absolute_error: 0.769 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:27 INFO 140508977309504] #quality_metric: host=algo-1, epoch=4, validation mean_squared_error <loss>=0.9376952076280439\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:27 INFO 140508977309504] **************\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:27 INFO 140508977309504] patience losses: [0.9898146930578593, 0.9328117990815962, 0.9389876546086492]\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:27 INFO 140508977309504] min patience losses: 0.9328117990815962\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:27 INFO 140508977309504] current loss: 0.9376952076280439\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:27 INFO 140508977309504] absolute loss difference: 0.004883408546447754\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:27 INFO 140508977309504] Bad epoch: loss has not improved (enough). Bad count:2\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619630901.6331475, \"EndTime\": 1619630907.4860406, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 0.5469322204589844, \"count\": 1, \"min\": 0.5469322204589844, \"max\": 0.5469322204589844}, \"update.time\": {\"sum\": 5847.064018249512, \"count\": 1, \"min\": 5847.064018249512, \"max\": 5847.064018249512}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:27 INFO 140508977309504] #progress_metric: host=algo-1, completed 25.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619630901.638959, \"EndTime\": 1619630907.4863148, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 453120.0, \"count\": 1, \"min\": 453120, \"max\": 453120}, \"Total Batches Seen\": {\"sum\": 7080.0, \"count\": 1, \"min\": 7080, \"max\": 7080}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:27 INFO 140508977309504] #throughput_metric: host=algo-1, train throughput=15497.945301355954 records/second\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:27 INFO 140508977309504] Epoch: 5, batches: 100, num_examples: 6400, 16373.7 samples/sec, epoch time so far: 0:00:00.390870\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:27 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.097 mean_absolute_error: 0.240 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:28 INFO 140508977309504] Epoch: 5, batches: 200, num_examples: 12800, 16325.7 samples/sec, epoch time so far: 0:00:00.784038\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:28 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.093 mean_absolute_error: 0.234 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:28 INFO 140508977309504] Epoch: 5, batches: 300, num_examples: 19200, 16241.7 samples/sec, epoch time so far: 0:00:01.182144\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:28 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.090 mean_absolute_error: 0.231 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:29 INFO 140508977309504] Epoch: 5, batches: 400, num_examples: 25600, 16268.6 samples/sec, epoch time so far: 0:00:01.573586\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:29 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.089 mean_absolute_error: 0.229 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:29 INFO 140508977309504] Epoch: 5, batches: 500, num_examples: 32000, 16300.8 samples/sec, epoch time so far: 0:00:01.963092\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:29 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.088 mean_absolute_error: 0.228 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:29 INFO 140508977309504] Epoch: 5, batches: 600, num_examples: 38400, 16263.7 samples/sec, epoch time so far: 0:00:02.361090\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:29 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.088 mean_absolute_error: 0.228 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:30 INFO 140508977309504] Epoch: 5, batches: 700, num_examples: 44800, 16286.2 samples/sec, epoch time so far: 0:00:02.750794\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:30 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.087 mean_absolute_error: 0.228 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:30 INFO 140508977309504] Epoch: 5, batches: 800, num_examples: 51200, 16275.7 samples/sec, epoch time so far: 0:00:03.145790\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:30 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.087 mean_absolute_error: 0.227 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:31 INFO 140508977309504] Epoch: 5, batches: 900, num_examples: 57600, 16279.8 samples/sec, epoch time so far: 0:00:03.538117\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:31 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.087 mean_absolute_error: 0.227 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:31 INFO 140508977309504] Epoch: 5, batches: 1000, num_examples: 64000, 16261.2 samples/sec, epoch time so far: 0:00:03.935755\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:31 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.087 mean_absolute_error: 0.227 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:31 INFO 140508977309504] Epoch: 5, batches: 1100, num_examples: 70400, 16265.7 samples/sec, epoch time so far: 0:00:04.328129\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:31 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.087 mean_absolute_error: 0.227 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:32 INFO 140508977309504] Epoch: 5, batches: 1200, num_examples: 76800, 16199.9 samples/sec, epoch time so far: 0:00:04.740765\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:32 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.087 mean_absolute_error: 0.228 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:32 INFO 140508977309504] Epoch: 5, batches: 1300, num_examples: 83200, 16212.6 samples/sec, epoch time so far: 0:00:05.131805\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:32 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.087 mean_absolute_error: 0.227 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:33 INFO 140508977309504] Epoch: 5, batches: 1400, num_examples: 89600, 16191.6 samples/sec, epoch time so far: 0:00:05.533750\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:33 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.087 mean_absolute_error: 0.228 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:33 INFO 140508977309504] **************\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:33 INFO 140508977309504] Completed Epoch: 5, time taken: 0:00:05.596542\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:33 INFO 140508977309504] Epoch 5 Training metrics:   mean_squared_error: 0.087 mean_absolute_error: 0.228 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:33 INFO 140508977309504] #quality_metric: host=algo-1, epoch=5, train mean_squared_error <loss>=0.08699015286056545\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:33 INFO 140508977309504] Epoch 5 Validation metrics: mean_squared_error: 0.936 mean_absolute_error: 0.765 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:33 INFO 140508977309504] #quality_metric: host=algo-1, epoch=5, validation mean_squared_error <loss>=0.9355560831121497\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:33 INFO 140508977309504] **************\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:33 INFO 140508977309504] patience losses: [0.9328117990815962, 0.9389876546086492, 0.9376952076280439]\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:33 INFO 140508977309504] min patience losses: 0.9328117990815962\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:33 INFO 140508977309504] current loss: 0.9355560831121497\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:33 INFO 140508977309504] absolute loss difference: 0.00274428403055349\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:33 INFO 140508977309504] Bad epoch: loss has not improved (enough). Bad count:3\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619630907.4861336, \"EndTime\": 1619630913.2899163, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 0.5342960357666016, \"count\": 1, \"min\": 0.5342960357666016, \"max\": 0.5342960357666016}, \"update.time\": {\"sum\": 5797.922372817993, \"count\": 1, \"min\": 5797.922372817993, \"max\": 5797.922372817993}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:33 INFO 140508977309504] #progress_metric: host=algo-1, completed 30.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619630907.4919732, \"EndTime\": 1619630913.290182, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 543744.0, \"count\": 1, \"min\": 543744, \"max\": 543744}, \"Total Batches Seen\": {\"sum\": 8496.0, \"count\": 1, \"min\": 8496, \"max\": 8496}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:33 INFO 140508977309504] #throughput_metric: host=algo-1, train throughput=15629.27680030763 records/second\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:33 INFO 140508977309504] Epoch: 6, batches: 100, num_examples: 6400, 16258.9 samples/sec, epoch time so far: 0:00:00.393630\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:33 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.085 mean_absolute_error: 0.225 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:34 INFO 140508977309504] Epoch: 6, batches: 200, num_examples: 12800, 16247.8 samples/sec, epoch time so far: 0:00:00.787801\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:34 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.085 mean_absolute_error: 0.224 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:34 INFO 140508977309504] Epoch: 6, batches: 300, num_examples: 19200, 16305.4 samples/sec, epoch time so far: 0:00:01.177525\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:34 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.085 mean_absolute_error: 0.223 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:34 INFO 140508977309504] Epoch: 6, batches: 400, num_examples: 25600, 16275.8 samples/sec, epoch time so far: 0:00:01.572885\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:34 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.084 mean_absolute_error: 0.222 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:35 INFO 140508977309504] Epoch: 6, batches: 500, num_examples: 32000, 16299.5 samples/sec, epoch time so far: 0:00:01.963251\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:35 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.083 mean_absolute_error: 0.222 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:35 INFO 140508977309504] Epoch: 6, batches: 600, num_examples: 38400, 16310.5 samples/sec, epoch time so far: 0:00:02.354306\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:35 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.084 mean_absolute_error: 0.222 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:36 INFO 140508977309504] Epoch: 6, batches: 700, num_examples: 44800, 16311.7 samples/sec, epoch time so far: 0:00:02.746494\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:36 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.083 mean_absolute_error: 0.222 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:36 INFO 140508977309504] Epoch: 6, batches: 800, num_examples: 51200, 16296.2 samples/sec, epoch time so far: 0:00:03.141838\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:36 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.083 mean_absolute_error: 0.222 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:36 INFO 140508977309504] Epoch: 6, batches: 900, num_examples: 57600, 16284.4 samples/sec, epoch time so far: 0:00:03.537124\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:36 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.083 mean_absolute_error: 0.222 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:37 INFO 140508977309504] Epoch: 6, batches: 1000, num_examples: 64000, 16112.4 samples/sec, epoch time so far: 0:00:03.972106\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:37 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.083 mean_absolute_error: 0.222 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:37 INFO 140508977309504] Epoch: 6, batches: 1100, num_examples: 70400, 16105.0 samples/sec, epoch time so far: 0:00:04.371313\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:37 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.084 mean_absolute_error: 0.223 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:38 INFO 140508977309504] Epoch: 6, batches: 1200, num_examples: 76800, 16103.8 samples/sec, epoch time so far: 0:00:04.769060\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:38 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.084 mean_absolute_error: 0.223 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:38 INFO 140508977309504] Epoch: 6, batches: 1300, num_examples: 83200, 16109.6 samples/sec, epoch time so far: 0:00:05.164621\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:38 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.084 mean_absolute_error: 0.223 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:38 INFO 140508977309504] Epoch: 6, batches: 1400, num_examples: 89600, 16084.3 samples/sec, epoch time so far: 0:00:05.570651\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:38 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.084 mean_absolute_error: 0.224 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:38 INFO 140508977309504] **************\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:38 INFO 140508977309504] Completed Epoch: 6, time taken: 0:00:05.633040\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:38 INFO 140508977309504] Epoch 6 Training metrics:   mean_squared_error: 0.084 mean_absolute_error: 0.224 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:38 INFO 140508977309504] #quality_metric: host=algo-1, epoch=6, train mean_squared_error <loss>=0.08404863857280064\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:39 INFO 140508977309504] Epoch 6 Validation metrics: mean_squared_error: 0.924 mean_absolute_error: 0.752 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:39 INFO 140508977309504] #quality_metric: host=algo-1, epoch=6, validation mean_squared_error <loss>=0.9241858978529234\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:39 INFO 140508977309504] **************\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:39 INFO 140508977309504] patience losses: [0.9389876546086492, 0.9376952076280439, 0.9355560831121497]\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:39 INFO 140508977309504] min patience losses: 0.9355560831121497\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:39 INFO 140508977309504] current loss: 0.9241858978529234\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:39 INFO 140508977309504] absolute loss difference: 0.011370185259226284\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619630913.2900097, \"EndTime\": 1619630919.1355653, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 3.7317276000976562, \"count\": 1, \"min\": 3.7317276000976562, \"max\": 3.7317276000976562}, \"update.time\": {\"sum\": 5839.760780334473, \"count\": 1, \"min\": 5839.760780334473, \"max\": 5839.760780334473}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:39 INFO 140508977309504] #progress_metric: host=algo-1, completed 35.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619630913.2957814, \"EndTime\": 1619630919.1358738, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 634368.0, \"count\": 1, \"min\": 634368, \"max\": 634368}, \"Total Batches Seen\": {\"sum\": 9912.0, \"count\": 1, \"min\": 9912, \"max\": 9912}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 7.0, \"count\": 1, \"min\": 7, \"max\": 7}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:39 INFO 140508977309504] #throughput_metric: host=algo-1, train throughput=15517.155953120877 records/second\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:39 INFO 140508977309504] Epoch: 7, batches: 100, num_examples: 6400, 16397.9 samples/sec, epoch time so far: 0:00:00.390294\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:39 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.082 mean_absolute_error: 0.217 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:39 INFO 140508977309504] Epoch: 7, batches: 200, num_examples: 12800, 16327.0 samples/sec, epoch time so far: 0:00:00.783979\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:39 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.080 mean_absolute_error: 0.215 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:40 INFO 140508977309504] Epoch: 7, batches: 300, num_examples: 19200, 16343.5 samples/sec, epoch time so far: 0:00:01.174776\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:40 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.078 mean_absolute_error: 0.214 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:40 INFO 140508977309504] Epoch: 7, batches: 400, num_examples: 25600, 16347.6 samples/sec, epoch time so far: 0:00:01.565982\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:40 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.078 mean_absolute_error: 0.214 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:41 INFO 140508977309504] Epoch: 7, batches: 500, num_examples: 32000, 16317.7 samples/sec, epoch time so far: 0:00:01.961058\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:41 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.078 mean_absolute_error: 0.214 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:41 INFO 140508977309504] Epoch: 7, batches: 600, num_examples: 38400, 16321.5 samples/sec, epoch time so far: 0:00:02.352727\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:41 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.078 mean_absolute_error: 0.214 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:41 INFO 140508977309504] Epoch: 7, batches: 700, num_examples: 44800, 16325.8 samples/sec, epoch time so far: 0:00:02.744127\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:41 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.078 mean_absolute_error: 0.214 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:42 INFO 140508977309504] Epoch: 7, batches: 800, num_examples: 51200, 16284.2 samples/sec, epoch time so far: 0:00:03.144152\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:42 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.078 mean_absolute_error: 0.214 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:42 INFO 140508977309504] Epoch: 7, batches: 900, num_examples: 57600, 16225.7 samples/sec, epoch time so far: 0:00:03.549914\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:42 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.077 mean_absolute_error: 0.213 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:43 INFO 140508977309504] Epoch: 7, batches: 1000, num_examples: 64000, 16203.4 samples/sec, epoch time so far: 0:00:03.949787\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:43 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.077 mean_absolute_error: 0.213 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:43 INFO 140508977309504] Epoch: 7, batches: 1100, num_examples: 70400, 16212.4 samples/sec, epoch time so far: 0:00:04.342355\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:43 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.076 mean_absolute_error: 0.212 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:43 INFO 140508977309504] Epoch: 7, batches: 1200, num_examples: 76800, 16201.9 samples/sec, epoch time so far: 0:00:04.740177\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:43 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.076 mean_absolute_error: 0.212 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:44 INFO 140508977309504] Epoch: 7, batches: 1300, num_examples: 83200, 16215.4 samples/sec, epoch time so far: 0:00:05.130939\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:44 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.076 mean_absolute_error: 0.212 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:44 INFO 140508977309504] Epoch: 7, batches: 1400, num_examples: 89600, 16228.6 samples/sec, epoch time so far: 0:00:05.521106\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:44 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.076 mean_absolute_error: 0.212 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:44 INFO 140508977309504] **************\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:44 INFO 140508977309504] Completed Epoch: 7, time taken: 0:00:05.584366\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:44 INFO 140508977309504] Epoch 7 Training metrics:   mean_squared_error: 0.076 mean_absolute_error: 0.212 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:44 INFO 140508977309504] #quality_metric: host=algo-1, epoch=7, train mean_squared_error <loss>=0.07614576313013242\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:44 INFO 140508977309504] Epoch 7 Validation metrics: mean_squared_error: 0.919 mean_absolute_error: 0.751 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:44 INFO 140508977309504] #quality_metric: host=algo-1, epoch=7, validation mean_squared_error <loss>=0.9186116138825545\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:44 INFO 140508977309504] **************\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:44 INFO 140508977309504] patience losses: [0.9376952076280439, 0.9355560831121497, 0.9241858978529234]\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:44 INFO 140508977309504] min patience losses: 0.9241858978529234\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:44 INFO 140508977309504] current loss: 0.9186116138825545\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:44 INFO 140508977309504] absolute loss difference: 0.005574283970368854\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:44 INFO 140508977309504] Bad epoch: loss has not improved (enough). Bad count:1\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619630919.1356685, \"EndTime\": 1619630924.9577966, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 2.9265880584716797, \"count\": 1, \"min\": 2.9265880584716797, \"max\": 2.9265880584716797}, \"update.time\": {\"sum\": 5796.05770111084, \"count\": 1, \"min\": 5796.05770111084, \"max\": 5796.05770111084}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:44 INFO 140508977309504] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619630919.1617115, \"EndTime\": 1619630924.9581087, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 7, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 724992.0, \"count\": 1, \"min\": 724992, \"max\": 724992}, \"Total Batches Seen\": {\"sum\": 11328.0, \"count\": 1, \"min\": 11328, \"max\": 11328}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 8.0, \"count\": 1, \"min\": 8, \"max\": 8}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:44 INFO 140508977309504] #throughput_metric: host=algo-1, train throughput=15634.126457614755 records/second\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:45 INFO 140508977309504] Epoch: 8, batches: 100, num_examples: 6400, 16508.7 samples/sec, epoch time so far: 0:00:00.387674\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:45 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.067 mean_absolute_error: 0.197 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:45 INFO 140508977309504] Epoch: 8, batches: 200, num_examples: 12800, 16435.0 samples/sec, epoch time so far: 0:00:00.778826\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:45 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.065 mean_absolute_error: 0.194 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:46 INFO 140508977309504] Epoch: 8, batches: 300, num_examples: 19200, 16290.4 samples/sec, epoch time so far: 0:00:01.178610\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:46 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.065 mean_absolute_error: 0.195 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:46 INFO 140508977309504] Epoch: 8, batches: 400, num_examples: 25600, 16257.4 samples/sec, epoch time so far: 0:00:01.574663\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:46 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.065 mean_absolute_error: 0.194 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:46 INFO 140508977309504] Epoch: 8, batches: 500, num_examples: 32000, 16250.2 samples/sec, epoch time so far: 0:00:01.969208\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:46 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.064 mean_absolute_error: 0.193 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:47 INFO 140508977309504] Epoch: 8, batches: 600, num_examples: 38400, 16238.9 samples/sec, epoch time so far: 0:00:02.364685\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:47 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.064 mean_absolute_error: 0.193 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:47 INFO 140508977309504] Epoch: 8, batches: 700, num_examples: 44800, 16143.5 samples/sec, epoch time so far: 0:00:02.775118\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:47 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.064 mean_absolute_error: 0.193 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:48 INFO 140508977309504] Epoch: 8, batches: 800, num_examples: 51200, 16138.6 samples/sec, epoch time so far: 0:00:03.172509\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:48 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.064 mean_absolute_error: 0.194 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:48 INFO 140508977309504] Epoch: 8, batches: 900, num_examples: 57600, 16161.9 samples/sec, epoch time so far: 0:00:03.563948\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:48 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.064 mean_absolute_error: 0.193 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:48 INFO 140508977309504] Epoch: 8, batches: 1000, num_examples: 64000, 16148.3 samples/sec, epoch time so far: 0:00:03.963275\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:48 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.064 mean_absolute_error: 0.193 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:49 INFO 140508977309504] Epoch: 8, batches: 1100, num_examples: 70400, 16155.3 samples/sec, epoch time so far: 0:00:04.357702\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:49 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.064 mean_absolute_error: 0.193 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:49 INFO 140508977309504] Epoch: 8, batches: 1200, num_examples: 76800, 16175.1 samples/sec, epoch time so far: 0:00:04.748028\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:49 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.064 mean_absolute_error: 0.193 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:50 INFO 140508977309504] Epoch: 8, batches: 1300, num_examples: 83200, 16173.5 samples/sec, epoch time so far: 0:00:05.144214\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:50 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.064 mean_absolute_error: 0.193 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:50 INFO 140508977309504] Epoch: 8, batches: 1400, num_examples: 89600, 16191.6 samples/sec, epoch time so far: 0:00:05.533749\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:50 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.064 mean_absolute_error: 0.193 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:50 INFO 140508977309504] **************\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:50 INFO 140508977309504] Completed Epoch: 8, time taken: 0:00:05.596169\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:50 INFO 140508977309504] Epoch 8 Training metrics:   mean_squared_error: 0.064 mean_absolute_error: 0.193 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:50 INFO 140508977309504] #quality_metric: host=algo-1, epoch=8, train mean_squared_error <loss>=0.06403211966988309\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:50 INFO 140508977309504] Epoch 8 Validation metrics: mean_squared_error: 0.910 mean_absolute_error: 0.747 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:50 INFO 140508977309504] #quality_metric: host=algo-1, epoch=8, validation mean_squared_error <loss>=0.9095894130500587\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:50 INFO 140508977309504] **************\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:50 INFO 140508977309504] patience losses: [0.9355560831121497, 0.9241858978529234, 0.9186116138825545]\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:50 INFO 140508977309504] min patience losses: 0.9186116138825545\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:50 INFO 140508977309504] current loss: 0.9095894130500587\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:50 INFO 140508977309504] absolute loss difference: 0.00902220083249583\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:50 INFO 140508977309504] Bad epoch: loss has not improved (enough). Bad count:2\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619630924.957907, \"EndTime\": 1619630930.7837255, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 2.840280532836914, \"count\": 1, \"min\": 2.840280532836914, \"max\": 2.840280532836914}, \"update.time\": {\"sum\": 5801.3012409210205, \"count\": 1, \"min\": 5801.3012409210205, \"max\": 5801.3012409210205}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:50 INFO 140508977309504] #progress_metric: host=algo-1, completed 45.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619630924.982397, \"EndTime\": 1619630930.7840326, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 8, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 815616.0, \"count\": 1, \"min\": 815616, \"max\": 815616}, \"Total Batches Seen\": {\"sum\": 12744.0, \"count\": 1, \"min\": 12744, \"max\": 12744}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 9.0, \"count\": 1, \"min\": 9, \"max\": 9}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:50 INFO 140508977309504] #throughput_metric: host=algo-1, train throughput=15620.005647790276 records/second\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:51 INFO 140508977309504] Epoch: 9, batches: 100, num_examples: 6400, 16288.6 samples/sec, epoch time so far: 0:00:00.392912\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:51 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.060 mean_absolute_error: 0.184 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:51 INFO 140508977309504] Epoch: 9, batches: 200, num_examples: 12800, 16204.7 samples/sec, epoch time so far: 0:00:00.789897\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:51 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.059 mean_absolute_error: 0.182 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:51 INFO 140508977309504] Epoch: 9, batches: 300, num_examples: 19200, 16270.0 samples/sec, epoch time so far: 0:00:01.180084\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:51 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.057 mean_absolute_error: 0.181 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:52 INFO 140508977309504] Epoch: 9, batches: 400, num_examples: 25600, 16247.0 samples/sec, epoch time so far: 0:00:01.575672\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:52 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.057 mean_absolute_error: 0.181 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:52 INFO 140508977309504] Epoch: 9, batches: 500, num_examples: 32000, 16130.9 samples/sec, epoch time so far: 0:00:01.983776\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:52 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.057 mean_absolute_error: 0.180 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:53 INFO 140508977309504] Epoch: 9, batches: 600, num_examples: 38400, 16150.0 samples/sec, epoch time so far: 0:00:02.377715\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:53 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.057 mean_absolute_error: 0.180 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:53 INFO 140508977309504] Epoch: 9, batches: 700, num_examples: 44800, 16180.0 samples/sec, epoch time so far: 0:00:02.768842\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:53 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.057 mean_absolute_error: 0.180 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:53 INFO 140508977309504] Epoch: 9, batches: 800, num_examples: 51200, 16198.2 samples/sec, epoch time so far: 0:00:03.160836\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:53 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.056 mean_absolute_error: 0.179 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:54 INFO 140508977309504] Epoch: 9, batches: 900, num_examples: 57600, 16163.4 samples/sec, epoch time so far: 0:00:03.563604\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:54 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.056 mean_absolute_error: 0.179 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:54 INFO 140508977309504] Epoch: 9, batches: 1000, num_examples: 64000, 16191.1 samples/sec, epoch time so far: 0:00:03.952788\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:54 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.056 mean_absolute_error: 0.179 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:55 INFO 140508977309504] Epoch: 9, batches: 1100, num_examples: 70400, 16195.6 samples/sec, epoch time so far: 0:00:04.346865\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:55 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.056 mean_absolute_error: 0.179 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:55 INFO 140508977309504] Epoch: 9, batches: 1200, num_examples: 76800, 16210.7 samples/sec, epoch time so far: 0:00:04.737618\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:55 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.056 mean_absolute_error: 0.179 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:55 INFO 140508977309504] Epoch: 9, batches: 1300, num_examples: 83200, 16228.2 samples/sec, epoch time so far: 0:00:05.126882\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:55 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.056 mean_absolute_error: 0.179 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:56 INFO 140508977309504] Epoch: 9, batches: 1400, num_examples: 89600, 16225.2 samples/sec, epoch time so far: 0:00:05.522289\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:56 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.056 mean_absolute_error: 0.179 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:56 INFO 140508977309504] **************\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:56 INFO 140508977309504] Completed Epoch: 9, time taken: 0:00:05.584874\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:56 INFO 140508977309504] Epoch 9 Training metrics:   mean_squared_error: 0.056 mean_absolute_error: 0.180 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:56 INFO 140508977309504] #quality_metric: host=algo-1, epoch=9, train mean_squared_error <loss>=0.056242616198651785\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:56 INFO 140508977309504] Epoch 9 Validation metrics: mean_squared_error: 0.917 mean_absolute_error: 0.753 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:56 INFO 140508977309504] #quality_metric: host=algo-1, epoch=9, validation mean_squared_error <loss>=0.9166324174887425\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:56 INFO 140508977309504] **************\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:56 INFO 140508977309504] patience losses: [0.9241858978529234, 0.9186116138825545, 0.9095894130500587]\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:56 INFO 140508977309504] min patience losses: 0.9095894130500587\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:56 INFO 140508977309504] current loss: 0.9166324174887425\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:56 INFO 140508977309504] absolute loss difference: 0.007043004438683775\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:56 INFO 140508977309504] Bad epoch: loss has not improved (enough). Bad count:3\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619630930.7838316, \"EndTime\": 1619630936.5933154, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 0.5044937133789062, \"count\": 1, \"min\": 0.5044937133789062, \"max\": 0.5044937133789062}, \"update.time\": {\"sum\": 5785.646200180054, \"count\": 1, \"min\": 5785.646200180054, \"max\": 5785.646200180054}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:56 INFO 140508977309504] #progress_metric: host=algo-1, completed 50.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619630930.8076408, \"EndTime\": 1619630936.5935993, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 9, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 906240.0, \"count\": 1, \"min\": 906240, \"max\": 906240}, \"Total Batches Seen\": {\"sum\": 14160.0, \"count\": 1, \"min\": 14160, \"max\": 14160}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 10.0, \"count\": 1, \"min\": 10, \"max\": 10}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:56 INFO 140508977309504] #throughput_metric: host=algo-1, train throughput=15662.286046988267 records/second\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:56 INFO 140508977309504] Epoch: 10, batches: 100, num_examples: 6400, 16347.2 samples/sec, epoch time so far: 0:00:00.391504\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:56 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.053 mean_absolute_error: 0.172 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:57 INFO 140508977309504] Epoch: 10, batches: 200, num_examples: 12800, 16179.6 samples/sec, epoch time so far: 0:00:00.791119\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:57 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.054 mean_absolute_error: 0.173 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:57 INFO 140508977309504] Epoch: 10, batches: 300, num_examples: 19200, 16043.9 samples/sec, epoch time so far: 0:00:01.196716\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:57 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.053 mean_absolute_error: 0.172 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:58 INFO 140508977309504] Epoch: 10, batches: 400, num_examples: 25600, 16062.5 samples/sec, epoch time so far: 0:00:01.593774\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:58 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.053 mean_absolute_error: 0.171 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:58 INFO 140508977309504] Epoch: 10, batches: 500, num_examples: 32000, 16100.8 samples/sec, epoch time so far: 0:00:01.987485\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:58 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.052 mean_absolute_error: 0.170 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:58 INFO 140508977309504] Epoch: 10, batches: 600, num_examples: 38400, 16094.7 samples/sec, epoch time so far: 0:00:02.385876\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:58 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.051 mean_absolute_error: 0.169 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:59 INFO 140508977309504] Epoch: 10, batches: 700, num_examples: 44800, 16094.1 samples/sec, epoch time so far: 0:00:02.783627\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:59 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.051 mean_absolute_error: 0.169 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:59 INFO 140508977309504] Epoch: 10, batches: 800, num_examples: 51200, 16115.3 samples/sec, epoch time so far: 0:00:03.177103\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:28:59 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.051 mean_absolute_error: 0.168 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:29:00 INFO 140508977309504] Epoch: 10, batches: 900, num_examples: 57600, 16096.0 samples/sec, epoch time so far: 0:00:03.578521\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:29:00 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.051 mean_absolute_error: 0.169 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:29:00 INFO 140508977309504] Epoch: 10, batches: 1000, num_examples: 64000, 16117.0 samples/sec, epoch time so far: 0:00:03.970951\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:29:00 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.051 mean_absolute_error: 0.168 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:29:00 INFO 140508977309504] Epoch: 10, batches: 1100, num_examples: 70400, 16142.2 samples/sec, epoch time so far: 0:00:04.361239\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:29:00 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.051 mean_absolute_error: 0.168 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:29:01 INFO 140508977309504] Epoch: 10, batches: 1200, num_examples: 76800, 16122.9 samples/sec, epoch time so far: 0:00:04.763423\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:29:01 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.051 mean_absolute_error: 0.168 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:29:01 INFO 140508977309504] Epoch: 10, batches: 1300, num_examples: 83200, 16149.1 samples/sec, epoch time so far: 0:00:05.151997\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:29:01 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.051 mean_absolute_error: 0.168 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:29:02 INFO 140508977309504] Epoch: 10, batches: 1400, num_examples: 89600, 16010.7 samples/sec, epoch time so far: 0:00:05.596243\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:29:02 INFO 140508977309504] #011Training metrics: mean_squared_error: 0.050 mean_absolute_error: 0.168 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:29:02 INFO 140508977309504] **************\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:29:02 INFO 140508977309504] Completed Epoch: 10, time taken: 0:00:05.661055\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:29:02 INFO 140508977309504] Epoch 10 Training metrics:   mean_squared_error: 0.050 mean_absolute_error: 0.168 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:29:02 INFO 140508977309504] #quality_metric: host=algo-1, epoch=10, train mean_squared_error <loss>=0.05045281701700204\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:29:02 INFO 140508977309504] Epoch 10 Validation metrics: mean_squared_error: 0.913 mean_absolute_error: 0.744 \u001b[0m\n",
      "\u001b[34m[04/28/2021 17:29:02 INFO 140508977309504] #quality_metric: host=algo-1, epoch=10, validation mean_squared_error <loss>=0.9133979557333766\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:29:02 INFO 140508977309504] **************\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:29:02 INFO 140508977309504] patience losses: [0.9186116138825545, 0.9095894130500587, 0.9166324174887425]\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:29:02 INFO 140508977309504] min patience losses: 0.9095894130500587\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:29:02 INFO 140508977309504] current loss: 0.9133979557333766\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:29:02 INFO 140508977309504] absolute loss difference: 0.0038085426833178726\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:29:02 INFO 140508977309504] Bad epoch: loss has not improved (enough). Bad count:4\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:29:02 INFO 140508977309504] Bad epochs exceeded patience. Stopping training early!\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:29:02 INFO 140508977309504] Early stopping criterion met! Stopping training at epoch: 10\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619630936.5934083, \"EndTime\": 1619630942.4723475, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 0.7047653198242188, \"count\": 1, \"min\": 0.7047653198242188, \"max\": 0.7047653198242188}, \"update.time\": {\"sum\": 5873.131513595581, \"count\": 1, \"min\": 5873.131513595581, \"max\": 5873.131513595581}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:29:02 INFO 140508977309504] Early stop condition met. Stopping training.\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:29:02 INFO 140508977309504] #progress_metric: host=algo-1, completed 100 % epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619630936.5991948, \"EndTime\": 1619630942.472756, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 10, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 996864.0, \"count\": 1, \"min\": 996864, \"max\": 996864}, \"Total Batches Seen\": {\"sum\": 15576.0, \"count\": 1, \"min\": 15576, \"max\": 15576}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 11.0, \"count\": 1, \"min\": 11, \"max\": 11}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:29:02 INFO 140508977309504] #throughput_metric: host=algo-1, train throughput=15428.777861413017 records/second\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:29:02 WARNING 140508977309504] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:29:02 INFO 140508977309504] Best model based on epoch 8. Best loss: 0.910\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619630942.472458, \"EndTime\": 1619630942.4743516, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 1.2087821960449219, \"count\": 1, \"min\": 1.2087821960449219, \"max\": 1.2087821960449219}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:29:02 INFO 140508977309504] Serializing model to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:29:02 INFO 140508977309504] Saved checkpoint to \"/tmp/tmpjy2b_f2t/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[04/28/2021 17:29:02 INFO 140508977309504] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619630942.4744096, \"EndTime\": 1619630942.5388265, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.serialize.time\": {\"sum\": 62.53218650817871, \"count\": 1, \"min\": 62.53218650817871, \"max\": 62.53218650817871}, \"setuptime\": {\"sum\": 10.319948196411133, \"count\": 1, \"min\": 10.319948196411133, \"max\": 10.319948196411133}, \"totaltime\": {\"sum\": 72594.411611557, \"count\": 1, \"min\": 72594.411611557, \"max\": 72594.411611557}}}\n",
      "\u001b[0m\n",
      "\n",
      "2021-04-28 17:29:23 Uploading - Uploading generated training model\n",
      "2021-04-28 17:29:23 Completed - Training job completed\n",
      "ProfilerReport-1619630638: NoIssuesFound\n",
      "Training seconds: 159\n",
      "Billable seconds: 159\n"
     ]
    }
   ],
   "source": [
    "# alter hyperparameter and repeat training\n",
    "hyperparameters['enc0_network'] = \"bilstm\"\n",
    "\n",
    "regressor = sagemaker.estimator.Estimator(container,\n",
    "                                         role,\n",
    "                                         instance_count=1,\n",
    "                                         instance_type='ml.p2.xlarge',\n",
    "                                         output_path=output_path + \"output-2\",\n",
    "                                         tags=[{\"Key\": tagKey,\"Value\": tagVal}],\n",
    "                                         sagemaker_session=sess)\n",
    "\n",
    "regressor.set_hyperparameters(**hyperparameters)\n",
    "\n",
    "regressor.fit(input_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 19:18:46 Starting - Starting the training job...\n",
      "2021-04-28 19:19:09 Starting - Launching requested ML instancesProfilerReport-1619637526: InProgress\n",
      "......\n",
      "2021-04-28 19:20:10 Starting - Preparing the instances for training.........\n",
      "2021-04-28 19:21:37 Downloading - Downloading input data...\n",
      "2021-04-28 19:22:10 Training - Downloading the training image.....\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:00 INFO 139782663567168] Reading default configuration from /opt/amazon/lib/python3.7/site-packages/algorithm/default-input.json: {'enc_dim': 4096, 'mlp_dim': 512, 'mlp_activation': 'linear', 'mlp_layers': 2, 'output_layer': 'softmax', 'optimizer': 'adam', 'learning_rate': 0.0004, 'mini_batch_size': 32, 'epochs': 30, 'bucket_width': 0, 'early_stopping_tolerance': 0.01, 'early_stopping_patience': 3, 'dropout': 0, 'weight_decay': 0, 'negative_sampling_rate': 0, 'comparator_list': 'hadamard, concat, abs_diff', 'tied_token_embedding_weight': 'false', 'token_embedding_storage_type': 'dense', 'enc0_network': 'hcnn', 'enc1_network': 'enc0', 'enc0_token_embedding_dim': 300, 'enc0_layers': 'auto', 'enc0_cnn_filter_width': 3, 'enc1_token_embedding_dim': 300, 'enc1_layers': 'auto', 'enc1_cnn_filter_width': 3, 'enc0_pretrained_embedding_file': '', 'enc0_freeze_pretrained_embedding': 'true', 'enc1_pretrained_embedding_file': '', 'enc1_freeze_pretrained_embedding': 'true', 'enc0_vocab_file': '', 'enc1_vocab_file': '', 'num_classes': 2, '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', '_kvstore': 'auto_gpu'}\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:00 INFO 139782663567168] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'enc0_network': 'hcnn', 'num_classes': '2', 'enc0_layers': 'auto', 'enc_dim': '1024', 'enc1_network': 'pooled_embedding', 'enc0_token_embedding_dim': '300', 'enc1_layers': 'auto', 'mlp_activation': 'tanh', 'mlp_dim': '256', 'optimizer': 'adam', 'enc1_vocab_size': '1684', '_num_kv_servers': 'auto', 'mlp_layers': '1', '_kvstore': 'device', 'enc0_vocab_size': '944', 'enc0_max_seq_len': '1', 'enc1_token_embedding_dim': '300', 'early_stopping_patience': '3', 'enc1_max_seq_len': '1', 'output_layer': 'mean_squared_error', '_num_gpus': 'auto', 'enc0_cnn_filter_width': '3', 'early_stopping_tolerance': '0.01', 'bucket_width': '0', 'epochs': '20', 'learning_rate': '0.001', 'mini_batch_size': '64'}\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:00 INFO 139782663567168] Final configuration: {'enc_dim': '1024', 'mlp_dim': '256', 'mlp_activation': 'tanh', 'mlp_layers': '1', 'output_layer': 'mean_squared_error', 'optimizer': 'adam', 'learning_rate': '0.001', 'mini_batch_size': '64', 'epochs': '20', 'bucket_width': '0', 'early_stopping_tolerance': '0.01', 'early_stopping_patience': '3', 'dropout': 0, 'weight_decay': 0, 'negative_sampling_rate': 0, 'comparator_list': 'hadamard, concat, abs_diff', 'tied_token_embedding_weight': 'false', 'token_embedding_storage_type': 'dense', 'enc0_network': 'hcnn', 'enc1_network': 'pooled_embedding', 'enc0_token_embedding_dim': '300', 'enc0_layers': 'auto', 'enc0_cnn_filter_width': '3', 'enc1_token_embedding_dim': '300', 'enc1_layers': 'auto', 'enc1_cnn_filter_width': 3, 'enc0_pretrained_embedding_file': '', 'enc0_freeze_pretrained_embedding': 'true', 'enc1_pretrained_embedding_file': '', 'enc1_freeze_pretrained_embedding': 'true', 'enc0_vocab_file': '', 'enc1_vocab_file': '', 'num_classes': '2', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', '_kvstore': 'device', 'enc1_vocab_size': '1684', 'enc0_vocab_size': '944', 'enc0_max_seq_len': '1', 'enc1_max_seq_len': '1'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:00 INFO 139782663567168] Using default worker.\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:00 INFO 139782663567168] Loaded iterator creator application/jsonlines for content type ('application/jsonlines', '1.0')\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:00 INFO 139782663567168] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:00 INFO 139782663567168] create_iter params {'enc_dim': '1024', 'mlp_dim': '256', 'mlp_activation': 'tanh', 'mlp_layers': '1', 'output_layer': 'mean_squared_error', 'optimizer': 'adam', 'learning_rate': '0.001', 'mini_batch_size': '64', 'epochs': '20', 'bucket_width': '0', 'early_stopping_tolerance': '0.01', 'early_stopping_patience': '3', 'dropout': 0, 'weight_decay': 0, 'negative_sampling_rate': 0, 'comparator_list': 'hadamard, concat, abs_diff', 'tied_token_embedding_weight': 'false', 'token_embedding_storage_type': 'dense', 'enc0_network': 'hcnn', 'enc1_network': 'pooled_embedding', 'enc0_token_embedding_dim': '300', 'enc0_layers': 'auto', 'enc0_cnn_filter_width': '3', 'enc1_token_embedding_dim': '300', 'enc1_layers': 'auto', 'enc1_cnn_filter_width': 3, 'enc0_pretrained_embedding_file': '', 'enc0_freeze_pretrained_embedding': 'true', 'enc1_pretrained_embedding_file': '', 'enc1_freeze_pretrained_embedding': 'true', 'enc0_vocab_file': '', 'enc1_vocab_file': '', 'num_classes': '2', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', '_kvstore': 'device', 'enc1_vocab_size': '1684', 'enc0_vocab_size': '944', 'enc0_max_seq_len': '1', 'enc1_max_seq_len': '1'}\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:00 INFO 139782663567168] create_iter content_params {}\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:00 INFO 139782663567168] Parameters of encoders: [{'network': 'hcnn', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': '3', 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'vocab_size': '944', 'max_seq_len': '1'}, {'network': 'pooled_embedding', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': 3, 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'vocab_size': '1684', 'max_seq_len': '1'}]\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:00 WARNING 139782663567168] Cannot use network \"hcnn\" with enc0. Modifying network to \"pooled_embedding\"\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:00 INFO 139782663567168] output_layer is set to mean_squared_error. Ignoring the hyperparameter 'num_classes'.\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:00 INFO 139782663567168] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:00 INFO 139782663567168] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:00 INFO 139782663567168] Encoder configs: [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 1024, 'vocab_size': 944, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 1024, 'vocab_size': 1684, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:00 INFO 139782663567168] Config: {'enc_dim': 1024, 'max_seq_lens': [1, 1], 'dropout': 0.0, 'weight_decay': 0.0, 'mlp_activation': 'tanh', 'mlp_dim': 256, 'mlp_layers': 1, 'output_layer': 'mean_squared_error', 'learning_rate': 0.001, 'optimizer': 'adam', 'num_classes': None, 'epochs': 20, 'mini_batch_size': 64, 'bucket_width': 0, 'comparator_list': ['hadamard', 'concat', 'abs_diff'], 'tied_token_embedding_weight': False, 'negative_sampling_rate': 0, 'token_embedding_storage_type': 'dense', 'early_stopping_patience': 3, 'early_stopping_tolerance': 0.01, 'enc_configs': [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 1024, 'vocab_size': 944, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 1024, 'vocab_size': 1684, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]}\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:00 INFO 139782663567168] use bucketing: False\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:00 INFO 139782663567168] Creating data iterator for /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:03 INFO 139782663567168] Source words: 90570\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:03 INFO 139782663567168] Target words: 90570\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:03 INFO 139782663567168] Total: 90570 samples in 1 buckets\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:03 INFO 139782663567168] Bucket of (1, 1) : 90570 samples in 1416 batches of 64, approx 64.0 words/batch\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:03 INFO 139782663567168] 0 sentence pairs discarded\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:03 INFO 139782663567168] fill up mode: replicate\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:03 INFO 139782663567168] \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:03 INFO 139782663567168] Negative sampling not used\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:03 INFO 139782663567168] Replicating 54 random sentences from bucket (1, 1) to size it to multiple of 64\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:03 INFO 139782663567168] Bucket batch sizes: [BucketBatchSize(batch_size=64, average_words_per_batch=64.0)]\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:03 INFO 139782663567168] create_iter params {'enc_dim': '1024', 'mlp_dim': '256', 'mlp_activation': 'tanh', 'mlp_layers': '1', 'output_layer': 'mean_squared_error', 'optimizer': 'adam', 'learning_rate': '0.001', 'mini_batch_size': '64', 'epochs': '20', 'bucket_width': '0', 'early_stopping_tolerance': '0.01', 'early_stopping_patience': '3', 'dropout': 0, 'weight_decay': 0, 'negative_sampling_rate': 0, 'comparator_list': 'hadamard, concat, abs_diff', 'tied_token_embedding_weight': 'false', 'token_embedding_storage_type': 'dense', 'enc0_network': 'hcnn', 'enc1_network': 'pooled_embedding', 'enc0_token_embedding_dim': '300', 'enc0_layers': 'auto', 'enc0_cnn_filter_width': '3', 'enc1_token_embedding_dim': '300', 'enc1_layers': 'auto', 'enc1_cnn_filter_width': 3, 'enc0_pretrained_embedding_file': '', 'enc0_freeze_pretrained_embedding': 'true', 'enc1_pretrained_embedding_file': '', 'enc1_freeze_pretrained_embedding': 'true', 'enc0_vocab_file': '', 'enc1_vocab_file': '', 'num_classes': '2', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', '_kvstore': 'device', 'enc1_vocab_size': '1684', 'enc0_vocab_size': '944', 'enc0_max_seq_len': '1', 'enc1_max_seq_len': '1'}\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:03 INFO 139782663567168] create_iter content_params {}\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:03 INFO 139782663567168] Parameters of encoders: [{'network': 'hcnn', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': '3', 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'vocab_size': '944', 'max_seq_len': '1'}, {'network': 'pooled_embedding', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': 3, 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'vocab_size': '1684', 'max_seq_len': '1'}]\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:03 WARNING 139782663567168] Cannot use network \"hcnn\" with enc0. Modifying network to \"pooled_embedding\"\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:03 INFO 139782663567168] output_layer is set to mean_squared_error. Ignoring the hyperparameter 'num_classes'.\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:03 INFO 139782663567168] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:03 INFO 139782663567168] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:03 INFO 139782663567168] Encoder configs: [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 1024, 'vocab_size': 944, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 1024, 'vocab_size': 1684, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:03 INFO 139782663567168] Config: {'enc_dim': 1024, 'max_seq_lens': [1, 1], 'dropout': 0.0, 'weight_decay': 0.0, 'mlp_activation': 'tanh', 'mlp_dim': 256, 'mlp_layers': 1, 'output_layer': 'mean_squared_error', 'learning_rate': 0.001, 'optimizer': 'adam', 'num_classes': None, 'epochs': 20, 'mini_batch_size': 64, 'bucket_width': 0, 'comparator_list': ['hadamard', 'concat', 'abs_diff'], 'tied_token_embedding_weight': False, 'negative_sampling_rate': 0, 'token_embedding_storage_type': 'dense', 'early_stopping_patience': 3, 'early_stopping_tolerance': 0.01, 'enc_configs': [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 1024, 'vocab_size': 944, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 1024, 'vocab_size': 1684, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]}\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:03 INFO 139782663567168] use bucketing: False\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:03 INFO 139782663567168] Creating data iterator for /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:04 INFO 139782663567168] Source words: 9430\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:04 INFO 139782663567168] Target words: 9430\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:04 INFO 139782663567168] Total: 9430 samples in 1 buckets\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:04 INFO 139782663567168] Bucket of (1, 1) : 9430 samples in 148 batches of 64, approx 64.0 words/batch\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:04 INFO 139782663567168] 0 sentence pairs discarded\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:04 INFO 139782663567168] fill up mode: replicate\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:04 INFO 139782663567168] \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:04 INFO 139782663567168] Negative sampling not used\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:04 INFO 139782663567168] Replicating 42 random sentences from bucket (1, 1) to size it to multiple of 64\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:04 INFO 139782663567168] Parameters of encoders: [{'network': 'hcnn', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': '3', 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'vocab_size': '944', 'max_seq_len': '1'}, {'network': 'pooled_embedding', 'token_embedding_dim': '300', 'layers': 'auto', 'cnn_filter_width': 3, 'pretrained_embedding_file': '', 'freeze_pretrained_embedding': 'true', 'vocab_file': '', 'vocab_size': '1684', 'max_seq_len': '1'}]\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:04 WARNING 139782663567168] Cannot use network \"hcnn\" with enc0. Modifying network to \"pooled_embedding\"\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:04 INFO 139782663567168] output_layer is set to mean_squared_error. Ignoring the hyperparameter 'num_classes'.\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:04 INFO 139782663567168] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:04 INFO 139782663567168] Inconsistent enc_dim and token_embedding_dim found for token-embedding-encoder: 1024 vs 300. Setting token embedding dim to be 1024\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:04 INFO 139782663567168] Encoder configs: [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 1024, 'vocab_size': 944, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 1024, 'vocab_size': 1684, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:04 INFO 139782663567168] Config: {'enc_dim': 1024, 'max_seq_lens': [1, 1], 'dropout': 0.0, 'weight_decay': 0.0, 'mlp_activation': 'tanh', 'mlp_dim': 256, 'mlp_layers': 1, 'output_layer': 'mean_squared_error', 'learning_rate': 0.001, 'optimizer': 'adam', 'num_classes': None, 'epochs': 20, 'mini_batch_size': 64, 'bucket_width': 0, 'comparator_list': ['hadamard', 'concat', 'abs_diff'], 'tied_token_embedding_weight': False, 'negative_sampling_rate': 0, 'token_embedding_storage_type': 'dense', 'early_stopping_patience': 3, 'early_stopping_tolerance': 0.01, 'enc_configs': [{'num_layers': 1, 'enc_index': 0, 'token_embedding_dim': 1024, 'vocab_size': 944, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}, {'num_layers': 1, 'enc_index': 1, 'token_embedding_dim': 1024, 'vocab_size': 1684, 'vocab_file': '', 'vocab_dict': None, 'dropout': 0.0, 'pretrained_embedding_file': '', 'pretrained_embedding_file_path': None, 'freeze_pretrained_embedding': True, 'is_train': True}]}\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:04 INFO 139782663567168] Creating new state\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:04 INFO 139782663567168] params {'enc_dim': '1024', 'mlp_dim': '256', 'mlp_activation': 'tanh', 'mlp_layers': '1', 'output_layer': 'mean_squared_error', 'optimizer': 'adam', 'learning_rate': '0.001', 'mini_batch_size': '64', 'epochs': '20', 'bucket_width': '0', 'early_stopping_tolerance': '0.01', 'early_stopping_patience': '3', 'dropout': 0, 'weight_decay': 0, 'negative_sampling_rate': 0, 'comparator_list': 'hadamard, concat, abs_diff', 'tied_token_embedding_weight': 'false', 'token_embedding_storage_type': 'dense', 'enc0_network': 'hcnn', 'enc1_network': 'pooled_embedding', 'enc0_token_embedding_dim': '300', 'enc0_layers': 'auto', 'enc0_cnn_filter_width': '3', 'enc1_token_embedding_dim': '300', 'enc1_layers': 'auto', 'enc1_cnn_filter_width': 3, 'enc0_pretrained_embedding_file': '', 'enc0_freeze_pretrained_embedding': 'true', 'enc1_pretrained_embedding_file': '', 'enc1_freeze_pretrained_embedding': 'true', 'enc0_vocab_file': '', 'enc1_vocab_file': '', 'num_classes': '2', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_tuning_objective_metric': '', '_kvstore': 'device', 'enc1_vocab_size': '1684', 'enc0_vocab_size': '944', 'enc0_max_seq_len': '1', 'enc1_max_seq_len': '1', 'default_bucket_key': (1, 1)}\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:04 INFO 139782663567168] default_bucket_key (1, 1)\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:04 INFO 139782663567168] nvidia-smi: took 0.034 seconds to run.\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:04 INFO 139782663567168] nvidia-smi identified 1 GPUs.\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:04 INFO 139782663567168] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:04 INFO 139782663567168] context [gpu(0)]\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:04 INFO 139782663567168] Create Store: device\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:04 INFO 139782663567168] Number of GPUs being used: 1\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:04 WARNING 139782663567168] dense token embedding is used in a multi-gpu setting...consider changing 'token_embedding_storage_type' to 'row_sparse'\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:04 INFO 139782663567168] data_names: ['source', 'target']\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:04 INFO 139782663567168] label_names: ['out_layer_label']\u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mLayer (type)                                        Output Shape            Param #     Previous Layer                  \u001b[0m\n",
      "\u001b[34m========================================================================================================================\u001b[0m\n",
      "\u001b[34msource(null)                                        1                       0                                           \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34membed_0(Embedding)                                  1x1024                  0           source                          \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_not_equal_scalar0(_not_equal_scalar)               1                       0           source                          \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mreshape0(Reshape)                                   1x1                     0           _not_equal_scalar0              \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbroadcast_mul0(broadcast_mul)                       1x1024                  0           embed_0                         \n",
      "                                                                                        reshape0                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34msum0(sum)                                           1024                    0           broadcast_mul0                  \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34msum1(sum)                                           1                       0           reshape0                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mzeros_like0(zeros_like)                             1                       0           sum1                            \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_equal0(_equal)                                     1                       0           sum1                            \n",
      "                                                                                        zeros_like0                     \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_plus0(elemwise_add)                                1                       0           sum1                            \n",
      "                                                                                        _equal0                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbroadcast_div0(broadcast_div)                       1024                    0           sum0                            \n",
      "                                                                                        _plus0                          \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout0(Dropout)                                   1024                    0           broadcast_div0                  \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34membed_1(Embedding)                                  1x1024                  0                                           \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_not_equal_scalar1(_not_equal_scalar)               1                       0                                           \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mreshape1(Reshape)                                   1x1                     0           _not_equal_scalar1              \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbroadcast_mul1(broadcast_mul)                       1x1024                  0           embed_1                         \n",
      "                                                                                        reshape1                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34msum2(sum)                                           1024                    0           broadcast_mul1                  \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34msum3(sum)                                           1                       0           reshape1                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mzeros_like1(zeros_like)                             1                       0           sum3                            \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_equal1(_equal)                                     1                       0           sum3                            \n",
      "                                                                                        zeros_like1                     \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_plus1(elemwise_add)                                1                       0           sum3                            \n",
      "                                                                                        _equal1                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mbroadcast_div1(broadcast_div)                       1024                    0           sum2                            \n",
      "                                                                                        _plus1                          \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout1(Dropout)                                   1024                    0           broadcast_div1                  \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_mul0(elemwise_mul)                                 1024                    0           dropout0                        \n",
      "                                                                                        dropout1                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m_minus0(elemwise_sub)                               1024                    0           dropout0                        \n",
      "                                                                                        dropout1                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mabs0(abs)                                           1024                    0           _minus0                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mconcat0(Concat)                                     4096                    0           _mul0                           \n",
      "                                                                                        dropout0                        \n",
      "                                                                                        dropout1                        \n",
      "                                                                                        abs0                            \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mmlp_fc0(FullyConnected)                             256                     1048832     concat0                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mactivation0(Activation)                             256                     0           mlp_fc0                         \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mdropout2(Dropout)                                   256                     0           activation0                     \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34moutput_layer(FullyConnected)                        1                       257         dropout2                        \u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34mout_layer(LinearRegressionOutput)                   1                       0           output_layer                    \u001b[0m\n",
      "\u001b[34m========================================================================================================================\u001b[0m\n",
      "\u001b[34mTotal params: 1049089\u001b[0m\n",
      "\u001b[34m________________________________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:04 INFO 139782663567168] data_shapes [DataDesc[source,(64, 1),<class 'numpy.float32'>,NTC], DataDesc[target,(64, 1),<class 'numpy.float32'>,NTC]]\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:04 INFO 139782663567168] label_shapes [DataDesc[out_layer_label,(64,),<class 'numpy.float32'>,NTC]]\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:04 INFO 139782663567168] fixed_param_names: []\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:04 INFO 139782663567168] Initialized BucketingPlus Module\u001b[0m\n",
      "\n",
      "2021-04-28 19:23:10 Training - Training image download completed. Training in progress.\u001b[34m[04/28/2021 19:23:09 INFO 139782663567168] arg_params keys for module initialization: dict_keys([])\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:09 INFO 139782663567168] all params:dict_keys(['embed_0_weight', 'embed_1_weight', 'mlp_fc0_weight', 'mlp_fc0_bias', 'output_layer_weight', 'output_layer_bias'])\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619637780.9539778, \"EndTime\": 1619637789.7394292, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 5482.791423797607, \"count\": 1, \"min\": 5482.791423797607, \"max\": 5482.791423797607}}}\n",
      "\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619637789.7396593, \"EndTime\": 1619637789.7397287, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Total Batches Seen\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Records Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Max Batches Seen Between Resets\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Reset Count\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:10 INFO 139782663567168] Epoch: 0, batches: 100, num_examples: 6400, 14224.5 samples/sec, epoch time so far: 0:00:00.449927\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:10 INFO 139782663567168] #011Training metrics: mean_squared_error: 1.620 mean_absolute_error: 0.992 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:10 INFO 139782663567168] Epoch: 0, batches: 200, num_examples: 12800, 14917.0 samples/sec, epoch time so far: 0:00:00.858082\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:10 INFO 139782663567168] #011Training metrics: mean_squared_error: 1.354 mean_absolute_error: 0.911 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:11 INFO 139782663567168] Epoch: 0, batches: 300, num_examples: 19200, 14883.3 samples/sec, epoch time so far: 0:00:01.290039\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:11 INFO 139782663567168] #011Training metrics: mean_squared_error: 1.245 mean_absolute_error: 0.876 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:11 INFO 139782663567168] Epoch: 0, batches: 400, num_examples: 25600, 15152.1 samples/sec, epoch time so far: 0:00:01.689531\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:11 INFO 139782663567168] #011Training metrics: mean_squared_error: 1.197 mean_absolute_error: 0.861 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:11 INFO 139782663567168] Epoch: 0, batches: 500, num_examples: 32000, 15358.8 samples/sec, epoch time so far: 0:00:02.083491\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:11 INFO 139782663567168] #011Training metrics: mean_squared_error: 1.162 mean_absolute_error: 0.850 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:12 INFO 139782663567168] Epoch: 0, batches: 600, num_examples: 38400, 15485.2 samples/sec, epoch time so far: 0:00:02.479779\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:12 INFO 139782663567168] #011Training metrics: mean_squared_error: 1.131 mean_absolute_error: 0.840 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:12 INFO 139782663567168] Epoch: 0, batches: 700, num_examples: 44800, 15581.4 samples/sec, epoch time so far: 0:00:02.875218\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:12 INFO 139782663567168] #011Training metrics: mean_squared_error: 1.110 mean_absolute_error: 0.834 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:13 INFO 139782663567168] Epoch: 0, batches: 800, num_examples: 51200, 15490.3 samples/sec, epoch time so far: 0:00:03.305305\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:13 INFO 139782663567168] #011Training metrics: mean_squared_error: 1.094 mean_absolute_error: 0.828 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:13 INFO 139782663567168] Epoch: 0, batches: 900, num_examples: 57600, 15573.2 samples/sec, epoch time so far: 0:00:03.698654\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:13 INFO 139782663567168] #011Training metrics: mean_squared_error: 1.076 mean_absolute_error: 0.821 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:13 INFO 139782663567168] Epoch: 0, batches: 1000, num_examples: 64000, 15640.4 samples/sec, epoch time so far: 0:00:04.091974\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:13 INFO 139782663567168] #011Training metrics: mean_squared_error: 1.062 mean_absolute_error: 0.816 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:14 INFO 139782663567168] Epoch: 0, batches: 1100, num_examples: 70400, 15678.4 samples/sec, epoch time so far: 0:00:04.490241\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:14 INFO 139782663567168] #011Training metrics: mean_squared_error: 1.051 mean_absolute_error: 0.812 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:14 INFO 139782663567168] Epoch: 0, batches: 1200, num_examples: 76800, 15723.6 samples/sec, epoch time so far: 0:00:04.884378\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:14 INFO 139782663567168] #011Training metrics: mean_squared_error: 1.041 mean_absolute_error: 0.807 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:15 INFO 139782663567168] Epoch: 0, batches: 1300, num_examples: 83200, 15768.9 samples/sec, epoch time so far: 0:00:05.276206\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:15 INFO 139782663567168] #011Training metrics: mean_squared_error: 1.032 mean_absolute_error: 0.803 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:15 INFO 139782663567168] Epoch: 0, batches: 1400, num_examples: 89600, 15799.8 samples/sec, epoch time so far: 0:00:05.670957\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:15 INFO 139782663567168] #011Training metrics: mean_squared_error: 1.023 mean_absolute_error: 0.800 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:15 INFO 139782663567168] **************\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:15 INFO 139782663567168] Completed Epoch: 0, time taken: 0:00:05.734163\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:15 INFO 139782663567168] Epoch 0 Training metrics:   mean_squared_error: 1.022 mean_absolute_error: 0.799 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:15 INFO 139782663567168] #quality_metric: host=algo-1, epoch=0, train mean_squared_error <loss>=1.0222340797805516\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:15 INFO 139782663567168] Epoch 0 Validation metrics: mean_squared_error: 0.944 mean_absolute_error: 0.770 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:15 INFO 139782663567168] #quality_metric: host=algo-1, epoch=0, validation mean_squared_error <loss>=0.9436331765877234\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:15 INFO 139782663567168] **************\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619637789.7395878, \"EndTime\": 1619637795.7569296, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"epochs\": {\"sum\": 20.0, \"count\": 1, \"min\": 20, \"max\": 20}, \"early_stop.time\": {\"sum\": 0.7143020629882812, \"count\": 1, \"min\": 0.7143020629882812, \"max\": 0.7143020629882812}, \"update.time\": {\"sum\": 5944.82159614563, \"count\": 1, \"min\": 5944.82159614563, \"max\": 5944.82159614563}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:15 INFO 139782663567168] #progress_metric: host=algo-1, completed 5.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619637789.812077, \"EndTime\": 1619637795.7573254, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Total Batches Seen\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 1.0, \"count\": 1, \"min\": 1, \"max\": 1}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:15 INFO 139782663567168] #throughput_metric: host=algo-1, train throughput=15242.616351002764 records/second\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:16 INFO 139782663567168] Epoch: 1, batches: 100, num_examples: 6400, 14528.8 samples/sec, epoch time so far: 0:00:00.440506\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:16 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.723 mean_absolute_error: 0.671 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:16 INFO 139782663567168] Epoch: 1, batches: 200, num_examples: 12800, 15296.7 samples/sec, epoch time so far: 0:00:00.836782\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:16 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.717 mean_absolute_error: 0.666 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:17 INFO 139782663567168] Epoch: 1, batches: 300, num_examples: 19200, 15600.2 samples/sec, epoch time so far: 0:00:01.230755\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:17 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.712 mean_absolute_error: 0.663 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:17 INFO 139782663567168] Epoch: 1, batches: 400, num_examples: 25600, 15703.4 samples/sec, epoch time so far: 0:00:01.630223\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:17 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.700 mean_absolute_error: 0.657 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:17 INFO 139782663567168] Epoch: 1, batches: 500, num_examples: 32000, 15810.7 samples/sec, epoch time so far: 0:00:02.023942\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:17 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.696 mean_absolute_error: 0.655 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:18 INFO 139782663567168] Epoch: 1, batches: 600, num_examples: 38400, 15872.0 samples/sec, epoch time so far: 0:00:02.419349\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:18 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.688 mean_absolute_error: 0.652 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:18 INFO 139782663567168] Epoch: 1, batches: 700, num_examples: 44800, 15928.2 samples/sec, epoch time so far: 0:00:02.812617\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:18 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.684 mean_absolute_error: 0.650 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:19 INFO 139782663567168] Epoch: 1, batches: 800, num_examples: 51200, 15743.8 samples/sec, epoch time so far: 0:00:03.252066\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:19 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.680 mean_absolute_error: 0.648 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:19 INFO 139782663567168] Epoch: 1, batches: 900, num_examples: 57600, 15514.0 samples/sec, epoch time so far: 0:00:03.712782\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:19 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.678 mean_absolute_error: 0.647 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:19 INFO 139782663567168] Epoch: 1, batches: 1000, num_examples: 64000, 15352.0 samples/sec, epoch time so far: 0:00:04.168848\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:19 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.678 mean_absolute_error: 0.647 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:20 INFO 139782663567168] Epoch: 1, batches: 1100, num_examples: 70400, 15114.6 samples/sec, epoch time so far: 0:00:04.657747\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:20 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.674 mean_absolute_error: 0.645 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:20 INFO 139782663567168] Epoch: 1, batches: 1200, num_examples: 76800, 15081.2 samples/sec, epoch time so far: 0:00:05.092426\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:20 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.671 mean_absolute_error: 0.644 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:21 INFO 139782663567168] Epoch: 1, batches: 1300, num_examples: 83200, 15032.5 samples/sec, epoch time so far: 0:00:05.534660\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:21 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.667 mean_absolute_error: 0.642 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:21 INFO 139782663567168] Epoch: 1, batches: 1400, num_examples: 89600, 15110.7 samples/sec, epoch time so far: 0:00:05.929566\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:21 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.666 mean_absolute_error: 0.641 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:21 INFO 139782663567168] **************\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:21 INFO 139782663567168] Completed Epoch: 1, time taken: 0:00:05.992178\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:21 INFO 139782663567168] Epoch 1 Training metrics:   mean_squared_error: 0.666 mean_absolute_error: 0.641 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:21 INFO 139782663567168] #quality_metric: host=algo-1, epoch=1, train mean_squared_error <loss>=0.6655455794879945\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:21 INFO 139782663567168] Epoch 1 Validation metrics: mean_squared_error: 0.984 mean_absolute_error: 0.796 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:21 INFO 139782663567168] #quality_metric: host=algo-1, epoch=1, validation mean_squared_error <loss>=0.9844859834458377\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:21 INFO 139782663567168] **************\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619637795.7570658, \"EndTime\": 1619637801.9990084, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 0.039577484130859375, \"count\": 1, \"min\": 0.039577484130859375, \"max\": 0.039577484130859375}, \"update.time\": {\"sum\": 6199.476718902588, \"count\": 1, \"min\": 6199.476718902588, \"max\": 6199.476718902588}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:21 INFO 139782663567168] #progress_metric: host=algo-1, completed 10.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619637795.7995005, \"EndTime\": 1619637801.9993258, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 181248.0, \"count\": 1, \"min\": 181248, \"max\": 181248}, \"Total Batches Seen\": {\"sum\": 2832.0, \"count\": 1, \"min\": 2832, \"max\": 2832}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:21 INFO 139782663567168] #throughput_metric: host=algo-1, train throughput=14616.757218681305 records/second\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:22 INFO 139782663567168] Epoch: 2, batches: 100, num_examples: 6400, 16192.0 samples/sec, epoch time so far: 0:00:00.395257\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:22 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.272 mean_absolute_error: 0.400 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:22 INFO 139782663567168] Epoch: 2, batches: 200, num_examples: 12800, 16163.1 samples/sec, epoch time so far: 0:00:00.791926\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:22 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.280 mean_absolute_error: 0.405 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:23 INFO 139782663567168] Epoch: 2, batches: 300, num_examples: 19200, 16172.5 samples/sec, epoch time so far: 0:00:01.187197\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:23 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.275 mean_absolute_error: 0.402 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:23 INFO 139782663567168] Epoch: 2, batches: 400, num_examples: 25600, 16134.7 samples/sec, epoch time so far: 0:00:01.586641\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:23 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.273 mean_absolute_error: 0.400 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:23 INFO 139782663567168] Epoch: 2, batches: 500, num_examples: 32000, 16159.0 samples/sec, epoch time so far: 0:00:01.980316\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:23 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.272 mean_absolute_error: 0.399 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:24 INFO 139782663567168] Epoch: 2, batches: 600, num_examples: 38400, 16167.8 samples/sec, epoch time so far: 0:00:02.375095\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:24 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.269 mean_absolute_error: 0.397 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:24 INFO 139782663567168] Epoch: 2, batches: 700, num_examples: 44800, 16176.9 samples/sec, epoch time so far: 0:00:02.769379\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:24 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.269 mean_absolute_error: 0.397 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:25 INFO 139782663567168] Epoch: 2, batches: 800, num_examples: 51200, 16195.6 samples/sec, epoch time so far: 0:00:03.161346\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:25 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.270 mean_absolute_error: 0.398 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:25 INFO 139782663567168] Epoch: 2, batches: 900, num_examples: 57600, 16145.5 samples/sec, epoch time so far: 0:00:03.567568\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:25 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.272 mean_absolute_error: 0.400 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:25 INFO 139782663567168] Epoch: 2, batches: 1000, num_examples: 64000, 16144.3 samples/sec, epoch time so far: 0:00:03.964243\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:25 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.272 mean_absolute_error: 0.400 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:26 INFO 139782663567168] Epoch: 2, batches: 1100, num_examples: 70400, 15989.8 samples/sec, epoch time so far: 0:00:04.402815\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:26 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.273 mean_absolute_error: 0.401 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:26 INFO 139782663567168] Epoch: 2, batches: 1200, num_examples: 76800, 16002.7 samples/sec, epoch time so far: 0:00:04.799201\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:26 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.274 mean_absolute_error: 0.402 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:27 INFO 139782663567168] Epoch: 2, batches: 1300, num_examples: 83200, 16008.9 samples/sec, epoch time so far: 0:00:05.197099\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:27 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.275 mean_absolute_error: 0.403 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:27 INFO 139782663567168] Epoch: 2, batches: 1400, num_examples: 89600, 16010.6 samples/sec, epoch time so far: 0:00:05.596286\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:27 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.277 mean_absolute_error: 0.404 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:27 INFO 139782663567168] **************\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:27 INFO 139782663567168] Completed Epoch: 2, time taken: 0:00:05.659685\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:27 INFO 139782663567168] Epoch 2 Training metrics:   mean_squared_error: 0.277 mean_absolute_error: 0.404 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:27 INFO 139782663567168] #quality_metric: host=algo-1, epoch=2, train mean_squared_error <loss>=0.27706680704686937\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:27 INFO 139782663567168] Epoch 2 Validation metrics: mean_squared_error: 0.950 mean_absolute_error: 0.766 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:27 INFO 139782663567168] #quality_metric: host=algo-1, epoch=2, validation mean_squared_error <loss>=0.9499793616501061\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:27 INFO 139782663567168] **************\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619637801.9991205, \"EndTime\": 1619637807.8730555, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 0.03600120544433594, \"count\": 1, \"min\": 0.03600120544433594, \"max\": 0.03600120544433594}, \"update.time\": {\"sum\": 5867.552995681763, \"count\": 1, \"min\": 5867.552995681763, \"max\": 5867.552995681763}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:27 INFO 139782663567168] #progress_metric: host=algo-1, completed 15.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619637802.0054739, \"EndTime\": 1619637807.8733194, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 271872.0, \"count\": 1, \"min\": 271872, \"max\": 271872}, \"Total Batches Seen\": {\"sum\": 4248.0, \"count\": 1, \"min\": 4248, \"max\": 4248}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:27 INFO 139782663567168] #throughput_metric: host=algo-1, train throughput=15443.767720746908 records/second\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:28 INFO 139782663567168] Epoch: 3, batches: 100, num_examples: 6400, 16152.9 samples/sec, epoch time so far: 0:00:00.396213\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:28 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.176 mean_absolute_error: 0.308 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:28 INFO 139782663567168] Epoch: 3, batches: 200, num_examples: 12800, 15890.2 samples/sec, epoch time so far: 0:00:00.805526\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:28 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.172 mean_absolute_error: 0.303 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:29 INFO 139782663567168] Epoch: 3, batches: 300, num_examples: 19200, 15911.9 samples/sec, epoch time so far: 0:00:01.206643\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:29 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.165 mean_absolute_error: 0.298 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:29 INFO 139782663567168] Epoch: 3, batches: 400, num_examples: 25600, 15929.0 samples/sec, epoch time so far: 0:00:01.607132\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:29 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.163 mean_absolute_error: 0.297 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:29 INFO 139782663567168] Epoch: 3, batches: 500, num_examples: 32000, 15981.2 samples/sec, epoch time so far: 0:00:02.002347\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:29 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.163 mean_absolute_error: 0.297 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:30 INFO 139782663567168] Epoch: 3, batches: 600, num_examples: 38400, 16033.6 samples/sec, epoch time so far: 0:00:02.394978\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:30 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.164 mean_absolute_error: 0.299 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:30 INFO 139782663567168] Epoch: 3, batches: 700, num_examples: 44800, 15991.2 samples/sec, epoch time so far: 0:00:02.801542\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:30 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.164 mean_absolute_error: 0.299 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:31 INFO 139782663567168] Epoch: 3, batches: 800, num_examples: 51200, 16026.8 samples/sec, epoch time so far: 0:00:03.194655\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:31 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.165 mean_absolute_error: 0.301 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:31 INFO 139782663567168] Epoch: 3, batches: 900, num_examples: 57600, 15902.3 samples/sec, epoch time so far: 0:00:03.622117\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:31 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.164 mean_absolute_error: 0.300 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:31 INFO 139782663567168] Epoch: 3, batches: 1000, num_examples: 64000, 15928.4 samples/sec, epoch time so far: 0:00:04.017991\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:31 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.163 mean_absolute_error: 0.300 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:32 INFO 139782663567168] Epoch: 3, batches: 1100, num_examples: 70400, 15934.4 samples/sec, epoch time so far: 0:00:04.418114\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:32 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.164 mean_absolute_error: 0.301 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:32 INFO 139782663567168] Epoch: 3, batches: 1200, num_examples: 76800, 15942.8 samples/sec, epoch time so far: 0:00:04.817214\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:32 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.165 mean_absolute_error: 0.302 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:33 INFO 139782663567168] Epoch: 3, batches: 1300, num_examples: 83200, 15960.0 samples/sec, epoch time so far: 0:00:05.213032\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:33 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.165 mean_absolute_error: 0.303 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:33 INFO 139782663567168] Epoch: 3, batches: 1400, num_examples: 89600, 15974.7 samples/sec, epoch time so far: 0:00:05.608875\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:33 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.165 mean_absolute_error: 0.303 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:33 INFO 139782663567168] **************\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:33 INFO 139782663567168] Completed Epoch: 3, time taken: 0:00:05.676092\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:33 INFO 139782663567168] Epoch 3 Training metrics:   mean_squared_error: 0.166 mean_absolute_error: 0.303 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:33 INFO 139782663567168] #quality_metric: host=algo-1, epoch=3, train mean_squared_error <loss>=0.16552483047342906\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:33 INFO 139782663567168] Epoch 3 Validation metrics: mean_squared_error: 0.969 mean_absolute_error: 0.788 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:33 INFO 139782663567168] #quality_metric: host=algo-1, epoch=3, validation mean_squared_error <loss>=0.968811986816896\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:33 INFO 139782663567168] **************\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:33 INFO 139782663567168] patience losses: [0.9436331765877234, 0.9844859834458377, 0.9499793616501061]\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:33 INFO 139782663567168] min patience losses: 0.9436331765877234\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:33 INFO 139782663567168] current loss: 0.968811986816896\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:33 INFO 139782663567168] absolute loss difference: 0.025178810229172566\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:33 INFO 139782663567168] Bad epoch: loss has not improved (enough). Bad count:1\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619637807.87315, \"EndTime\": 1619637813.756681, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 0.46539306640625, \"count\": 1, \"min\": 0.46539306640625, \"max\": 0.46539306640625}, \"update.time\": {\"sum\": 5877.115726470947, \"count\": 1, \"min\": 5877.115726470947, \"max\": 5877.115726470947}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:33 INFO 139782663567168] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619637807.8795424, \"EndTime\": 1619637813.7570174, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 362496.0, \"count\": 1, \"min\": 362496, \"max\": 362496}, \"Total Batches Seen\": {\"sum\": 5664.0, \"count\": 1, \"min\": 5664, \"max\": 5664}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:33 INFO 139782663567168] #throughput_metric: host=algo-1, train throughput=15418.423843887775 records/second\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:34 INFO 139782663567168] Epoch: 4, batches: 100, num_examples: 6400, 16380.7 samples/sec, epoch time so far: 0:00:00.390703\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:34 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.124 mean_absolute_error: 0.264 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:34 INFO 139782663567168] Epoch: 4, batches: 200, num_examples: 12800, 16134.4 samples/sec, epoch time so far: 0:00:00.793336\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:34 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.115 mean_absolute_error: 0.256 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:34 INFO 139782663567168] Epoch: 4, batches: 300, num_examples: 19200, 16170.3 samples/sec, epoch time so far: 0:00:01.187362\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:34 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.114 mean_absolute_error: 0.254 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:35 INFO 139782663567168] Epoch: 4, batches: 400, num_examples: 25600, 16185.7 samples/sec, epoch time so far: 0:00:01.581644\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:35 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.112 mean_absolute_error: 0.252 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:35 INFO 139782663567168] Epoch: 4, batches: 500, num_examples: 32000, 16105.6 samples/sec, epoch time so far: 0:00:01.986881\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:35 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.111 mean_absolute_error: 0.250 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:36 INFO 139782663567168] Epoch: 4, batches: 600, num_examples: 38400, 16138.3 samples/sec, epoch time so far: 0:00:02.379438\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:36 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.110 mean_absolute_error: 0.249 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:36 INFO 139782663567168] Epoch: 4, batches: 700, num_examples: 44800, 15942.3 samples/sec, epoch time so far: 0:00:02.810139\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:36 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.110 mean_absolute_error: 0.249 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:36 INFO 139782663567168] Epoch: 4, batches: 800, num_examples: 51200, 15966.9 samples/sec, epoch time so far: 0:00:03.206636\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:36 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.111 mean_absolute_error: 0.251 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:37 INFO 139782663567168] Epoch: 4, batches: 900, num_examples: 57600, 16001.5 samples/sec, epoch time so far: 0:00:03.599657\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:37 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.111 mean_absolute_error: 0.251 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:37 INFO 139782663567168] Epoch: 4, batches: 1000, num_examples: 64000, 15998.1 samples/sec, epoch time so far: 0:00:04.000465\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:37 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.111 mean_absolute_error: 0.251 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:38 INFO 139782663567168] Epoch: 4, batches: 1100, num_examples: 70400, 16018.4 samples/sec, epoch time so far: 0:00:04.394937\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:38 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.110 mean_absolute_error: 0.251 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:38 INFO 139782663567168] Epoch: 4, batches: 1200, num_examples: 76800, 16021.7 samples/sec, epoch time so far: 0:00:04.793494\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:38 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.110 mean_absolute_error: 0.251 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:38 INFO 139782663567168] Epoch: 4, batches: 1300, num_examples: 83200, 16029.6 samples/sec, epoch time so far: 0:00:05.190384\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:38 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.110 mean_absolute_error: 0.251 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:39 INFO 139782663567168] Epoch: 4, batches: 1400, num_examples: 89600, 16051.5 samples/sec, epoch time so far: 0:00:05.582037\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:39 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.110 mean_absolute_error: 0.251 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:39 INFO 139782663567168] **************\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:39 INFO 139782663567168] Completed Epoch: 4, time taken: 0:00:05.645724\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:39 INFO 139782663567168] Epoch 4 Training metrics:   mean_squared_error: 0.110 mean_absolute_error: 0.251 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:39 INFO 139782663567168] #quality_metric: host=algo-1, epoch=4, train mean_squared_error <loss>=0.10992073957771484\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:39 INFO 139782663567168] Epoch 4 Validation metrics: mean_squared_error: 0.941 mean_absolute_error: 0.766 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:39 INFO 139782663567168] #quality_metric: host=algo-1, epoch=4, validation mean_squared_error <loss>=0.9408759764722876\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:39 INFO 139782663567168] **************\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:39 INFO 139782663567168] patience losses: [0.9844859834458377, 0.9499793616501061, 0.968811986816896]\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:39 INFO 139782663567168] min patience losses: 0.9499793616501061\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:39 INFO 139782663567168] current loss: 0.9408759764722876\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:39 INFO 139782663567168] absolute loss difference: 0.009103385177818502\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:39 INFO 139782663567168] Bad epoch: loss has not improved (enough). Bad count:2\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619637813.756804, \"EndTime\": 1619637819.6168802, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 3.335237503051758, \"count\": 1, \"min\": 3.335237503051758, \"max\": 3.335237503051758}, \"update.time\": {\"sum\": 5853.624105453491, \"count\": 1, \"min\": 5853.624105453491, \"max\": 5853.624105453491}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:39 INFO 139782663567168] #progress_metric: host=algo-1, completed 25.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619637813.7632308, \"EndTime\": 1619637819.6172357, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 453120.0, \"count\": 1, \"min\": 453120, \"max\": 453120}, \"Total Batches Seen\": {\"sum\": 7080.0, \"count\": 1, \"min\": 7080, \"max\": 7080}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:39 INFO 139782663567168] #throughput_metric: host=algo-1, train throughput=15480.261061237436 records/second\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:40 INFO 139782663567168] Epoch: 5, batches: 100, num_examples: 6400, 16339.2 samples/sec, epoch time so far: 0:00:00.391696\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:40 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.096 mean_absolute_error: 0.236 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:40 INFO 139782663567168] Epoch: 5, batches: 200, num_examples: 12800, 16307.1 samples/sec, epoch time so far: 0:00:00.784933\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:40 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.093 mean_absolute_error: 0.235 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:40 INFO 139782663567168] Epoch: 5, batches: 300, num_examples: 19200, 16146.9 samples/sec, epoch time so far: 0:00:01.189081\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:40 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.090 mean_absolute_error: 0.231 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:41 INFO 139782663567168] Epoch: 5, batches: 400, num_examples: 25600, 16200.6 samples/sec, epoch time so far: 0:00:01.580193\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:41 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.089 mean_absolute_error: 0.230 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:41 INFO 139782663567168] Epoch: 5, batches: 500, num_examples: 32000, 15976.0 samples/sec, epoch time so far: 0:00:02.003003\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:41 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.089 mean_absolute_error: 0.229 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:42 INFO 139782663567168] Epoch: 5, batches: 600, num_examples: 38400, 16020.7 samples/sec, epoch time so far: 0:00:02.396902\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:42 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.088 mean_absolute_error: 0.228 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:42 INFO 139782663567168] Epoch: 5, batches: 700, num_examples: 44800, 16024.1 samples/sec, epoch time so far: 0:00:02.795789\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:42 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.087 mean_absolute_error: 0.228 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:42 INFO 139782663567168] Epoch: 5, batches: 800, num_examples: 51200, 16036.9 samples/sec, epoch time so far: 0:00:03.192641\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:42 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.087 mean_absolute_error: 0.228 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:43 INFO 139782663567168] Epoch: 5, batches: 900, num_examples: 57600, 16057.4 samples/sec, epoch time so far: 0:00:03.587132\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:43 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.088 mean_absolute_error: 0.228 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:43 INFO 139782663567168] Epoch: 5, batches: 1000, num_examples: 64000, 16065.2 samples/sec, epoch time so far: 0:00:03.983758\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:43 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.088 mean_absolute_error: 0.228 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:44 INFO 139782663567168] Epoch: 5, batches: 1100, num_examples: 70400, 16064.6 samples/sec, epoch time so far: 0:00:04.382302\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:44 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.087 mean_absolute_error: 0.228 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:44 INFO 139782663567168] Epoch: 5, batches: 1200, num_examples: 76800, 16083.1 samples/sec, epoch time so far: 0:00:04.775192\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:44 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.087 mean_absolute_error: 0.228 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:44 INFO 139782663567168] Epoch: 5, batches: 1300, num_examples: 83200, 16082.7 samples/sec, epoch time so far: 0:00:05.173259\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:44 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.087 mean_absolute_error: 0.228 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:45 INFO 139782663567168] Epoch: 5, batches: 1400, num_examples: 89600, 16100.0 samples/sec, epoch time so far: 0:00:05.565209\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:45 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.088 mean_absolute_error: 0.229 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:45 INFO 139782663567168] **************\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:45 INFO 139782663567168] Completed Epoch: 5, time taken: 0:00:05.627641\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:45 INFO 139782663567168] Epoch 5 Training metrics:   mean_squared_error: 0.088 mean_absolute_error: 0.229 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:45 INFO 139782663567168] #quality_metric: host=algo-1, epoch=5, train mean_squared_error <loss>=0.08773928587088141\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:45 INFO 139782663567168] Epoch 5 Validation metrics: mean_squared_error: 0.951 mean_absolute_error: 0.774 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:45 INFO 139782663567168] #quality_metric: host=algo-1, epoch=5, validation mean_squared_error <loss>=0.950501575260549\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:45 INFO 139782663567168] **************\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:45 INFO 139782663567168] patience losses: [0.9499793616501061, 0.968811986816896, 0.9408759764722876]\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:45 INFO 139782663567168] min patience losses: 0.9408759764722876\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:45 INFO 139782663567168] current loss: 0.950501575260549\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:45 INFO 139782663567168] absolute loss difference: 0.009625598788261414\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:45 INFO 139782663567168] Bad epoch: loss has not improved (enough). Bad count:3\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619637819.6170046, \"EndTime\": 1619637825.5038614, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 0.5137920379638672, \"count\": 1, \"min\": 0.5137920379638672, \"max\": 0.5137920379638672}, \"update.time\": {\"sum\": 5847.0447063446045, \"count\": 1, \"min\": 5847.0447063446045, \"max\": 5847.0447063446045}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:45 INFO 139782663567168] #progress_metric: host=algo-1, completed 30.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619637819.6567824, \"EndTime\": 1619637825.504199, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 5, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 543744.0, \"count\": 1, \"min\": 543744, \"max\": 543744}, \"Total Batches Seen\": {\"sum\": 8496.0, \"count\": 1, \"min\": 8496, \"max\": 8496}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:45 INFO 139782663567168] #throughput_metric: host=algo-1, train throughput=15497.612299695482 records/second\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:45 INFO 139782663567168] Epoch: 6, batches: 100, num_examples: 6400, 16091.5 samples/sec, epoch time so far: 0:00:00.397726\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:45 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.087 mean_absolute_error: 0.228 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:46 INFO 139782663567168] Epoch: 6, batches: 200, num_examples: 12800, 16170.9 samples/sec, epoch time so far: 0:00:00.791544\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:46 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.085 mean_absolute_error: 0.226 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:46 INFO 139782663567168] Epoch: 6, batches: 300, num_examples: 19200, 15833.7 samples/sec, epoch time so far: 0:00:01.212600\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:46 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.086 mean_absolute_error: 0.226 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:47 INFO 139782663567168] Epoch: 6, batches: 400, num_examples: 25600, 15902.3 samples/sec, epoch time so far: 0:00:01.609828\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:47 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.085 mean_absolute_error: 0.225 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:47 INFO 139782663567168] Epoch: 6, batches: 500, num_examples: 32000, 15921.1 samples/sec, epoch time so far: 0:00:02.009916\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:47 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.084 mean_absolute_error: 0.224 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:47 INFO 139782663567168] Epoch: 6, batches: 600, num_examples: 38400, 15935.5 samples/sec, epoch time so far: 0:00:02.409709\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:47 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.083 mean_absolute_error: 0.223 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:48 INFO 139782663567168] Epoch: 6, batches: 700, num_examples: 44800, 15988.0 samples/sec, epoch time so far: 0:00:02.802101\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:48 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.083 mean_absolute_error: 0.222 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:48 INFO 139782663567168] Epoch: 6, batches: 800, num_examples: 51200, 16029.1 samples/sec, epoch time so far: 0:00:03.194185\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:48 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.083 mean_absolute_error: 0.222 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:49 INFO 139782663567168] Epoch: 6, batches: 900, num_examples: 57600, 16043.5 samples/sec, epoch time so far: 0:00:03.590233\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:49 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.083 mean_absolute_error: 0.222 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:49 INFO 139782663567168] Epoch: 6, batches: 1000, num_examples: 64000, 16067.7 samples/sec, epoch time so far: 0:00:03.983148\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:49 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.082 mean_absolute_error: 0.222 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:49 INFO 139782663567168] Epoch: 6, batches: 1100, num_examples: 70400, 16069.8 samples/sec, epoch time so far: 0:00:04.380875\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:49 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.082 mean_absolute_error: 0.221 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:50 INFO 139782663567168] Epoch: 6, batches: 1200, num_examples: 76800, 16087.6 samples/sec, epoch time so far: 0:00:04.773852\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:50 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.082 mean_absolute_error: 0.221 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:50 INFO 139782663567168] Epoch: 6, batches: 1300, num_examples: 83200, 16098.2 samples/sec, epoch time so far: 0:00:05.168267\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:50 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.082 mean_absolute_error: 0.221 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:51 INFO 139782663567168] Epoch: 6, batches: 1400, num_examples: 89600, 16087.3 samples/sec, epoch time so far: 0:00:05.569596\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:51 INFO 139782663567168] #011Training metrics: mean_squared_error: 0.082 mean_absolute_error: 0.221 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:51 INFO 139782663567168] **************\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:51 INFO 139782663567168] Completed Epoch: 6, time taken: 0:00:05.632539\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:51 INFO 139782663567168] Epoch 6 Training metrics:   mean_squared_error: 0.082 mean_absolute_error: 0.221 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:51 INFO 139782663567168] #quality_metric: host=algo-1, epoch=6, train mean_squared_error <loss>=0.0817836912212062\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:51 INFO 139782663567168] Epoch 6 Validation metrics: mean_squared_error: 0.938 mean_absolute_error: 0.770 \u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:51 INFO 139782663567168] #quality_metric: host=algo-1, epoch=6, validation mean_squared_error <loss>=0.9377473725660427\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:51 INFO 139782663567168] **************\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:51 INFO 139782663567168] patience losses: [0.968811986816896, 0.9408759764722876, 0.950501575260549]\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:51 INFO 139782663567168] min patience losses: 0.9408759764722876\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:51 INFO 139782663567168] current loss: 0.9377473725660427\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:51 INFO 139782663567168] absolute loss difference: 0.00312860390624492\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:51 INFO 139782663567168] Bad epoch: loss has not improved (enough). Bad count:4\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:51 INFO 139782663567168] Bad epochs exceeded patience. Stopping training early!\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:51 INFO 139782663567168] Early stopping criterion met! Stopping training at epoch: 6\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619637825.5039704, \"EndTime\": 1619637831.3490605, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"early_stop.time\": {\"sum\": 3.8576126098632812, \"count\": 1, \"min\": 3.8576126098632812, \"max\": 3.8576126098632812}, \"update.time\": {\"sum\": 5838.627338409424, \"count\": 1, \"min\": 5838.627338409424, \"max\": 5838.627338409424}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:51 INFO 139782663567168] Early stop condition met. Stopping training.\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:51 INFO 139782663567168] #progress_metric: host=algo-1, completed 100 % epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619637825.510404, \"EndTime\": 1619637831.3495004, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 6, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 634368.0, \"count\": 1, \"min\": 634368, \"max\": 634368}, \"Total Batches Seen\": {\"sum\": 9912.0, \"count\": 1, \"min\": 9912, \"max\": 9912}, \"Max Records Seen Between Resets\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Max Batches Seen Between Resets\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}, \"Reset Count\": {\"sum\": 7.0, \"count\": 1, \"min\": 7, \"max\": 7}, \"Number of Records Since Last Reset\": {\"sum\": 90624.0, \"count\": 1, \"min\": 90624, \"max\": 90624}, \"Number of Batches Since Last Reset\": {\"sum\": 1416.0, \"count\": 1, \"min\": 1416, \"max\": 1416}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:51 INFO 139782663567168] #throughput_metric: host=algo-1, train throughput=15519.778932430983 records/second\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:51 WARNING 139782663567168] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:51 INFO 139782663567168] Best model based on epoch 6. Best loss: 0.938\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619637831.3491895, \"EndTime\": 1619637831.3521972, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"finalize.time\": {\"sum\": 2.279520034790039, \"count\": 1, \"min\": 2.279520034790039, \"max\": 2.279520034790039}}}\n",
      "\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:51 INFO 139782663567168] Serializing model to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:51 INFO 139782663567168] Saved checkpoint to \"/tmp/tmp1l34tc9q/state-0001.params\"\u001b[0m\n",
      "\u001b[34m[04/28/2021 19:23:51 INFO 139782663567168] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1619637831.3523226, \"EndTime\": 1619637831.4428577, \"Dimensions\": {\"Algorithm\": \"ObjectToVec\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"model.serialize.time\": {\"sum\": 88.88745307922363, \"count\": 1, \"min\": 88.88745307922363, \"max\": 88.88745307922363}, \"setuptime\": {\"sum\": 11.815547943115234, \"count\": 1, \"min\": 11.815547943115234, \"max\": 11.815547943115234}, \"totaltime\": {\"sum\": 50521.18134498596, \"count\": 1, \"min\": 50521.18134498596, \"max\": 50521.18134498596}}}\n",
      "\u001b[0m\n",
      "\n",
      "2021-04-28 19:24:11 Uploading - Uploading generated training model\n",
      "2021-04-28 19:24:11 Completed - Training job completed\n",
      "Training seconds: 148\n",
      "Billable seconds: 148\n"
     ]
    }
   ],
   "source": [
    "# alter hyperparameter and repeat training\n",
    "hyperparameters['enc0_network'] = \"hcnn\"\n",
    "\n",
    "regressor = sagemaker.estimator.Estimator(container,\n",
    "                                         role,\n",
    "                                         instance_count=1,\n",
    "                                         instance_type='ml.p2.xlarge',\n",
    "                                         output_path=output_path + \"output-3\",\n",
    "                                         tags=[{\"Key\": tagKey,\"Value\": tagVal}],\n",
    "                                         sagemaker_session=sess)\n",
    "\n",
    "regressor.set_hyperparameters(**hyperparameters)\n",
    "\n",
    "regressor.fit(input_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the algorithm image\n",
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "container = f\"{account}.dkr.ecr.{region}.amazonaws.com/sagemaker-surprise-svd:latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create input data paths\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "base_path = f\"s3://{bucket}/input/csv/\"\n",
    "input_paths = {}\n",
    "for channel in ['train', 'validation']:\n",
    "    input_paths[channel] = TrainingInput(base_path + f\"{channel}/{channel}.csv\",\n",
    "                                         distribution=\"ShardedByS3Key\",\n",
    "                                         content_type=\"text/csv\")\n",
    "\n",
    "# create ouput path for generated model artifacts\n",
    "output_path = f\"s3://{bucket}/output/surprise-svd/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 19:52:10 Starting - Starting the training job...\n",
      "2021-04-28 19:52:33 Starting - Launching requested ML instancesProfilerReport-1619639530: InProgress\n",
      "......\n",
      "2021-04-28 19:53:33 Starting - Preparing the instances for training......\n",
      "2021-04-28 19:54:34 Downloading - Downloading input data\n",
      "2021-04-28 19:54:34 Training - Downloading the training image...\n",
      "2021-04-28 19:55:11 Uploading - Uploading generated training model\u001b[34mStarting the training.\u001b[0m\n",
      "\u001b[34mMetricRMSE=0.9501996976986254;\u001b[0m\n",
      "\u001b[34mTraining complete.\u001b[0m\n",
      "\n",
      "2021-04-28 19:55:34 Completed - Training job completed\n",
      "Training seconds: 60\n",
      "Billable seconds: 60\n"
     ]
    }
   ],
   "source": [
    "# begin training\n",
    "svd = sagemaker.estimator.Estimator(container,\n",
    "                                   role,\n",
    "                                   instance_count=1,\n",
    "                                   instance_type='ml.c4.2xlarge',\n",
    "                                   output_path=output_path,\n",
    "                                   tags=[{\"Key\": tagKey,\"Value\": tagVal}],\n",
    "                                   sagemaker_session=sess,\n",
    "                                   metric_definitions=[{'Name': 'validation:mean_squared_error', 'Regex': 'MetricRMSE=(.*?);'}])\n",
    "\n",
    "svd.fit(input_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVD++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 21:42:07 Starting - Starting the training job...\n",
      "2021-04-28 21:42:30 Starting - Launching requested ML instancesProfilerReport-1619646127: InProgress\n",
      "......\n",
      "2021-04-28 21:43:34 Starting - Preparing the instances for training......\n",
      "2021-04-28 21:44:38 Downloading - Downloading input data\n",
      "2021-04-28 21:44:38 Training - Downloading the training image.....\u001b[34mStarting the training.\u001b[0m\n",
      "\n",
      "2021-04-28 21:45:31 Training - Training image download completed. Training in progress.\u001b[34mMetricRMSE=0.9369658404487412;\u001b[0m\n",
      "\u001b[34mTraining complete.\u001b[0m\n",
      "\n",
      "2021-04-28 21:49:00 Uploading - Uploading generated training model\n",
      "2021-04-28 21:49:00 Completed - Training job completed\n",
      "Training seconds: 274\n",
      "Billable seconds: 274\n"
     ]
    }
   ],
   "source": [
    "# get the algorithm image\n",
    "container = f\"{account}.dkr.ecr.{region}.amazonaws.com/sagemaker-surprise-svdpp:latest\"\n",
    "# create ouput path for generated model artifacts\n",
    "output_path = f\"s3://{bucket}/output/surprise-svdpp/\"\n",
    "\n",
    "# begin training\n",
    "svdpp = sagemaker.estimator.Estimator(container,\n",
    "                                      role,\n",
    "                                      instance_count=1,\n",
    "                                      instance_type='ml.c4.2xlarge',\n",
    "                                      output_path=output_path,\n",
    "                                      tags=[{\"Key\": tagKey,\"Value\": tagVal}],\n",
    "                                      sagemaker_session=sess,\n",
    "                                      metric_definitions=[{'Name': 'validation:mean_squared_error', 'Regex': 'MetricRMSE=(.*?);'}])\n",
    "\n",
    "svdpp.fit(input_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 22:16:28 Starting - Starting the training job...\n",
      "2021-04-28 22:16:51 Starting - Launching requested ML instancesProfilerReport-1619648188: InProgress\n",
      "......\n",
      "2021-04-28 22:17:51 Starting - Preparing the instances for training...\n",
      "2021-04-28 22:18:25 Downloading - Downloading input data...\n",
      "2021-04-28 22:18:51 Training - Downloading the training image..\u001b[34mStarting the training.\u001b[0m\n",
      "\u001b[34mMetricRMSE=0.9928632845948795;\u001b[0m\n",
      "\u001b[34mTraining complete.\u001b[0m\n",
      "\n",
      "2021-04-28 22:19:18 Uploading - Uploading generated training model\n",
      "2021-04-28 22:19:18 Completed - Training job completed\n",
      "Training seconds: 53\n",
      "Billable seconds: 53\n"
     ]
    }
   ],
   "source": [
    "# get the algorithm image\n",
    "container = f\"{account}.dkr.ecr.{region}.amazonaws.com/sagemaker-surprise-nmf:latest\"\n",
    "# create ouput path for generated model artifacts\n",
    "output_path = f\"s3://{bucket}/output/surprise-nmf/\"\n",
    "\n",
    "# begin training\n",
    "nmf = sagemaker.estimator.Estimator(container,\n",
    "                                      role,\n",
    "                                      instance_count=1,\n",
    "                                      instance_type='ml.c4.2xlarge',\n",
    "                                      output_path=output_path,\n",
    "                                      tags=[{\"Key\": tagKey,\"Value\": tagVal}],\n",
    "                                      sagemaker_session=sess,\n",
    "                                      metric_definitions=[{'Name': 'validation:mean_squared_error', 'Regex': 'MetricRMSE=(.*?);'}])\n",
    "\n",
    "nmf.fit(input_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNNBasic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 22:07:19 Starting - Starting the training job...\n",
      "2021-04-28 22:07:41 Starting - Launching requested ML instancesProfilerReport-1619647638: InProgress\n",
      ".........\n",
      "2021-04-28 22:09:10 Starting - Preparing the instances for training......\n",
      "2021-04-28 22:10:12 Downloading - Downloading input data\n",
      "2021-04-28 22:10:12 Training - Downloading the training image...\n",
      "2021-04-28 22:10:46 Uploading - Uploading generated training model\u001b[34mStarting the training.\u001b[0m\n",
      "\u001b[34mComputing the msd similarity matrix...\u001b[0m\n",
      "\u001b[34mDone computing similarity matrix.\u001b[0m\n",
      "\u001b[34mMetricRMSE=0.9963111213563114;\u001b[0m\n",
      "\u001b[34mTraining complete.\u001b[0m\n",
      "\n",
      "2021-04-28 22:11:02 Completed - Training job completed\n",
      "Training seconds: 53\n",
      "Billable seconds: 53\n"
     ]
    }
   ],
   "source": [
    "# get the algorithm image\n",
    "container = f\"{account}.dkr.ecr.{region}.amazonaws.com/sagemaker-surprise-knnbasic:latest\"\n",
    "# create ouput path for generated model artifacts\n",
    "output_path = f\"s3://{bucket}/output/surprise-knnbasic/\"\n",
    "\n",
    "# begin training\n",
    "knnbasic = sagemaker.estimator.Estimator(container,\n",
    "                                      role,\n",
    "                                      instance_count=1,\n",
    "                                      instance_type='ml.c4.2xlarge',\n",
    "                                      output_path=output_path,\n",
    "                                      tags=[{\"Key\": tagKey,\"Value\": tagVal}],\n",
    "                                      sagemaker_session=sess,\n",
    "                                      metric_definitions=[{'Name': 'validation:mean_squared_error', 'Regex': 'MetricRMSE=(.*?);'}])\n",
    "\n",
    "knnbasic.fit(input_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNNWithMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 22:39:29 Starting - Starting the training job...\n",
      "2021-04-28 22:39:30 Starting - Launching requested ML instancesProfilerReport-1619649568: InProgress\n",
      "......\n",
      "2021-04-28 22:40:43 Starting - Preparing the instances for training......\n",
      "2021-04-28 22:41:43 Downloading - Downloading input data\n",
      "2021-04-28 22:41:43 Training - Downloading the training image...\n",
      "2021-04-28 22:42:23 Uploading - Uploading generated training model\n",
      "2021-04-28 22:42:23 Completed - Training job completed\n",
      "\u001b[34mStarting the training.\u001b[0m\n",
      "\u001b[34mComputing the msd similarity matrix...\u001b[0m\n",
      "\u001b[34mDone computing similarity matrix.\u001b[0m\n",
      "\u001b[34mMetricRMSE=0.9715234551918015;\u001b[0m\n",
      "\u001b[34mTraining complete.\u001b[0m\n",
      "Training seconds: 53\n",
      "Billable seconds: 53\n"
     ]
    }
   ],
   "source": [
    "# get the algorithm image\n",
    "container = f\"{account}.dkr.ecr.{region}.amazonaws.com/sagemaker-surprise-knnmeans:latest\"\n",
    "# create ouput path for generated model artifacts\n",
    "output_path = f\"s3://{bucket}/output/surprise-knnmeans/\"\n",
    "\n",
    "# begin training\n",
    "knnmeans = sagemaker.estimator.Estimator(container,\n",
    "                                      role,\n",
    "                                      instance_count=1,\n",
    "                                      instance_type='ml.c4.2xlarge',\n",
    "                                      output_path=output_path,\n",
    "                                      tags=[{\"Key\": tagKey,\"Value\": tagVal}],\n",
    "                                      sagemaker_session=sess,\n",
    "                                      metric_definitions=[{'Name': 'validation:mean_squared_error', 'Regex': 'MetricRMSE=(.*?);'}])\n",
    "\n",
    "knnmeans.fit(input_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SlopeOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-28 22:47:38 Starting - Starting the training job...\n",
      "2021-04-28 22:47:40 Starting - Launching requested ML instancesProfilerReport-1619650058: InProgress\n",
      "......\n",
      "2021-04-28 22:49:05 Starting - Preparing the instances for training...\n",
      "2021-04-28 22:49:36 Downloading - Downloading input data...\n",
      "2021-04-28 22:50:06 Training - Downloading the training image..\u001b[34mStarting the training.\u001b[0m\n",
      "\u001b[34mMetricRMSE=0.9648840238100149;\u001b[0m\n",
      "\u001b[34mTraining complete.\u001b[0m\n",
      "\n",
      "2021-04-28 22:50:26 Uploading - Uploading generated training model\n",
      "2021-04-28 22:50:26 Completed - Training job completed\n",
      "Training seconds: 47\n",
      "Billable seconds: 47\n"
     ]
    }
   ],
   "source": [
    "# get the algorithm image\n",
    "container = f\"{account}.dkr.ecr.{region}.amazonaws.com/sagemaker-surprise-slopeone:latest\"\n",
    "# create ouput path for generated model artifacts\n",
    "output_path = f\"s3://{bucket}/output/surprise-slopeone/\"\n",
    "\n",
    "# begin training\n",
    "slopeone = sagemaker.estimator.Estimator(container,\n",
    "                                      role,\n",
    "                                      instance_count=1,\n",
    "                                      instance_type='ml.c4.2xlarge',\n",
    "                                      output_path=output_path,\n",
    "                                      tags=[{\"Key\": tagKey,\"Value\": tagVal}],\n",
    "                                      sagemaker_session=sess,\n",
    "                                      metric_definitions=[{'Name': 'validation:mean_squared_error', 'Regex': 'MetricRMSE=(.*?);'}])\n",
    "\n",
    "slopeone.fit(input_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search query returned 9 training jobs\n"
     ]
    }
   ],
   "source": [
    "# construct query for training jobs from this experiment\n",
    "search_params={\n",
    "    \"MaxResults\": 10,\n",
    "    \"Resource\": \"TrainingJob\",\n",
    "    \"SearchExpression\": {\n",
    "        \"Filters\": [\n",
    "            {\n",
    "                \"Name\": f\"Tags.{tagKey}\",\n",
    "                \"Operator\": \"Equals\",\n",
    "                \"Value\": tagVal\n",
    "            },\n",
    "            {\n",
    "                \"Name\": \"TrainingJobStatus\",\n",
    "                \"Operator\": \"Equals\",\n",
    "                \"Value\": \"Completed\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"SortBy\": \"Metrics.validation:mean_squared_error\",\n",
    "    \"SortOrder\": \"Ascending\"\n",
    "}\n",
    "\n",
    "results = smclient.search(**search_params)\n",
    "print(f\"Search query returned {len(results['Results'])} training jobs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object2Vec Network Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object2vec algorithm offers three network models to choose from. These are HCNN,\n",
    "a hierarchical convolutional neural network, biLSTM, a bidirectional long short-term\n",
    "memory network, and pooled embedding, which averages the embedding of all tokens.\n",
    "The validation metric of each network model can now be retrieved and plotted.\n",
    "The best of these will be used in the overall algorithm comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract training job metrics\n",
    "job_metrics = []\n",
    "\n",
    "for result in results['Results']:\n",
    "    job = result['TrainingJob']\n",
    "    name = job['TrainingJobName']\n",
    "    if name.startswith('object2vec'):\n",
    "        metrics = job['FinalMetricDataList']\n",
    "        train_rmse = next(m for m in metrics if m['MetricName'] == 'train:mean_squared_error')['Value']\n",
    "        validation_rmse = next(m for m in metrics if m['MetricName'] == 'validation:mean_squared_error')['Value']\n",
    "        job_metrics.append((name, train_rmse, validation_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = ['Pooled Embedding', 'biLSTM', 'HCNN']\n",
    "train_score = [train for (_, train, _) in job_metrics]\n",
    "valid_score = [valid for (_, _, valid) in job_metrics]\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "train_bars = ax.bar(x - width/2, train_score, width, label='Train')\n",
    "valid_bars = ax.bar(x + width/2, valid_score, width, label='Validation')\n",
    "\n",
    "ax.set_ylabel('RMSE')\n",
    "ax.set_title('Object2Vec Training Metrics')\n",
    "ax.set_xticks(x)\n",
    "ax.set_yticks(np.linspace(0,1,11))\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "ax.set_axisbelow(True)\n",
    "plt.grid(True, axis='y')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract training job metrics\n",
    "job_metrics = []\n",
    "\n",
    "for result in results['Results']:\n",
    "    job = result['TrainingJob']\n",
    "    name = job['TrainingJobName']\n",
    "    metrics = job['FinalMetricDataList']\n",
    "    validation_rmse = next(m for m in metrics if m['MetricName'] == 'validation:mean_squared_error')['Value']\n",
    "    job_metrics.append((name, validation_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('object2vec-2021-04-28-17-23-58-543', 0.9133979678153992),\n",
       " ('object2vec-2021-04-28-17-18-11-479', 0.917380154132843),\n",
       " ('sagemaker-surprise-svdpp-2021-04-28-21-42-07-188', 0.936965823173523),\n",
       " ('object2vec-2021-04-28-19-18-46-639', 0.9377473592758179),\n",
       " ('sagemaker-surprise-svd-2021-04-28-19-52-10-601', 0.9501997232437134),\n",
       " ('sagemaker-surprise-slopeone-2021-04-28-22-47-38-614', 0.9648840427398682),\n",
       " ('sagemaker-surprise-knnmeans-2021-04-28-22-39-28-907', 0.9715234637260437),\n",
       " ('sagemaker-surprise-nmf-2021-04-28-22-16-28-386', 0.9928632974624634),\n",
       " ('sagemaker-surprise-knnbasic-2021-04-28-22-07-18-790', 0.9963111281394958)]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the best performing model for each algorithm\n",
    "\n",
    "# list of best models with metric (default None)\n",
    "best_models = {'object2vec': None,\n",
    "               'sagemaker-surprise-svd': None,\n",
    "               'sagemaker-surprise-svdpp': None,\n",
    "               'sagemaker-surprise-nmf': None,\n",
    "               'sagemaker-surprise-knnbasic': None,\n",
    "               'sagemaker-surprise-knnmeans': None,\n",
    "               'sagemaker-surprise-slopeone': None\n",
    "              }\n",
    "\n",
    "# for each algorithm\n",
    "for algo in best_models.keys():\n",
    "    # for each model trained\n",
    "    for (job_name, score) in job_metrics:\n",
    "        # if this model uses that algorithm\n",
    "        if job_name.startswith(algo+'-'):\n",
    "            best_score = best_models[algo]\n",
    "            # if this model has a better score than the current best\n",
    "            if best_score == None or best_score >= score:\n",
    "                # update best score\n",
    "                best_models[algo] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort models by score\n",
    "sorted_models = sorted(best_models.items(), key=lambda item: item[1])\n",
    "\n",
    "# map algorithm names to chart labels\n",
    "label_map = {\n",
    "    'object2vec': 'object2vec',\n",
    "    'sagemaker-surprise-svd': 'SVD',\n",
    "    'sagemaker-surprise-svdpp': 'SVD++',\n",
    "    'sagemaker-surprise-nmf': 'NMF',\n",
    "    'sagemaker-surprise-knnbasic': 'KNNBasic',\n",
    "    'sagemaker-surprise-knnmeans': 'KNNWithMeans',\n",
    "    'sagemaker-surprise-slopeone': 'SlopeOne'\n",
    "}\n",
    "\n",
    "labeled_models = [(label_map[algo_name], score) for (algo_name, score) in sorted_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "[labels, rmse_scores] = list(zip(*labeled_models))\n",
    "\n",
    "x = np.arange(len(labels))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_figwidth(10)\n",
    "bars = ax.bar(x, rmse_scores, width)\n",
    "\n",
    "ax.set_ylabel('RMSE')\n",
    "ax.set_title('MovieLens Prediction Error')\n",
    "ax.set_xticks(x)\n",
    "ax.set_yticks(np.linspace(0,1,11))\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_axisbelow(True)\n",
    "plt.grid(True, axis='y')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Winning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best performing model (here object2vec with pooled embedding) can now be deployed to an endpoint and used for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "regression_model = regressor.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "predictor = regression_model.deploy(initial_instance_count=1,\n",
    "                                    instance_type = 'ml.m4.xlarge',\n",
    "                                    serializer = JSONSerializer(),\n",
    "                                    deserializer = JSONDeserializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the endpoint by making a single test prediction.\n",
    "(The actual rating for user 1 and movie 253 is 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': [{'scores': [4.642399311065674]}]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a prediction\n",
    "predictor.predict({\"instances\":[{\"in0\":[1],\"in1\":[253]}]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now convert `df_test` to an inference payload and have the model make a prediction for each entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make inference payload and get list of true ratings\n",
    "payload = {\"instances\":[]}\n",
    "true_ratings = []\n",
    "\n",
    "for index, row in df_test.iterrows():\n",
    "    userID = int(row['userID'])\n",
    "    movieID = int(row['movieID'])\n",
    "    rating = int(row['rating'])\n",
    "    payload['instances'].append({\"in0\":[userID],\"in1\":[movieID]})\n",
    "    true_ratings.append(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions from predictor endpoint\n",
    "predictions = predictor.predict(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract list of predicted ratings\n",
    "predicted_ratings = []\n",
    "for pred in predictions['predictions']:\n",
    "    predicted_ratings.append(pred['scores'][0])\n",
    "\n",
    "r_predicted = np.array(predicted_ratings)\n",
    "r_actual = np.array(true_ratings)\n",
    "\n",
    "# calculate RMSE\n",
    "error = r_predicted - r_actual\n",
    "sqr_err = error ** 2\n",
    "mse_err = sqr_err.sum()/len(sqr_err)\n",
    "rmse_err = np.sqrt(mse_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27294449904556345"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.delete_endpoint(predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
